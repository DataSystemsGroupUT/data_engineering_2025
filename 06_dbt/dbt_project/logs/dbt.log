[0m16:41:14.452040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0b040f650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0ad6b7b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0ad6aa6d0>]}


============================== 16:41:14.460802 | b334fd56-8899-4425-b63b-69ac86f8f937 ==============================
[0m16:41:14.460802 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:41:14.461723 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt debug', 'profiles_dir': '/dbt', 'version_check': 'True', 'log_path': 'logs', 'empty': 'None', 'static_parser': 'True', 'target_path': 'None', 'debug': 'False', 'quiet': 'False', 'partial_parse': 'True', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'printer_width': '80', 'write_json': 'True', 'warn_error': 'None', 'log_format': 'default', 'fail_fast': 'False', 'introspect': 'True', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_cache_events': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False'}
[0m16:41:14.472356 [info ] [MainThread]: dbt version: 1.10.13
[0m16:41:14.473363 [info ] [MainThread]: python version: 3.11.14
[0m16:41:14.474570 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m16:41:14.475534 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m16:41:14.550091 [info ] [MainThread]: Using profiles dir at /dbt
[0m16:41:14.551405 [info ] [MainThread]: Using profiles.yml file at /dbt/profiles.yml
[0m16:41:14.552405 [info ] [MainThread]: Using dbt_project.yml file at /dbt/dbt_project.yml
[0m16:41:14.554465 [info ] [MainThread]: adapter type: clickhouse
[0m16:41:14.555391 [info ] [MainThread]: adapter version: 1.9.5
[0m16:41:14.556813 [info ] [MainThread]: Configuration:
[0m16:41:14.558187 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m16:41:14.559431 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m16:41:14.560511 [info ] [MainThread]: Required dependencies:
[0m16:41:14.561475 [debug] [MainThread]: Executing "git --help"
[0m16:41:14.563209 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m16:41:14.564112 [info ] [MainThread]: Connection:
[0m16:41:14.565373 [info ] [MainThread]:   driver: None
[0m16:41:14.566269 [info ] [MainThread]:   host: clickhouse-server
[0m16:41:14.567365 [info ] [MainThread]:   port: 8123
[0m16:41:14.568267 [info ] [MainThread]:   user: default
[0m16:41:14.569376 [info ] [MainThread]:   schema: default
[0m16:41:14.570326 [info ] [MainThread]:   retries: 1
[0m16:41:14.571251 [info ] [MainThread]:   cluster: None
[0m16:41:14.572152 [info ] [MainThread]:   database_engine: None
[0m16:41:14.573182 [info ] [MainThread]:   cluster_mode: False
[0m16:41:14.574508 [info ] [MainThread]:   secure: False
[0m16:41:14.575504 [info ] [MainThread]:   verify: True
[0m16:41:14.576762 [info ] [MainThread]:   client_cert: None
[0m16:41:14.578147 [info ] [MainThread]:   client_cert_key: None
[0m16:41:14.579459 [info ] [MainThread]:   connect_timeout: 10
[0m16:41:14.580767 [info ] [MainThread]:   send_receive_timeout: 300
[0m16:41:14.582038 [info ] [MainThread]:   sync_request_timeout: 5
[0m16:41:14.583135 [info ] [MainThread]:   compress_block_size: 1048576
[0m16:41:14.584379 [info ] [MainThread]:   compression: 
[0m16:41:14.585773 [info ] [MainThread]:   check_exchange: True
[0m16:41:14.586889 [info ] [MainThread]:   custom_settings: None
[0m16:41:14.588164 [info ] [MainThread]:   use_lw_deletes: False
[0m16:41:14.590118 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m16:41:14.591690 [info ] [MainThread]:   tcp_keepalive: False
[0m16:41:14.593493 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:41:14.662870 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m16:41:14.664082 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:41:14.722941 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m16:41:14.724400 [info ] [MainThread]: [31m3 checks failed:[0m
[0m16:41:14.725629 [info ] [MainThread]: Project loading failed for the following reason:
 project path </dbt/dbt_project.yml> not found

[0m16:41:14.726654 [info ] [MainThread]: Error from git --help: Could not find command, ensure it is in the user's PATH: "git"

[0m16:41:14.728029 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  Received ClickHouse exception, code: 194, server response: Code: 194. DB::Exception: default: Authentication failed: password is incorrect, or there is no user with such name.
  
  If you use ClickHouse Cloud, the password can be reset at https://clickhouse.cloud/
  on the settings page for the corresponding service.
  
  If you have installed ClickHouse and forgot password you can reset it in the configuration file.
  The password for default user is typically located at /etc/clickhouse-server/users.d/default-password.xml
  and deleting this file will reset the password.
  See also /etc/clickhouse-server/users.xml on the server where ClickHouse is installed.
  
  . (REQUIRED_PASSWORD) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m16:41:14.730050 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.34404758, "process_in_blocks": "0", "process_kernel_time": 0.309006, "process_mem_max_rss": "107204", "process_out_blocks": "2131", "process_user_time": 1.866115}
[0m16:41:14.731001 [debug] [MainThread]: Command `dbt debug` failed at 16:41:14.730880 after 0.35 seconds
[0m16:41:14.731701 [debug] [MainThread]: Connection 'debug' was left open.
[0m16:41:14.732320 [debug] [MainThread]: On debug: No close available on handle
[0m16:41:14.732936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0ad6a08d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0ad6a9110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0ad4a9fd0>]}
[0m16:41:14.733683 [debug] [MainThread]: Flushing usage events
[0m16:41:24.794624 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:47:45.874663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52c007b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52c0171450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52c017bc10>]}


============================== 16:47:45.887279 | 66d9e785-f0ae-4e67-adb6-4205ccdf0f4c ==============================
[0m16:47:45.887279 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:47:45.889493 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'target_path': 'None', 'log_format': 'default', 'log_cache_events': 'False', 'debug': 'False', 'quiet': 'False', 'log_path': 'logs', 'empty': 'None', 'invocation_command': 'dbt debug', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/dbt', 'use_experimental_parser': 'False', 'printer_width': '80', 'introspect': 'True', 'use_colors': 'True', 'partial_parse': 'True', 'static_parser': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'cache_selected_only': 'False', 'no_print': 'None'}
[0m16:47:45.906650 [info ] [MainThread]: dbt version: 1.10.13
[0m16:47:45.908066 [info ] [MainThread]: python version: 3.11.14
[0m16:47:45.909731 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m16:47:45.910920 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m16:47:45.914334 [info ] [MainThread]: target not specified in profile 'name', using 'default'
[0m16:47:45.916661 [info ] [MainThread]: target not specified in profile 'version', using 'default'
[0m16:47:45.919511 [info ] [MainThread]: target not specified in profile 'profile', using 'default'
[0m16:47:45.922551 [info ] [MainThread]: target not specified in profile 'model-paths', using 'default'
[0m16:47:45.925435 [error] [MainThread]: Encountered an error:
string indices must be integers, not 'str'
[0m16:47:45.929215 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/main.py", line 420, in debug
    results = task.run()
              ^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/task/debug.py", line 114, in run
    load_profile_status: SubtaskStatus = self._load_profile()
                                         ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/task/debug.py", line 205, in _load_profile
    profile: Profile = Profile.render(
                       ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/config/profile.py", line 402, in render
    return cls.from_raw_profiles(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/config/profile.py", line 368, in from_raw_profiles
    return cls.from_raw_profile_info(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/config/profile.py", line 314, in from_raw_profile_info
    target_name, profile_data = cls.render_profile(
                                ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/config/profile.py", line 275, in render_profile
    target_name = renderer.render_value(raw_profile["target"])
                                        ~~~~~~~~~~~^^^^^^^^^^
TypeError: string indices must be integers, not 'str'

[0m16:47:45.934527 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.19806395, "process_in_blocks": "0", "process_kernel_time": 0.538862, "process_mem_max_rss": "104496", "process_out_blocks": "2095", "process_user_time": 2.502477}
[0m16:47:45.937396 [debug] [MainThread]: Command `dbt debug` failed at 16:47:45.936822 after 0.20 seconds
[0m16:47:45.939541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52c0168910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52c0171250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52c03b6410>]}
[0m16:47:45.941391 [debug] [MainThread]: Flushing usage events
[0m16:47:56.055425 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:49:55.253554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dfb0ad0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dfe088a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dfdf27b90>]}


============================== 16:49:55.261265 | e7a9bdb0-f894-423a-8520-2c6cc8b77ef1 ==============================
[0m16:49:55.261265 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:49:55.262876 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/dbt', 'cache_selected_only': 'False', 'warn_error': 'None', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'None', 'log_path': 'logs', 'log_cache_events': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'printer_width': '80', 'log_format': 'default', 'target_path': 'None', 'debug': 'False', 'partial_parse': 'True', 'version_check': 'True', 'quiet': 'False', 'no_print': 'None', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'invocation_command': 'dbt debug', 'use_colors': 'True', 'introspect': 'True'}
[0m16:49:55.278519 [info ] [MainThread]: dbt version: 1.10.13
[0m16:49:55.279858 [info ] [MainThread]: python version: 3.11.14
[0m16:49:55.281521 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m16:49:55.282822 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m16:49:55.286658 [info ] [MainThread]: target not specified in profile 'name', using 'default'
[0m16:49:55.289752 [info ] [MainThread]: target not specified in profile 'version', using 'default'
[0m16:49:55.292896 [info ] [MainThread]: target not specified in profile 'profile', using 'default'
[0m16:49:55.295912 [info ] [MainThread]: target not specified in profile 'model-paths', using 'default'
[0m16:49:55.298511 [error] [MainThread]: Encountered an error:
string indices must be integers, not 'str'
[0m16:49:55.301652 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/main.py", line 420, in debug
    results = task.run()
              ^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/task/debug.py", line 114, in run
    load_profile_status: SubtaskStatus = self._load_profile()
                                         ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/task/debug.py", line 205, in _load_profile
    profile: Profile = Profile.render(
                       ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/config/profile.py", line 402, in render
    return cls.from_raw_profiles(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/config/profile.py", line 368, in from_raw_profiles
    return cls.from_raw_profile_info(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/config/profile.py", line 314, in from_raw_profile_info
    target_name, profile_data = cls.render_profile(
                                ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/config/profile.py", line 275, in render_profile
    target_name = renderer.render_value(raw_profile["target"])
                                        ~~~~~~~~~~~^^^^^^^^^^
TypeError: string indices must be integers, not 'str'

[0m16:49:55.304322 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.11789889, "process_in_blocks": "0", "process_kernel_time": 0.367326, "process_mem_max_rss": "103984", "process_out_blocks": "2095", "process_user_time": 2.431349}
[0m16:49:55.305909 [debug] [MainThread]: Command `dbt debug` failed at 16:49:55.305652 after 0.12 seconds
[0m16:49:55.307390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dfb0adc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dfb0af010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dfb1a3a10>]}
[0m16:49:55.308920 [debug] [MainThread]: Flushing usage events
[0m16:50:05.429205 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:53:18.415302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81160c8550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81160c9910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81161a6450>]}


============================== 16:53:18.427307 | 55a07d96-6f50-4a07-959a-4502febfbb36 ==============================
[0m16:53:18.427307 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:53:18.438655 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'target_path': 'None', 'introspect': 'True', 'log_path': '/dbt/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'use_colors': 'True', 'log_format': 'default', 'empty': 'None', 'version_check': 'True', 'debug': 'False', 'write_json': 'True', 'log_cache_events': 'False', 'profiles_dir': '/dbt', 'cache_selected_only': 'False', 'static_parser': 'True', 'printer_width': '80', 'no_print': 'None', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'fail_fast': 'False'}
[0m16:53:18.466066 [info ] [MainThread]: dbt version: 1.10.13
[0m16:53:18.472573 [info ] [MainThread]: python version: 3.11.14
[0m16:53:18.480396 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m16:53:18.486845 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m16:53:18.513316 [info ] [MainThread]: Using profiles dir at /dbt
[0m16:53:18.516959 [info ] [MainThread]: Using profiles.yml file at /dbt/profiles.yml
[0m16:53:18.520541 [info ] [MainThread]: Using dbt_project.yml file at /dbt/dbt_project.yml
[0m16:53:18.771487 [info ] [MainThread]: Configuration:
[0m16:53:18.772513 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m16:53:18.774125 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:53:18.775213 [info ] [MainThread]: Required dependencies:
[0m16:53:18.776416 [debug] [MainThread]: Executing "git --help"
[0m16:53:18.782315 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m16:53:18.783659 [info ] [MainThread]: Connection test skipped since no profile was found
[0m16:53:18.785994 [info ] [MainThread]: [31m2 checks failed:[0m
[0m16:53:18.788112 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Could not find profile named 'default'


[0m16:53:18.790099 [info ] [MainThread]: Error from git --help: Could not find command, ensure it is in the user's PATH: "git"

[0m16:53:18.793388 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.5678558, "process_in_blocks": "0", "process_kernel_time": 0.436193, "process_mem_max_rss": "104384", "process_out_blocks": "2093", "process_user_time": 3.012006}
[0m16:53:18.795204 [debug] [MainThread]: Command `dbt debug` failed at 16:53:18.794903 after 0.57 seconds
[0m16:53:18.797074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f811619c6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8115f9e850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8116190890>]}
[0m16:53:18.799078 [debug] [MainThread]: Flushing usage events
[0m16:53:28.872036 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:57:19.071857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375b5ab050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375b5ab190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375b5a9090>]}


============================== 16:57:19.081663 | ea1ea4e6-d267-42bc-89e4-63b09ed10554 ==============================
[0m16:57:19.081663 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:57:19.083583 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'warn_error': 'None', 'target_path': 'None', 'fail_fast': 'False', 'cache_selected_only': 'False', 'quiet': 'False', 'invocation_command': 'dbt debug', 'log_cache_events': 'False', 'log_format': 'default', 'partial_parse': 'True', 'printer_width': '80', 'indirect_selection': 'eager', 'empty': 'None', 'write_json': 'True', 'static_parser': 'True', 'log_path': '/dbt/logs', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'profiles_dir': '/dbt', 'use_colors': 'True'}
[0m16:57:19.096369 [info ] [MainThread]: dbt version: 1.10.13
[0m16:57:19.097857 [info ] [MainThread]: python version: 3.11.14
[0m16:57:19.099551 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m16:57:19.101147 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m16:57:19.191354 [info ] [MainThread]: Using profiles dir at /dbt
[0m16:57:19.192660 [info ] [MainThread]: Using profiles.yml file at /dbt/profiles.yml
[0m16:57:19.194206 [info ] [MainThread]: Using dbt_project.yml file at /dbt/dbt_project.yml
[0m16:57:19.195947 [info ] [MainThread]: adapter type: clickhouse
[0m16:57:19.197227 [info ] [MainThread]: adapter version: 1.9.5
[0m16:57:19.315923 [info ] [MainThread]: Configuration:
[0m16:57:19.317051 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m16:57:19.318258 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:57:19.319424 [info ] [MainThread]: Required dependencies:
[0m16:57:19.320432 [debug] [MainThread]: Executing "git --help"
[0m16:57:19.322304 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m16:57:19.323188 [info ] [MainThread]: Connection:
[0m16:57:19.324169 [info ] [MainThread]:   driver: None
[0m16:57:19.325095 [info ] [MainThread]:   host: clickhouse-server
[0m16:57:19.326369 [info ] [MainThread]:   port: 8123
[0m16:57:19.327601 [info ] [MainThread]:   user: default
[0m16:57:19.329217 [info ] [MainThread]:   schema: default
[0m16:57:19.330489 [info ] [MainThread]:   retries: 1
[0m16:57:19.332248 [info ] [MainThread]:   cluster: None
[0m16:57:19.333793 [info ] [MainThread]:   database_engine: None
[0m16:57:19.335082 [info ] [MainThread]:   cluster_mode: False
[0m16:57:19.336286 [info ] [MainThread]:   secure: False
[0m16:57:19.337477 [info ] [MainThread]:   verify: True
[0m16:57:19.338454 [info ] [MainThread]:   client_cert: None
[0m16:57:19.339757 [info ] [MainThread]:   client_cert_key: None
[0m16:57:19.341162 [info ] [MainThread]:   connect_timeout: 10
[0m16:57:19.342342 [info ] [MainThread]:   send_receive_timeout: 300
[0m16:57:19.343613 [info ] [MainThread]:   sync_request_timeout: 5
[0m16:57:19.344698 [info ] [MainThread]:   compress_block_size: 1048576
[0m16:57:19.345927 [info ] [MainThread]:   compression: 
[0m16:57:19.347194 [info ] [MainThread]:   check_exchange: True
[0m16:57:19.348663 [info ] [MainThread]:   custom_settings: None
[0m16:57:19.350145 [info ] [MainThread]:   use_lw_deletes: False
[0m16:57:19.351188 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m16:57:19.352658 [info ] [MainThread]:   tcp_keepalive: False
[0m16:57:19.354477 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:57:19.451984 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m16:57:19.453237 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:57:19.631809 [info ] [MainThread]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m16:57:19.633440 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m16:57:19.639377 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:57:19.680855 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m16:57:19.682265 [info ] [MainThread]: [31m1 check failed:[0m
[0m16:57:19.683989 [info ] [MainThread]: Error from git --help: Could not find command, ensure it is in the user's PATH: "git"

[0m16:57:19.687017 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.68534875, "process_in_blocks": "0", "process_kernel_time": 0.489717, "process_mem_max_rss": "112608", "process_out_blocks": "2129", "process_user_time": 2.800897}
[0m16:57:19.688716 [debug] [MainThread]: Command `dbt debug` failed at 16:57:19.688489 after 0.69 seconds
[0m16:57:19.689889 [debug] [MainThread]: Connection 'debug' was left open.
[0m16:57:19.691255 [debug] [MainThread]: On debug: Close
[0m16:57:19.692573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375b4f9d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f376005cf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375b1cfcd0>]}
[0m16:57:19.693668 [debug] [MainThread]: Flushing usage events
[0m16:57:29.756559 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:59:37.273806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff6c799450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff6c6a9950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff6c798210>]}


============================== 16:59:37.280263 | 0498fbe9-82b4-4c7f-83af-9d9e35f476e6 ==============================
[0m16:59:37.280263 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:59:37.281655 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'quiet': 'False', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'static_parser': 'True', 'use_colors': 'True', 'invocation_command': 'dbt debug', 'log_cache_events': 'False', 'write_json': 'True', 'empty': 'None', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'debug': 'False', 'cache_selected_only': 'False', 'log_path': '/dbt/logs', 'introspect': 'True', 'profiles_dir': '/dbt', 'version_check': 'True', 'partial_parse': 'True', 'printer_width': '80', 'indirect_selection': 'eager', 'target_path': 'None', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m16:59:37.296783 [info ] [MainThread]: dbt version: 1.10.13
[0m16:59:37.298178 [info ] [MainThread]: python version: 3.11.14
[0m16:59:37.299830 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m16:59:37.301250 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m16:59:37.399587 [info ] [MainThread]: Using profiles dir at /dbt
[0m16:59:37.401023 [info ] [MainThread]: Using profiles.yml file at /dbt/profiles.yml
[0m16:59:37.402828 [info ] [MainThread]: Using dbt_project.yml file at /dbt/dbt_project.yml
[0m16:59:37.404849 [info ] [MainThread]: adapter type: clickhouse
[0m16:59:37.406274 [info ] [MainThread]: adapter version: 1.9.5
[0m16:59:37.571670 [info ] [MainThread]: Configuration:
[0m16:59:37.572829 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m16:59:37.573885 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:59:37.575033 [info ] [MainThread]: Required dependencies:
[0m16:59:37.576257 [debug] [MainThread]: Executing "git --help"
[0m16:59:37.579368 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m16:59:37.580478 [debug] [MainThread]: STDERR: "b''"
[0m16:59:37.581063 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m16:59:37.581793 [info ] [MainThread]: Connection:
[0m16:59:37.582833 [info ] [MainThread]:   driver: None
[0m16:59:37.584308 [info ] [MainThread]:   host: clickhouse-server
[0m16:59:37.585930 [info ] [MainThread]:   port: 8123
[0m16:59:37.587356 [info ] [MainThread]:   user: default
[0m16:59:37.588746 [info ] [MainThread]:   schema: default
[0m16:59:37.590237 [info ] [MainThread]:   retries: 1
[0m16:59:37.591947 [info ] [MainThread]:   cluster: None
[0m16:59:37.593568 [info ] [MainThread]:   database_engine: None
[0m16:59:37.595125 [info ] [MainThread]:   cluster_mode: False
[0m16:59:37.596716 [info ] [MainThread]:   secure: False
[0m16:59:37.598277 [info ] [MainThread]:   verify: True
[0m16:59:37.600023 [info ] [MainThread]:   client_cert: None
[0m16:59:37.601606 [info ] [MainThread]:   client_cert_key: None
[0m16:59:37.603103 [info ] [MainThread]:   connect_timeout: 10
[0m16:59:37.604896 [info ] [MainThread]:   send_receive_timeout: 300
[0m16:59:37.606301 [info ] [MainThread]:   sync_request_timeout: 5
[0m16:59:37.608078 [info ] [MainThread]:   compress_block_size: 1048576
[0m16:59:37.609366 [info ] [MainThread]:   compression: 
[0m16:59:37.610630 [info ] [MainThread]:   check_exchange: True
[0m16:59:37.612873 [info ] [MainThread]:   custom_settings: None
[0m16:59:37.614401 [info ] [MainThread]:   use_lw_deletes: False
[0m16:59:37.615915 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m16:59:37.617588 [info ] [MainThread]:   tcp_keepalive: False
[0m16:59:37.619249 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:59:37.702189 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m16:59:37.703684 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:59:37.863305 [info ] [MainThread]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m16:59:37.864732 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m16:59:37.870129 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:59:37.907754 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m16:59:37.909161 [info ] [MainThread]: [32mAll checks passed![0m
[0m16:59:37.912096 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.7339778, "process_in_blocks": "0", "process_kernel_time": 0.879408, "process_mem_max_rss": "113124", "process_out_blocks": "2133", "process_user_time": 2.947063}
[0m16:59:37.913092 [debug] [MainThread]: Command `dbt debug` succeeded at 16:59:37.912938 after 0.74 seconds
[0m16:59:37.913725 [debug] [MainThread]: Connection 'debug' was left open.
[0m16:59:37.914405 [debug] [MainThread]: On debug: Close
[0m16:59:37.915116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff6c69d250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff6c69f7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff6ca02150>]}
[0m16:59:37.915835 [debug] [MainThread]: Flushing usage events
[0m16:59:48.015991 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:01:08.343627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c67d6fd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c680bd6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c67f13010>]}


============================== 17:01:08.352267 | 6a1ad771-77a4-4a55-bd0b-dc379a22a3a8 ==============================
[0m17:01:08.352267 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:01:08.354348 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'version_check': 'True', 'log_path': '/dbt/logs', 'profiles_dir': '/dbt', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'introspect': 'True', 'log_format': 'default', 'printer_width': '80', 'use_colors': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'debug': 'False', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'write_json': 'True', 'quiet': 'False', 'empty': 'False', 'target_path': 'None', 'partial_parse': 'True', 'log_cache_events': 'False', 'indirect_selection': 'eager'}
[0m17:01:08.634131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6a1ad771-77a4-4a55-bd0b-dc379a22a3a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c67d30c10>]}
[0m17:01:08.714589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6a1ad771-77a4-4a55-bd0b-dc379a22a3a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c684a0990>]}
[0m17:01:08.716401 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m17:01:08.809563 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:01:08.812738 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m17:01:08.814363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6a1ad771-77a4-4a55-bd0b-dc379a22a3a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c67d30c10>]}
[0m17:01:09.914475 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.clickhouse_dbt_demo
[0m17:01:09.921057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6a1ad771-77a4-4a55-bd0b-dc379a22a3a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c69d26b50>]}
[0m17:01:10.014851 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:01:10.019108 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:01:10.049043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6a1ad771-77a4-4a55-bd0b-dc379a22a3a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c67a478d0>]}
[0m17:01:10.050201 [info ] [MainThread]: Found 485 macros
[0m17:01:10.051530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a1ad771-77a4-4a55-bd0b-dc379a22a3a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c67b88590>]}
[0m17:01:10.055046 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m17:01:10.056720 [debug] [MainThread]: Command end result
[0m17:01:10.115367 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:01:10.119477 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:01:10.124709 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m17:01:10.127066 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.876244, "process_in_blocks": "0", "process_kernel_time": 0.607378, "process_mem_max_rss": "111060", "process_out_blocks": "3151", "process_user_time": 3.955291}
[0m17:01:10.128026 [debug] [MainThread]: Command `dbt run` succeeded at 17:01:10.127866 after 1.88 seconds
[0m17:01:10.129092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c6c9d5590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c6c9fb9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c681dd490>]}
[0m17:01:10.130619 [debug] [MainThread]: Flushing usage events
[0m17:01:20.215260 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:23:54.863663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01130a7a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01103a0b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01103a12d0>]}


============================== 17:23:54.870425 | 49b174bc-192a-4911-9b8a-15371f2c6f9b ==============================
[0m17:23:54.870425 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:23:54.871998 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'printer_width': '80', 'use_colors': 'True', 'warn_error': 'None', 'empty': 'False', 'target_path': 'None', 'fail_fast': 'False', 'log_format': 'default', 'no_print': 'None', 'write_json': 'True', 'static_parser': 'True', 'indirect_selection': 'eager', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'debug': 'False', 'profiles_dir': '/dbt', 'log_path': '/dbt/logs', 'invocation_command': 'dbt run --select stg_dim_customer', 'log_cache_events': 'False'}
[0m17:23:55.080153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '49b174bc-192a-4911-9b8a-15371f2c6f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0110405810>]}
[0m17:23:55.151473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '49b174bc-192a-4911-9b8a-15371f2c6f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0110cec950>]}
[0m17:23:55.153392 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m17:23:55.243453 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:23:55.339279 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m17:23:55.340761 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://models/staging/stg_dim_customer.sql
[0m17:23:55.634230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49b174bc-192a-4911-9b8a-15371f2c6f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01101f2b90>]}
[0m17:23:55.717357 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:23:55.721003 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:23:55.741242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49b174bc-192a-4911-9b8a-15371f2c6f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010fddbd90>]}
[0m17:23:55.742676 [info ] [MainThread]: Found 1 model, 485 macros
[0m17:23:55.743833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49b174bc-192a-4911-9b8a-15371f2c6f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010fdd1850>]}
[0m17:23:55.747391 [info ] [MainThread]: 
[0m17:23:55.749340 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:23:55.751685 [info ] [MainThread]: 
[0m17:23:55.754006 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m17:23:55.760870 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m17:23:55.773849 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:23:56.093086 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:23:56.094324 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m17:23:56.103319 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:23:56.129561 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m17:23:56.137734 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:23:56.222433 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:23:56.224211 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m17:23:56.315006 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.09 seconds
[0m17:23:56.319293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49b174bc-192a-4911-9b8a-15371f2c6f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010f531250>]}
[0m17:23:56.336723 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:23:56.337891 [info ] [Thread-1 (]: 1 of 1 START sql view model `default`.`stg_dim_customer` ....................... [RUN]
[0m17:23:56.339170 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m17:23:56.340819 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:23:56.351094 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:23:56.358866 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:23:56.387008 [debug] [Thread-1 (]: Creating new relation stg_dim_customer
[0m17:23:56.405147 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:23:56.412381 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */


  create or replace view `default`.`stg_dim_customer` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM read_csv_auto('/var/lib/clickhouse/user_files/dim_customer.csv')
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:23:56.431206 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */


  create or replace view `default`.`stg_dim_customer` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM read_csv_auto('/var/lib/clickhouse/user_files/dim_customer.csv')
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m17:23:56.438893 [debug] [Thread-1 (]: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 46, server response: Code: 46. DB::Exception: Unknown table function read_csv_auto. (UNKNOWN_FUNCTION) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:23:56.441266 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49b174bc-192a-4911-9b8a-15371f2c6f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010e948250>]}
[0m17:23:56.442870 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model `default`.`stg_dim_customer` .............. [[31mERROR[0m in 0.10s]
[0m17:23:56.444827 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:23:56.446776 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.stg_dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 46, server response: Code: 46. DB::Exception: Unknown table function read_csv_auto. (UNKNOWN_FUNCTION) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql.
[0m17:23:56.453211 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:23:56.455065 [debug] [MainThread]: Connection 'list_' was left open.
[0m17:23:56.456256 [debug] [MainThread]: On list_: Close
[0m17:23:56.457373 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.stg_dim_customer' was left open.
[0m17:23:56.459166 [debug] [MainThread]: On model.clickhouse_dbt_demo.stg_dim_customer: Close
[0m17:23:56.460334 [info ] [MainThread]: 
[0m17:23:56.461319 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.71 seconds (0.71s).
[0m17:23:56.463788 [debug] [MainThread]: Command end result
[0m17:23:56.523645 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:23:56.527188 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:23:56.536905 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m17:23:56.538021 [info ] [MainThread]: 
[0m17:23:56.538966 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m17:23:56.539873 [info ] [MainThread]: 
[0m17:23:56.541287 [error] [MainThread]: [31mFailure in model stg_dim_customer (models/staging/stg_dim_customer.sql)[0m
[0m17:23:56.544114 [error] [MainThread]:   Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 46, server response: Code: 46. DB::Exception: Unknown table function read_csv_auto. (UNKNOWN_FUNCTION) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:23:56.546762 [info ] [MainThread]: 
[0m17:23:56.549385 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:23:56.551186 [info ] [MainThread]: 
[0m17:23:56.552792 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m17:23:56.558390 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.7723585, "process_in_blocks": "0", "process_kernel_time": 0.453391, "process_mem_max_rss": "122696", "process_out_blocks": "3110", "process_user_time": 2.791667}
[0m17:23:56.560374 [debug] [MainThread]: Command `dbt run` failed at 17:23:56.560198 after 1.77 seconds
[0m17:23:56.561296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01115e0990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0114d390d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0110645e10>]}
[0m17:23:56.563204 [debug] [MainThread]: Flushing usage events
[0m17:23:57.225959 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:25:49.406003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2abf599050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2abaedd590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2abac4cb10>]}


============================== 17:25:49.410074 | 457230bb-536c-4e2c-ad80-6247e01464f6 ==============================
[0m17:25:49.410074 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:25:49.411437 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'log_path': '/dbt/logs', 'warn_error': 'None', 'invocation_command': 'dbt run --select stg_dim_customer.sql', 'use_experimental_parser': 'False', 'debug': 'False', 'log_format': 'default', 'introspect': 'True', 'profiles_dir': '/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'version_check': 'True', 'no_print': 'None', 'partial_parse': 'True', 'target_path': 'None', 'indirect_selection': 'eager', 'quiet': 'False', 'empty': 'False', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m17:25:49.610440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '457230bb-536c-4e2c-ad80-6247e01464f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2abaa36710>]}
[0m17:25:49.682936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '457230bb-536c-4e2c-ad80-6247e01464f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2abb1a08d0>]}
[0m17:25:49.684987 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m17:25:49.766552 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:25:49.869705 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:25:49.870967 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/staging/stg_dim_customer.sql
[0m17:25:50.138226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '457230bb-536c-4e2c-ad80-6247e01464f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aba7f3d50>]}
[0m17:25:50.220006 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:25:50.223684 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:25:50.242334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '457230bb-536c-4e2c-ad80-6247e01464f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aba511550>]}
[0m17:25:50.243270 [info ] [MainThread]: Found 1 model, 485 macros
[0m17:25:50.244233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '457230bb-536c-4e2c-ad80-6247e01464f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aba6503d0>]}
[0m17:25:50.247972 [info ] [MainThread]: 
[0m17:25:50.250345 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:25:50.253400 [info ] [MainThread]: 
[0m17:25:50.256297 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m17:25:50.258692 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m17:25:50.276303 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:25:50.454271 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:25:50.455359 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m17:25:50.467178 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:25:50.486463 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m17:25:50.494202 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:25:50.592493 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:25:50.594128 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m17:25:50.610107 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:25:50.617834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '457230bb-536c-4e2c-ad80-6247e01464f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab95248d0>]}
[0m17:25:50.626661 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:25:50.628733 [info ] [Thread-1 (]: 1 of 1 START sql view model `default`.`stg_dim_customer` ....................... [RUN]
[0m17:25:50.630625 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m17:25:50.632494 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:25:50.648224 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:25:50.651635 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:25:50.684472 [debug] [Thread-1 (]: Creating new relation stg_dim_customer
[0m17:25:50.704171 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:25:50.708846 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */


  create or replace view `default`.`stg_dim_customer` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:25:50.734868 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:25:50.762356 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '457230bb-536c-4e2c-ad80-6247e01464f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2aba8c8fd0>]}
[0m17:25:50.763647 [info ] [Thread-1 (]: 1 of 1 OK created sql view model `default`.`stg_dim_customer` .................. [[32mOK[0m in 0.13s]
[0m17:25:50.765590 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:25:50.771045 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:25:50.772744 [debug] [MainThread]: Connection 'list_' was left open.
[0m17:25:50.774972 [debug] [MainThread]: On list_: Close
[0m17:25:50.777416 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.stg_dim_customer' was left open.
[0m17:25:50.779036 [debug] [MainThread]: On model.clickhouse_dbt_demo.stg_dim_customer: Close
[0m17:25:50.780805 [info ] [MainThread]: 
[0m17:25:50.782088 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.52 seconds (0.52s).
[0m17:25:50.785762 [debug] [MainThread]: Command end result
[0m17:25:50.839523 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:25:50.843347 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:25:50.852088 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m17:25:50.852912 [info ] [MainThread]: 
[0m17:25:50.853716 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:25:50.854918 [info ] [MainThread]: 
[0m17:25:50.856037 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m17:25:50.858059 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.521691, "process_in_blocks": "0", "process_kernel_time": 0.325842, "process_mem_max_rss": "122056", "process_out_blocks": "3081", "process_user_time": 2.808355}
[0m17:25:50.859066 [debug] [MainThread]: Command `dbt run` succeeded at 17:25:50.858913 after 1.52 seconds
[0m17:25:50.859799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2abaa8e010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2abaa8e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2abaa8df10>]}
[0m17:25:50.860718 [debug] [MainThread]: Flushing usage events
[0m17:25:51.421587 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:50:48.471909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8374c290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff83709d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff839dd710>]}


============================== 17:50:48.478517 | 92608cc0-bacb-40e9-9773-7891624a673c ==============================
[0m17:50:48.478517 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:50:48.480322 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'invocation_command': 'dbt seed', 'use_experimental_parser': 'False', 'debug': 'False', 'log_path': '/dbt/logs', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'target_path': 'None', 'cache_selected_only': 'False', 'use_colors': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'printer_width': '80', 'quiet': 'False', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'empty': 'None', 'partial_parse': 'True', 'log_format': 'default', 'write_json': 'True', 'introspect': 'True', 'profiles_dir': '/dbt'}
[0m17:50:48.706071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '92608cc0-bacb-40e9-9773-7891624a673c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff83570dd0>]}
[0m17:50:48.791490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '92608cc0-bacb-40e9-9773-7891624a673c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff83ca0890>]}
[0m17:50:48.792802 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m17:50:48.874711 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:50:49.002367 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 11 files added, 0 files changed.
[0m17:50:49.003816 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://seeds/dim_store.csv
[0m17:50:49.004833 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://seeds/dim_payment.csv
[0m17:50:49.005815 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://models/marts/dim_product.sql
[0m17:50:49.006694 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://models/marts/dim_store.sql
[0m17:50:49.007591 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://models/marts/dim_supplier.sql
[0m17:50:49.008420 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://models/marts/dim_date.sql
[0m17:50:49.009399 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://models/marts/dim_customer.sql
[0m17:50:49.010259 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://models/marts/dim_payment.sql
[0m17:50:49.011115 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://seeds/dim_product.csv
[0m17:50:49.011969 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://seeds/dim_date.csv
[0m17:50:49.012915 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://seeds/dim_supplier.csv
[0m17:50:49.458767 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two resources with the database representation "`default`.`dim_store`".
  dbt cannot create two resources with identical database representations. To fix this,
  change the configuration of one of these resources:
  - model.clickhouse_dbt_demo.dim_store (models/marts/dim_store.sql)
  - seed.clickhouse_dbt_demo.dim_store (seeds/dim_store.csv)
[0m17:50:49.461016 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 1.1331537, "process_in_blocks": "0", "process_kernel_time": 0.616313, "process_mem_max_rss": "116568", "process_out_blocks": "1059", "process_user_time": 3.252823}
[0m17:50:49.462446 [debug] [MainThread]: Command `dbt seed` failed at 17:50:49.462241 after 1.13 seconds
[0m17:50:49.463400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff83712a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8339ab50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff83836290>]}
[0m17:50:49.464649 [debug] [MainThread]: Flushing usage events
[0m17:50:50.118660 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:51:38.197233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39413a1950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39411e9d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39413161d0>]}


============================== 17:51:38.200893 | 3850c606-2782-433a-b239-ac810ffc0e49 ==============================
[0m17:51:38.200893 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:51:38.202045 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'introspect': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'log_path': '/dbt/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': '/dbt', 'printer_width': '80', 'quiet': 'False', 'cache_selected_only': 'False', 'invocation_command': 'dbt seed', 'version_check': 'True', 'write_json': 'True', 'debug': 'False', 'use_colors': 'True', 'target_path': 'None', 'indirect_selection': 'eager', 'no_print': 'None', 'log_cache_events': 'False', 'fail_fast': 'False', 'empty': 'None', 'partial_parse': 'True', 'static_parser': 'True'}
[0m17:51:38.403588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3850c606-2782-433a-b239-ac810ffc0e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3941131e90>]}
[0m17:51:38.473921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3850c606-2782-433a-b239-ac810ffc0e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39417aafd0>]}
[0m17:51:38.475461 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m17:51:38.555257 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:51:38.693205 [debug] [MainThread]: Partial parsing enabled: 5 files deleted, 5 files added, 0 files changed.
[0m17:51:38.694300 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://seeds/stg_dim_product.csv
[0m17:51:38.695011 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://seeds/stg_dim_supplier.csv
[0m17:51:38.695612 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://seeds/stg_dim_store.csv
[0m17:51:38.696186 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://seeds/stg_dim_payment.csv
[0m17:51:38.696768 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://seeds/stg_dim_date.csv
[0m17:51:38.697698 [debug] [MainThread]: Partial parsing: deleted file: clickhouse_dbt_demo://seeds/dim_store.csv
[0m17:51:38.698464 [debug] [MainThread]: Partial parsing: deleted file: clickhouse_dbt_demo://seeds/dim_payment.csv
[0m17:51:38.699029 [debug] [MainThread]: Partial parsing: deleted file: clickhouse_dbt_demo://seeds/dim_date.csv
[0m17:51:38.699556 [debug] [MainThread]: Partial parsing: deleted file: clickhouse_dbt_demo://seeds/dim_supplier.csv
[0m17:51:38.700231 [debug] [MainThread]: Partial parsing: deleted file: clickhouse_dbt_demo://seeds/dim_product.csv
[0m17:51:38.975276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3850c606-2782-433a-b239-ac810ffc0e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3940d16890>]}
[0m17:51:39.069852 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:51:39.073478 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:51:39.095275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3850c606-2782-433a-b239-ac810ffc0e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3940b54910>]}
[0m17:51:39.096245 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m17:51:39.097070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3850c606-2782-433a-b239-ac810ffc0e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3940c3f850>]}
[0m17:51:39.099710 [info ] [MainThread]: 
[0m17:51:39.100631 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:51:39.101583 [info ] [MainThread]: 
[0m17:51:39.102672 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m17:51:39.111174 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m17:51:39.123221 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:51:39.398252 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:51:39.399328 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m17:51:39.406137 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:51:39.448864 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m17:51:39.459162 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m17:51:39.473214 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:51:39.480268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3850c606-2782-433a-b239-ac810ffc0e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3940c91ad0>]}
[0m17:51:39.486120 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_date
[0m17:51:39.487652 [info ] [Thread-1 (]: 1 of 5 START seed file `default`.`stg_dim_date` ................................ [RUN]
[0m17:51:39.488927 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now seed.clickhouse_dbt_demo.stg_dim_date)
[0m17:51:39.490302 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_date
[0m17:51:39.491573 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_date
[0m17:51:39.570451 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */

    create table `default`.`stg_dim_date` 
   ("DateKey" Int32,"FullDate" Date,"Year" Int32,"Month" Int32,"Day" Int32,"DayOfWeek" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m17:51:39.601713 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:51:39.611893 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */
insert into `default`.`stg_dim_date` ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")
      
      format CSV
      1,2025-09-18,2025,9,18,Thursday
2,2025-09-19,2025,9,19,Friday
3,2025-09-20,2025,9,20,Saturday
...
[0m17:51:39.636286 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:51:39.641971 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_date"
[0m17:51:39.673686 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3850c606-2782-433a-b239-ac810ffc0e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f393fead250>]}
[0m17:51:39.675245 [info ] [Thread-1 (]: 1 of 5 OK loaded seed file default.stg_dim_date ................................ [[32mINSERT 3[0m in 0.18s]
[0m17:51:39.677103 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_date
[0m17:51:39.678433 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m17:51:39.679764 [info ] [Thread-1 (]: 2 of 5 START seed file `default`.`stg_dim_payment` ............................. [RUN]
[0m17:51:39.681280 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_date, now seed.clickhouse_dbt_demo.stg_dim_payment)
[0m17:51:39.682647 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_payment
[0m17:51:39.683472 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_payment
[0m17:51:39.689227 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */

    create table `default`.`stg_dim_payment` 
   ("PaymentKey" Int32,"PaymentType" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m17:51:39.709629 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:51:39.712591 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */
insert into `default`.`stg_dim_payment` ("PaymentKey", "PaymentType")
      
      format CSV
      1,Cash
2,Card
3,Voucher
...
[0m17:51:39.739969 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:51:39.741398 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_payment"
[0m17:51:39.746481 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3850c606-2782-433a-b239-ac810ffc0e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f393fd2d510>]}
[0m17:51:39.747376 [info ] [Thread-1 (]: 2 of 5 OK loaded seed file default.stg_dim_payment ............................. [[32mINSERT 3[0m in 0.07s]
[0m17:51:39.748470 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m17:51:39.749319 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_product
[0m17:51:39.750136 [info ] [Thread-1 (]: 3 of 5 START seed file `default`.`stg_dim_product` ............................. [RUN]
[0m17:51:39.751055 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_payment, now seed.clickhouse_dbt_demo.stg_dim_product)
[0m17:51:39.751868 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_product
[0m17:51:39.752737 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_product
[0m17:51:39.761777 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */

    create table `default`.`stg_dim_product` 
   ("ProductKey" Int32,"ProductName" String,"Category" String,"Brand" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m17:51:39.787948 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:51:39.790680 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */
insert into `default`.`stg_dim_product` ("ProductKey", "ProductName", "Category", "Brand")
      
      format CSV
      1,Apple,Fruit,FreshFarm
2,Banana,Fruit,Tropicana
3,Milk,Dairy,DairyBest
4,Bread,Bakery,BakeHouse
...
[0m17:51:39.813115 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:51:39.815082 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_product"
[0m17:51:39.823333 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3850c606-2782-433a-b239-ac810ffc0e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f393fec4710>]}
[0m17:51:39.825123 [info ] [Thread-1 (]: 3 of 5 OK loaded seed file default.stg_dim_product ............................. [[32mINSERT 4[0m in 0.07s]
[0m17:51:39.827040 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_product
[0m17:51:39.828819 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_store
[0m17:51:39.830637 [info ] [Thread-1 (]: 4 of 5 START seed file `default`.`stg_dim_store` ............................... [RUN]
[0m17:51:39.832606 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_product, now seed.clickhouse_dbt_demo.stg_dim_store)
[0m17:51:39.833580 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_store
[0m17:51:39.834474 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_store
[0m17:51:39.840392 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */

    create table `default`.`stg_dim_store` 
   ("StoreKey" Int32,"StoreName" String,"City" String,"Region" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m17:51:39.860765 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:51:39.864384 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */
insert into `default`.`stg_dim_store` ("StoreKey", "StoreName", "City", "Region")
      
      format CSV
      1,SuperMart Downtown,Tallinn,North
2,SuperMart Suburb,Tartu,South
...
[0m17:51:39.891580 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:51:39.893080 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_store"
[0m17:51:39.896998 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3850c606-2782-433a-b239-ac810ffc0e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f393fec3e10>]}
[0m17:51:39.898244 [info ] [Thread-1 (]: 4 of 5 OK loaded seed file default.stg_dim_store ............................... [[32mINSERT 2[0m in 0.06s]
[0m17:51:39.899705 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_store
[0m17:51:39.900645 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m17:51:39.901755 [info ] [Thread-1 (]: 5 of 5 START seed file `default`.`stg_dim_supplier` ............................ [RUN]
[0m17:51:39.903137 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_store, now seed.clickhouse_dbt_demo.stg_dim_supplier)
[0m17:51:39.904527 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m17:51:39.905831 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m17:51:39.914778 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */

    create table `default`.`stg_dim_supplier` 
   ("SupplierKey" Int32,"SupplierName" String,"ContactInfo" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m17:51:39.941889 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:51:39.944361 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */
insert into `default`.`stg_dim_supplier` ("SupplierKey", "SupplierName", "ContactInfo")
      
      format CSV
      1,FreshFarm Supplier,fresh@farm.com
2,Tropicana Supplier,contact@tropicana.com
3,DairyBest Supplier,sales@dairybest.com
4,BakeHouse Supplier,info@bakehouse.com
...
[0m17:51:39.969347 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:51:39.971217 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_supplier"
[0m17:51:39.978837 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3850c606-2782-433a-b239-ac810ffc0e49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f393fdfc110>]}
[0m17:51:39.980412 [info ] [Thread-1 (]: 5 of 5 OK loaded seed file default.stg_dim_supplier ............................ [[32mINSERT 4[0m in 0.08s]
[0m17:51:39.982147 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m17:51:39.985874 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:51:39.986763 [debug] [MainThread]: Connection 'seed.clickhouse_dbt_demo.stg_dim_supplier' was left open.
[0m17:51:39.987669 [debug] [MainThread]: On seed.clickhouse_dbt_demo.stg_dim_supplier: Close
[0m17:51:39.988873 [info ] [MainThread]: 
[0m17:51:39.989927 [info ] [MainThread]: Finished running 5 seeds in 0 hours 0 minutes and 0.89 seconds (0.89s).
[0m17:51:39.991715 [debug] [MainThread]: Command end result
[0m17:51:40.054502 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:51:40.060170 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:51:40.073697 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m17:51:40.074896 [info ] [MainThread]: 
[0m17:51:40.076308 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:51:40.078354 [info ] [MainThread]: 
[0m17:51:40.079608 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m17:51:40.082324 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 1.9529421, "process_in_blocks": "0", "process_kernel_time": 0.422801, "process_mem_max_rss": "121044", "process_out_blocks": "3236", "process_user_time": 3.091927}
[0m17:51:40.084293 [debug] [MainThread]: Command `dbt seed` succeeded at 17:51:40.084097 after 1.96 seconds
[0m17:51:40.085277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3941253cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3943f64250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39414c0810>]}
[0m17:51:40.086328 [debug] [MainThread]: Flushing usage events
[0m17:51:40.631578 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:53:56.569785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978c344490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978c301610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978c167f90>]}


============================== 17:53:56.574633 | 9e9d3d4f-e192-47f7-b111-841e3c3bcc72 ==============================
[0m17:53:56.574633 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:53:56.575882 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/dbt', 'debug': 'False', 'no_print': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'warn_error': 'None', 'invocation_command': 'dbt run --select dim_customer', 'log_cache_events': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/dbt/logs', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'fail_fast': 'False', 'version_check': 'True', 'empty': 'False', 'use_experimental_parser': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'use_colors': 'True'}
[0m17:53:56.774817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9e9d3d4f-e192-47f7-b111-841e3c3bcc72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978c8c2610>]}
[0m17:53:56.869296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9e9d3d4f-e192-47f7-b111-841e3c3bcc72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978c866b10>]}
[0m17:53:56.872863 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m17:53:56.966821 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:53:57.110425 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m17:53:57.111872 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/dim_customer.sql
[0m17:53:57.112938 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/dim_payment.sql
[0m17:53:57.113892 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/dim_product.sql
[0m17:53:57.431270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e9d3d4f-e192-47f7-b111-841e3c3bcc72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978bf16890>]}
[0m17:53:57.543632 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:53:57.547252 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:53:57.567690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e9d3d4f-e192-47f7-b111-841e3c3bcc72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978bbecd50>]}
[0m17:53:57.568722 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m17:53:57.569661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e9d3d4f-e192-47f7-b111-841e3c3bcc72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978bb6b250>]}
[0m17:53:57.573770 [info ] [MainThread]: 
[0m17:53:57.576667 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:53:57.578264 [info ] [MainThread]: 
[0m17:53:57.580245 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m17:53:57.583129 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m17:53:57.597947 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:53:57.806200 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:53:57.808369 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m17:53:57.824150 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:53:57.853155 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m17:53:57.864117 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m17:53:57.877782 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:53:57.884731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e9d3d4f-e192-47f7-b111-841e3c3bcc72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978c0bb350>]}
[0m17:53:57.889924 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m17:53:57.891154 [info ] [Thread-1 (]: 1 of 1 START sql view model `default`.`dim_customer` ........................... [RUN]
[0m17:53:57.892590 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_customer)
[0m17:53:57.894762 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_customer
[0m17:53:57.909285 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_customer"
[0m17:53:57.913484 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_customer
[0m17:53:57.929927 [debug] [Thread-1 (]: Creating new relation dim_customer
[0m17:53:57.946985 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_customer"
[0m17:53:57.951617 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */


  create or replace view `default`.`dim_customer` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:53:57.966685 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:53:57.993104 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e9d3d4f-e192-47f7-b111-841e3c3bcc72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978ba61dd0>]}
[0m17:53:57.994503 [info ] [Thread-1 (]: 1 of 1 OK created sql view model `default`.`dim_customer` ...................... [[32mOK[0m in 0.10s]
[0m17:53:57.995742 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m17:53:58.001529 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:53:58.003674 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.dim_customer' was left open.
[0m17:53:58.004960 [debug] [MainThread]: On model.clickhouse_dbt_demo.dim_customer: Close
[0m17:53:58.006401 [info ] [MainThread]: 
[0m17:53:58.007642 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.43 seconds (0.43s).
[0m17:53:58.010189 [debug] [MainThread]: Command end result
[0m17:53:58.070839 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:53:58.076237 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:53:58.086239 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m17:53:58.087126 [info ] [MainThread]: 
[0m17:53:58.088072 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:53:58.089494 [info ] [MainThread]: 
[0m17:53:58.090665 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m17:53:58.092965 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.5923176, "process_in_blocks": "0", "process_kernel_time": 0.270774, "process_mem_max_rss": "121432", "process_out_blocks": "3211", "process_user_time": 2.847201}
[0m17:53:58.093999 [debug] [MainThread]: Command `dbt run` succeeded at 17:53:58.093830 after 1.59 seconds
[0m17:53:58.094729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978c1884d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978c18a890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9790cc8650>]}
[0m17:53:58.095467 [debug] [MainThread]: Flushing usage events
[0m17:53:58.710342 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:54:14.856930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c7fa8b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c7fa8e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c80c43d0>]}


============================== 17:54:14.863002 | fefd576c-7937-4e9b-8ee7-211834257208 ==============================
[0m17:54:14.863002 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:54:14.865061 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'log_path': '/dbt/logs', 'log_cache_events': 'False', 'debug': 'False', 'write_json': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'profiles_dir': '/dbt', 'target_path': 'None', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'quiet': 'False', 'use_colors': 'True', 'version_check': 'True', 'static_parser': 'True', 'log_format': 'default', 'warn_error': 'None', 'partial_parse': 'True', 'no_print': 'None', 'empty': 'False'}
[0m17:54:15.118091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c7fcfd10>]}
[0m17:54:15.189498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c8546590>]}
[0m17:54:15.191012 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m17:54:15.272273 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:54:15.439494 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:54:15.440675 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:54:15.486295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c7a9ac50>]}
[0m17:54:15.591705 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:54:15.595198 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:54:15.623529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c7a99990>]}
[0m17:54:15.625963 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m17:54:15.628422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c7e197d0>]}
[0m17:54:15.633299 [info ] [MainThread]: 
[0m17:54:15.634723 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:54:15.635787 [info ] [MainThread]: 
[0m17:54:15.637356 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m17:54:15.646363 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m17:54:15.664783 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:54:15.814537 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:54:15.816417 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m17:54:15.827282 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:54:15.928911 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m17:54:15.936862 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m17:54:15.945957 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:54:15.952651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c7869290>]}
[0m17:54:15.961040 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m17:54:15.962954 [info ] [Thread-1 (]: 1 of 7 START sql view model `default`.`dim_date` ............................... [RUN]
[0m17:54:15.965041 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m17:54:15.966437 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m17:54:15.977876 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m17:54:15.983346 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m17:54:16.019341 [debug] [Thread-1 (]: Creating new relation dim_date
[0m17:54:16.050557 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m17:54:16.057951 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */


  create or replace view `default`.`dim_date` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:54:16.128133 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m17:54:16.185782 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c6cf5b90>]}
[0m17:54:16.187072 [info ] [Thread-1 (]: 1 of 7 OK created sql view model `default`.`dim_date` .......................... [[32mOK[0m in 0.22s]
[0m17:54:16.188438 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m17:54:16.189682 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m17:54:16.190828 [info ] [Thread-1 (]: 2 of 7 START sql view model `default`.`dim_payment` ............................ [RUN]
[0m17:54:16.192031 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m17:54:16.193060 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m17:54:16.196914 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m17:54:16.200679 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m17:54:16.206837 [debug] [Thread-1 (]: Creating new relation dim_payment
[0m17:54:16.210259 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m17:54:16.214776 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */


  create or replace view `default`.`dim_payment` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_product`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:54:16.233937 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:54:16.238226 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c8005310>]}
[0m17:54:16.239879 [info ] [Thread-1 (]: 2 of 7 OK created sql view model `default`.`dim_payment` ....................... [[32mOK[0m in 0.05s]
[0m17:54:16.269295 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m17:54:16.270965 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m17:54:16.272526 [info ] [Thread-1 (]: 3 of 7 START sql view model `default`.`dim_product` ............................ [RUN]
[0m17:54:16.274051 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m17:54:16.275493 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m17:54:16.281208 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m17:54:16.284508 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m17:54:16.289363 [debug] [Thread-1 (]: Creating new relation dim_product
[0m17:54:16.291177 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m17:54:16.293858 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */


  create or replace view `default`.`dim_product` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_product`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:54:16.307327 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:54:16.311856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c7eb7610>]}
[0m17:54:16.314223 [info ] [Thread-1 (]: 3 of 7 OK created sql view model `default`.`dim_product` ....................... [[32mOK[0m in 0.04s]
[0m17:54:16.316811 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m17:54:16.318239 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m17:54:16.320067 [info ] [Thread-1 (]: 4 of 7 START sql view model `default`.`dim_store` .............................. [RUN]
[0m17:54:16.322011 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m17:54:16.323457 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m17:54:16.330296 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m17:54:16.334094 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m17:54:16.337386 [debug] [Thread-1 (]: Creating new relation dim_store
[0m17:54:16.339448 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m17:54:16.344350 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */


  create or replace view `default`.`dim_store` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:54:16.363115 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:54:16.368410 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c6c17f50>]}
[0m17:54:16.371316 [info ] [Thread-1 (]: 4 of 7 OK created sql view model `default`.`dim_store` ......................... [[32mOK[0m in 0.05s]
[0m17:54:16.373802 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m17:54:16.375545 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m17:54:16.377405 [info ] [Thread-1 (]: 5 of 7 START sql view model `default`.`dim_supplier` ........................... [RUN]
[0m17:54:16.379093 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m17:54:16.380447 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m17:54:16.384134 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m17:54:16.387748 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m17:54:16.391276 [debug] [Thread-1 (]: Creating new relation dim_supplier
[0m17:54:16.393249 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m17:54:16.396820 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */


  create or replace view `default`.`dim_supplier` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:54:16.414328 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:54:16.422799 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c6c154d0>]}
[0m17:54:16.425646 [info ] [Thread-1 (]: 5 of 7 OK created sql view model `default`.`dim_supplier` ...................... [[32mOK[0m in 0.04s]
[0m17:54:16.428294 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m17:54:16.430300 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:54:16.432037 [info ] [Thread-1 (]: 6 of 7 START sql view model `default`.`stg_dim_customer` ....................... [RUN]
[0m17:54:16.433387 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m17:54:16.434810 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:54:16.438239 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:54:16.441913 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:54:16.445229 [debug] [Thread-1 (]: Relation stg_dim_customer already exists, replacing it
[0m17:54:16.463110 [debug] [Thread-1 (]: Model mvs to replace ['stg_dim_customer_mv']
[0m17:54:16.479859 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'default.stg_dim_customer'
  
  ...
[0m17:54:16.501440 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:54:16.508505 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:54:16.513667 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */


  create or replace view `default`.`stg_dim_customer` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:54:16.534742 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */


  create or replace view `default`.`stg_dim_customer` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m17:54:16.545561 [debug] [Thread-1 (]: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_38889fa093071b67_pgisqeyf5d6f7e87.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_38889fa093071b67_pgisqeyf5d6f7e87.c401f8b2-8a4b-43dc-bb7a-38fadb43b7a8.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:54:16.546902 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fefd576c-7937-4e9b-8ee7-211834257208', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c7b9b010>]}
[0m17:54:16.547884 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model `default`.`stg_dim_customer` .............. [[31mERROR[0m in 0.11s]
[0m17:54:16.548940 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:54:16.550063 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.stg_dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_38889fa093071b67_pgisqeyf5d6f7e87.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_38889fa093071b67_pgisqeyf5d6f7e87.c401f8b2-8a4b-43dc-bb7a-38fadb43b7a8.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql.
[0m17:54:16.553365 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m17:54:16.555035 [info ] [Thread-1 (]: 7 of 7 SKIP relation default.dim_customer ...................................... [[33mSKIP[0m]
[0m17:54:16.556876 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m17:54:16.562982 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:54:16.564133 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.stg_dim_customer' was left open.
[0m17:54:16.565446 [debug] [MainThread]: On model.clickhouse_dbt_demo.stg_dim_customer: Close
[0m17:54:16.566815 [info ] [MainThread]: 
[0m17:54:16.568209 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.93 seconds (0.93s).
[0m17:54:16.571537 [debug] [MainThread]: Command end result
[0m17:54:16.641947 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:54:16.645096 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:54:16.654296 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m17:54:16.655740 [info ] [MainThread]: 
[0m17:54:16.657257 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m17:54:16.658871 [info ] [MainThread]: 
[0m17:54:16.660209 [error] [MainThread]: [31mFailure in model stg_dim_customer (models/staging/stg_dim_customer.sql)[0m
[0m17:54:16.661617 [error] [MainThread]:   Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_38889fa093071b67_pgisqeyf5d6f7e87.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_38889fa093071b67_pgisqeyf5d6f7e87.c401f8b2-8a4b-43dc-bb7a-38fadb43b7a8.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:54:16.663758 [info ] [MainThread]: 
[0m17:54:16.665769 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:54:16.667210 [info ] [MainThread]: 
[0m17:54:16.669170 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=7
[0m17:54:16.671790 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.9140021, "process_in_blocks": "0", "process_kernel_time": 0.378643, "process_mem_max_rss": "119472", "process_out_blocks": "2203", "process_user_time": 3.131252}
[0m17:54:16.673251 [debug] [MainThread]: Command `dbt run` failed at 17:54:16.673059 after 1.92 seconds
[0m17:54:16.674405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c6f45890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c6f45510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86c6f79ed0>]}
[0m17:54:16.675817 [debug] [MainThread]: Flushing usage events
[0m17:54:17.339317 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:55:12.894602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d258c3090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d22d2c1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d22d2e1d0>]}


============================== 17:55:12.898220 | 824ec040-145e-458b-97fe-48038b8b5149 ==============================
[0m17:55:12.898220 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:55:12.899514 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'partial_parse': 'True', 'fail_fast': 'False', 'debug': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'profiles_dir': '/dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'log_path': '/dbt/logs', 'introspect': 'True', 'warn_error': 'None', 'target_path': 'None', 'use_experimental_parser': 'False', 'static_parser': 'True', 'version_check': 'True', 'printer_width': '80', 'indirect_selection': 'eager', 'quiet': 'False', 'use_colors': 'True', 'write_json': 'True', 'cache_selected_only': 'False'}
[0m17:55:13.093224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d23a8a950>]}
[0m17:55:13.196461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d231988d0>]}
[0m17:55:13.198197 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m17:55:13.279109 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:55:13.406497 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m17:55:13.407990 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/dim_store.sql
[0m17:55:13.408898 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/dim_supplier.sql
[0m17:55:13.409881 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/dim_date.sql
[0m17:55:13.677794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d2283a890>]}
[0m17:55:13.772882 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:55:13.776862 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:55:13.792713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d227f0b90>]}
[0m17:55:13.793716 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m17:55:13.794793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d228a0650>]}
[0m17:55:13.797404 [info ] [MainThread]: 
[0m17:55:13.798327 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:55:13.799227 [info ] [MainThread]: 
[0m17:55:13.800296 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m17:55:13.808276 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m17:55:13.818834 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:55:14.016280 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:55:14.018005 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m17:55:14.027575 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:55:14.045601 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m17:55:14.053555 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m17:55:14.069355 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:55:14.079627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d229b8790>]}
[0m17:55:14.084892 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m17:55:14.085962 [info ] [Thread-1 (]: 1 of 7 START sql view model `default`.`dim_date` ............................... [RUN]
[0m17:55:14.087233 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m17:55:14.088184 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m17:55:14.096268 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m17:55:14.099458 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m17:55:14.116585 [debug] [Thread-1 (]: Relation dim_date already exists, replacing it
[0m17:55:14.130108 [debug] [Thread-1 (]: Model mvs to replace ['dim_date_mv']
[0m17:55:14.133885 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'default.dim_date'
  
  ...
[0m17:55:14.141470 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:55:14.162857 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m17:55:14.166949 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */


  create or replace view `default`.`dim_date` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_date`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:55:14.180553 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */


  create or replace view `default`.`dim_date` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_date`
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m17:55:14.185252 [debug] [Thread-1 (]: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_c5b2baec5b2bc2a8_faivanpjd606f967.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_c5b2baec5b2bc2a8_faivanpjd606f967.981e6d12-ac4a-4c8f-8e66-953150318791.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m17:55:14.187720 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d2283cfd0>]}
[0m17:55:14.189156 [error] [Thread-1 (]: 1 of 7 ERROR creating sql view model `default`.`dim_date` ...................... [[31mERROR[0m in 0.10s]
[0m17:55:14.190735 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m17:55:14.191736 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m17:55:14.192320 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_date' to be skipped because of status 'error'.  Reason: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_c5b2baec5b2bc2a8_faivanpjd606f967.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_c5b2baec5b2bc2a8_faivanpjd606f967.981e6d12-ac4a-4c8f-8e66-953150318791.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql.
[0m17:55:14.193164 [info ] [Thread-1 (]: 2 of 7 START sql view model `default`.`dim_payment` ............................ [RUN]
[0m17:55:14.195523 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m17:55:14.196269 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m17:55:14.199595 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m17:55:14.201754 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m17:55:14.206953 [debug] [Thread-1 (]: Relation dim_payment already exists, replacing it
[0m17:55:14.208128 [debug] [Thread-1 (]: Model mvs to replace ['dim_payment_mv']
[0m17:55:14.209510 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'default.dim_payment'
  
  ...
[0m17:55:14.220396 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:55:14.224385 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m17:55:14.228980 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */


  create or replace view `default`.`dim_payment` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_product`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:55:14.245017 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */


  create or replace view `default`.`dim_payment` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_product`
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m17:55:14.248325 [debug] [Thread-1 (]: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_3f6112e8f6ac08a5_gsgeqcoe01acae27.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_3f6112e8f6ac08a5_gsgeqcoe01acae27.e30eaeff-37e5-472f-b3e1-1cb9de3cd242.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m17:55:14.249567 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d211380d0>]}
[0m17:55:14.251219 [error] [Thread-1 (]: 2 of 7 ERROR creating sql view model `default`.`dim_payment` ................... [[31mERROR[0m in 0.05s]
[0m17:55:14.253224 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m17:55:14.254707 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m17:55:14.256399 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_payment' to be skipped because of status 'error'.  Reason: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_3f6112e8f6ac08a5_gsgeqcoe01acae27.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_3f6112e8f6ac08a5_gsgeqcoe01acae27.e30eaeff-37e5-472f-b3e1-1cb9de3cd242.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql.
[0m17:55:14.258186 [info ] [Thread-1 (]: 3 of 7 START sql view model `default`.`dim_product` ............................ [RUN]
[0m17:55:14.261479 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m17:55:14.262985 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m17:55:14.271519 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m17:55:14.280405 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m17:55:14.284264 [debug] [Thread-1 (]: Relation dim_product already exists, replacing it
[0m17:55:14.285829 [debug] [Thread-1 (]: Model mvs to replace ['dim_product_mv']
[0m17:55:14.287463 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'default.dim_product'
  
  ...
[0m17:55:14.297690 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:55:14.301044 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m17:55:14.306037 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */


  create or replace view `default`.`dim_product` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_product`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:55:14.323107 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */


  create or replace view `default`.`dim_product` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_product`
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m17:55:14.328469 [debug] [Thread-1 (]: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_b3ca77f4ca012787_mfeoevpc33536d30.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_b3ca77f4ca012787_mfeoevpc33536d30.e3ec4380-924b-45b9-b016-45691f339da0.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m17:55:14.330167 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d224ace50>]}
[0m17:55:14.331768 [error] [Thread-1 (]: 3 of 7 ERROR creating sql view model `default`.`dim_product` ................... [[31mERROR[0m in 0.07s]
[0m17:55:14.333441 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m17:55:14.334859 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m17:55:14.335511 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_product' to be skipped because of status 'error'.  Reason: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_b3ca77f4ca012787_mfeoevpc33536d30.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_b3ca77f4ca012787_mfeoevpc33536d30.e3ec4380-924b-45b9-b016-45691f339da0.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql.
[0m17:55:14.336813 [info ] [Thread-1 (]: 4 of 7 START sql view model `default`.`dim_store` .............................. [RUN]
[0m17:55:14.339272 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m17:55:14.340310 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m17:55:14.344130 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m17:55:14.347734 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m17:55:14.354750 [debug] [Thread-1 (]: Relation dim_store already exists, replacing it
[0m17:55:14.356525 [debug] [Thread-1 (]: Model mvs to replace ['dim_store_mv']
[0m17:55:14.358543 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'default.dim_store'
  
  ...
[0m17:55:14.368878 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:55:14.375235 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m17:55:14.381099 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */


  create or replace view `default`.`dim_store` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_store`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:55:14.393813 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */


  create or replace view `default`.`dim_store` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_store`
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m17:55:14.396755 [debug] [Thread-1 (]: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_4b82644bb46daa95_xhlksrtnef8314de.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_4b82644bb46daa95_xhlksrtnef8314de.2a6d7203-2733-45ad-9d4b-83911f0a1955.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m17:55:14.397876 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d20db4f50>]}
[0m17:55:14.398887 [error] [Thread-1 (]: 4 of 7 ERROR creating sql view model `default`.`dim_store` ..................... [[31mERROR[0m in 0.06s]
[0m17:55:14.400430 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m17:55:14.401738 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m17:55:14.402899 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_store' to be skipped because of status 'error'.  Reason: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_4b82644bb46daa95_xhlksrtnef8314de.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_4b82644bb46daa95_xhlksrtnef8314de.2a6d7203-2733-45ad-9d4b-83911f0a1955.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql.
[0m17:55:14.404680 [info ] [Thread-1 (]: 5 of 7 START sql view model `default`.`dim_supplier` ........................... [RUN]
[0m17:55:14.407635 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m17:55:14.409138 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m17:55:14.415535 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m17:55:14.419426 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m17:55:14.423907 [debug] [Thread-1 (]: Relation dim_supplier already exists, replacing it
[0m17:55:14.425391 [debug] [Thread-1 (]: Model mvs to replace ['dim_supplier_mv']
[0m17:55:14.426829 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'default.dim_supplier'
  
  ...
[0m17:55:14.435283 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:55:14.439107 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m17:55:14.443706 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */


  create or replace view `default`.`dim_supplier` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_supplier`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:55:14.458416 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */


  create or replace view `default`.`dim_supplier` 
  
    
  
  
    
    
  as (
    SELECT
    *
FROM `default`.`stg_dim_supplier`
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m17:55:14.462634 [debug] [Thread-1 (]: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_056ef15c56f7824c_siwxaztje49b96b9.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_056ef15c56f7824c_siwxaztje49b96b9.544cb55e-66e0-4023-8659-14ab89b29ee4.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m17:55:14.465244 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d211e2890>]}
[0m17:55:14.467362 [error] [Thread-1 (]: 5 of 7 ERROR creating sql view model `default`.`dim_supplier` .................. [[31mERROR[0m in 0.06s]
[0m17:55:14.469378 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m17:55:14.470936 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:55:14.471958 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_supplier' to be skipped because of status 'error'.  Reason: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_056ef15c56f7824c_siwxaztje49b96b9.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_056ef15c56f7824c_siwxaztje49b96b9.544cb55e-66e0-4023-8659-14ab89b29ee4.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql.
[0m17:55:14.473195 [info ] [Thread-1 (]: 6 of 7 START sql view model `default`.`stg_dim_customer` ....................... [RUN]
[0m17:55:14.475650 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m17:55:14.477026 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:55:14.480446 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:55:14.484173 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:55:14.487800 [debug] [Thread-1 (]: Relation stg_dim_customer already exists, replacing it
[0m17:55:14.489120 [debug] [Thread-1 (]: Model mvs to replace ['stg_dim_customer_mv']
[0m17:55:14.490301 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'default.stg_dim_customer'
  
  ...
[0m17:55:14.499521 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:55:14.503142 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:55:14.507763 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */


  create or replace view `default`.`stg_dim_customer` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:55:14.527533 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */


  create or replace view `default`.`stg_dim_customer` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m17:55:14.531346 [debug] [Thread-1 (]: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_38889fa093071b67_ekrqtxkja5cf187d.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_38889fa093071b67_ekrqtxkja5cf187d.d10ea094-f10f-403b-8391-6a2af64ecb06.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:55:14.533013 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '824ec040-145e-458b-97fe-48038b8b5149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d215bcd50>]}
[0m17:55:14.534780 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model `default`.`stg_dim_customer` .............. [[31mERROR[0m in 0.06s]
[0m17:55:14.536346 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:55:14.538024 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.stg_dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_38889fa093071b67_ekrqtxkja5cf187d.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_38889fa093071b67_ekrqtxkja5cf187d.d10ea094-f10f-403b-8391-6a2af64ecb06.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql.
[0m17:55:14.539881 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m17:55:14.540963 [info ] [Thread-1 (]: 7 of 7 SKIP relation default.dim_customer ...................................... [[33mSKIP[0m]
[0m17:55:14.542235 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m17:55:14.545820 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:55:14.546700 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.stg_dim_customer' was left open.
[0m17:55:14.547353 [debug] [MainThread]: On model.clickhouse_dbt_demo.stg_dim_customer: Close
[0m17:55:14.548205 [info ] [MainThread]: 
[0m17:55:14.549135 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.75 seconds (0.75s).
[0m17:55:14.551597 [debug] [MainThread]: Command end result
[0m17:55:14.611846 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:55:14.616834 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:55:14.629522 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m17:55:14.630716 [info ] [MainThread]: 
[0m17:55:14.631989 [info ] [MainThread]: [31mCompleted with 6 errors, 0 partial successes, and 0 warnings:[0m
[0m17:55:14.633129 [info ] [MainThread]: 
[0m17:55:14.634525 [error] [MainThread]: [31mFailure in model dim_date (models/marts/dim_date.sql)[0m
[0m17:55:14.636061 [error] [MainThread]:   Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_c5b2baec5b2bc2a8_faivanpjd606f967.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_c5b2baec5b2bc2a8_faivanpjd606f967.981e6d12-ac4a-4c8f-8e66-953150318791.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m17:55:14.637429 [info ] [MainThread]: 
[0m17:55:14.638866 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m17:55:14.639999 [info ] [MainThread]: 
[0m17:55:14.641122 [error] [MainThread]: [31mFailure in model dim_payment (models/marts/dim_payment.sql)[0m
[0m17:55:14.642263 [error] [MainThread]:   Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_3f6112e8f6ac08a5_gsgeqcoe01acae27.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_3f6112e8f6ac08a5_gsgeqcoe01acae27.e30eaeff-37e5-472f-b3e1-1cb9de3cd242.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m17:55:14.643374 [info ] [MainThread]: 
[0m17:55:14.644552 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m17:55:14.645698 [info ] [MainThread]: 
[0m17:55:14.646778 [error] [MainThread]: [31mFailure in model dim_product (models/marts/dim_product.sql)[0m
[0m17:55:14.647894 [error] [MainThread]:   Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_b3ca77f4ca012787_mfeoevpc33536d30.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_b3ca77f4ca012787_mfeoevpc33536d30.e3ec4380-924b-45b9-b016-45691f339da0.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m17:55:14.648762 [info ] [MainThread]: 
[0m17:55:14.649851 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m17:55:14.650883 [info ] [MainThread]: 
[0m17:55:14.651928 [error] [MainThread]: [31mFailure in model dim_store (models/marts/dim_store.sql)[0m
[0m17:55:14.653533 [error] [MainThread]:   Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_4b82644bb46daa95_xhlksrtnef8314de.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_4b82644bb46daa95_xhlksrtnef8314de.2a6d7203-2733-45ad-9d4b-83911f0a1955.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m17:55:14.655343 [info ] [MainThread]: 
[0m17:55:14.657268 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m17:55:14.662062 [info ] [MainThread]: 
[0m17:55:14.663684 [error] [MainThread]: [31mFailure in model dim_supplier (models/marts/dim_supplier.sql)[0m
[0m17:55:14.665298 [error] [MainThread]:   Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_056ef15c56f7824c_siwxaztje49b96b9.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_056ef15c56f7824c_siwxaztje49b96b9.544cb55e-66e0-4023-8659-14ab89b29ee4.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m17:55:14.667019 [info ] [MainThread]: 
[0m17:55:14.668627 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m17:55:14.672631 [info ] [MainThread]: 
[0m17:55:14.676064 [error] [MainThread]: [31mFailure in model stg_dim_customer (models/staging/stg_dim_customer.sql)[0m
[0m17:55:14.678604 [error] [MainThread]:   Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_38889fa093071b67_ekrqtxkja5cf187d.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_38889fa093071b67_ekrqtxkja5cf187d.d10ea094-f10f-403b-8391-6a2af64ecb06.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:55:14.680401 [info ] [MainThread]: 
[0m17:55:14.682639 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:55:14.684143 [info ] [MainThread]: 
[0m17:55:14.685697 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=6 SKIP=1 NO-OP=0 TOTAL=7
[0m17:55:14.688325 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.8555273, "process_in_blocks": "0", "process_kernel_time": 0.298823, "process_mem_max_rss": "122224", "process_out_blocks": "3297", "process_user_time": 2.886884}
[0m17:55:14.689878 [debug] [MainThread]: Command `dbt run` failed at 17:55:14.689555 after 1.86 seconds
[0m17:55:14.691073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d22c0a850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d22a67f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d22ed5490>]}
[0m17:55:14.692423 [debug] [MainThread]: Flushing usage events
[0m17:55:15.336710 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:57:00.377849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad93b94d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad93c5510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad93b9bd0>]}


============================== 17:57:00.382765 | 90589099-0ed8-4222-a5bf-562d098ab3fc ==============================
[0m17:57:00.382765 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:57:00.384080 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'profiles_dir': '/dbt', 'log_format': 'default', 'quiet': 'False', 'use_colors': 'True', 'static_parser': 'True', 'version_check': 'True', 'indirect_selection': 'eager', 'fail_fast': 'False', 'empty': 'False', 'warn_error': 'None', 'cache_selected_only': 'False', 'log_path': '/dbt/logs', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'debug': 'False', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_customer', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'partial_parse': 'True', 'introspect': 'True', 'no_print': 'None'}
[0m17:57:00.624204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '90589099-0ed8-4222-a5bf-562d098ab3fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad91edc10>]}
[0m17:57:00.715020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '90589099-0ed8-4222-a5bf-562d098ab3fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad9934dd0>]}
[0m17:57:00.716890 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m17:57:00.810322 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:57:00.984901 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:57:00.986053 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:57:01.036986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '90589099-0ed8-4222-a5bf-562d098ab3fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad8e30190>]}
[0m17:57:01.149120 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:57:01.154328 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:57:01.182325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '90589099-0ed8-4222-a5bf-562d098ab3fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad8eb71d0>]}
[0m17:57:01.183627 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m17:57:01.184941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90589099-0ed8-4222-a5bf-562d098ab3fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad9199cd0>]}
[0m17:57:01.189818 [info ] [MainThread]: 
[0m17:57:01.192206 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:57:01.194236 [info ] [MainThread]: 
[0m17:57:01.196001 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m17:57:01.198257 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m17:57:01.219905 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:57:01.366272 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:57:01.368253 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m17:57:01.382059 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:57:01.476847 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m17:57:01.484165 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m17:57:01.495829 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:57:01.504463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90589099-0ed8-4222-a5bf-562d098ab3fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad8e30310>]}
[0m17:57:01.508868 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m17:57:01.510915 [info ] [Thread-1 (]: 1 of 1 START sql view model `default`.`dim_customer` ........................... [RUN]
[0m17:57:01.512880 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_customer)
[0m17:57:01.514944 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_customer
[0m17:57:01.535310 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_customer"
[0m17:57:01.539013 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_customer
[0m17:57:01.564253 [debug] [Thread-1 (]: Relation dim_customer already exists, replacing it
[0m17:57:01.586044 [debug] [Thread-1 (]: Model mvs to replace ['dim_customer_mv']
[0m17:57:01.590405 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'default.dim_customer'
  
  ...
[0m17:57:01.599552 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:57:01.635731 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_customer"
[0m17:57:01.640026 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */


  create or replace view `default`.`dim_customer` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m17:57:01.655329 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */


  create or replace view `default`.`dim_customer` 
  
    
  
  
    
    
  as (
    SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m17:57:01.677099 [debug] [Thread-1 (]: Database Error in model dim_customer (models/marts/dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_a88497b1d2743881_msqcmiveb6d5c574.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_a88497b1d2743881_msqcmiveb6d5c574.36b020e3-542a-4e0c-bdf5-636d823a69bb.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_customer.sql
[0m17:57:01.681436 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90589099-0ed8-4222-a5bf-562d098ab3fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad80c6790>]}
[0m17:57:01.685587 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model `default`.`dim_customer` .................. [[31mERROR[0m in 0.17s]
[0m17:57:01.691026 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m17:57:01.695319 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/marts/dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_a88497b1d2743881_msqcmiveb6d5c574.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_a88497b1d2743881_msqcmiveb6d5c574.36b020e3-542a-4e0c-bdf5-636d823a69bb.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_customer.sql.
[0m17:57:01.706246 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:57:01.707773 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.dim_customer' was left open.
[0m17:57:01.711071 [debug] [MainThread]: On model.clickhouse_dbt_demo.dim_customer: Close
[0m17:57:01.714727 [info ] [MainThread]: 
[0m17:57:01.716273 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.52 seconds (0.52s).
[0m17:57:01.719600 [debug] [MainThread]: Command end result
[0m17:57:01.828128 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:57:01.833823 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:57:01.846327 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m17:57:01.847085 [info ] [MainThread]: 
[0m17:57:01.848189 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m17:57:01.849505 [info ] [MainThread]: 
[0m17:57:01.852900 [error] [MainThread]: [31mFailure in model dim_customer (models/marts/dim_customer.sql)[0m
[0m17:57:01.854947 [error] [MainThread]:   Database Error in model dim_customer (models/marts/dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/_tmp_replace_a88497b1d2743881_msqcmiveb6d5c574.sql"] ["/var/lib/clickhouse/metadata_dropped/default._tmp_replace_a88497b1d2743881_msqcmiveb6d5c574.36b020e3-542a-4e0c-bdf5-636d823a69bb.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_customer.sql
[0m17:57:01.856913 [info ] [MainThread]: 
[0m17:57:01.859013 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_customer.sql
[0m17:57:01.861059 [info ] [MainThread]: 
[0m17:57:01.862823 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m17:57:01.865941 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5602776, "process_in_blocks": "0", "process_kernel_time": 0.336274, "process_mem_max_rss": "119168", "process_out_blocks": "2167", "process_user_time": 2.679021}
[0m17:57:01.868377 [debug] [MainThread]: Command `dbt run` failed at 17:57:01.867883 after 1.56 seconds
[0m17:57:01.870393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad9a22850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad93c7d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ad93c7ed0>]}
[0m17:57:01.872778 [debug] [MainThread]: Flushing usage events
[0m17:57:02.419217 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:58:28.943450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202ca00b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c9f5e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202cb99cd0>]}


============================== 17:58:28.947084 | 5f04d6b1-1b60-4939-91d6-088c50af20f5 ==============================
[0m17:58:28.947084 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:58:28.948479 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt run', 'target_path': 'None', 'profiles_dir': '/dbt', 'cache_selected_only': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'printer_width': '80', 'version_check': 'True', 'introspect': 'True', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'log_path': '/dbt/logs', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'indirect_selection': 'eager', 'fail_fast': 'False', 'warn_error': 'None', 'empty': 'False', 'log_format': 'default', 'write_json': 'True', 'quiet': 'False', 'debug': 'False', 'no_print': 'None'}
[0m17:58:29.167315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c8a1690>]}
[0m17:58:29.248068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202cf909d0>]}
[0m17:58:29.249738 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m17:58:29.329951 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:58:29.421400 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m17:58:29.422916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202cf79490>]}
[0m17:58:30.842290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c7cdc10>]}
[0m17:58:30.945990 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:58:30.949362 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:58:30.969008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c44db10>]}
[0m17:58:30.970543 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m17:58:30.971771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c6a4d10>]}
[0m17:58:30.975253 [info ] [MainThread]: 
[0m17:58:30.976922 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:58:30.978426 [info ] [MainThread]: 
[0m17:58:30.980483 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m17:58:30.989646 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m17:58:31.000339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:58:31.133741 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:58:31.135018 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m17:58:31.142464 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:31.160005 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m17:58:31.167146 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:58:31.251821 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:58:31.252931 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m17:58:31.267041 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:31.278165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c3f06d0>]}
[0m17:58:31.283024 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m17:58:31.284334 [info ] [Thread-1 (]: 1 of 7 START sql table model `default`.`dim_date` .............................. [RUN]
[0m17:58:31.285507 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m17:58:31.286664 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m17:58:31.297073 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m17:58:31.300338 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m17:58:31.376858 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date__dbt_tmp`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m17:58:31.396898 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:58:31.525979 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date__dbt_tmp'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:31.546613 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:58:31.551966 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m17:58:31.555946 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date__dbt_tmp`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m17:58:31.593913 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m17:58:31.602907 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    drop table if exists `default`.`dim_date__dbt_backup` 
  
  ...
[0m17:58:31.608934 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:31.611890 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    rename table `default`.`dim_date` to `default`.`dim_date__dbt_backup` 
  
  ...
[0m17:58:31.619445 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:31.624353 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    drop table if exists `default`.`dim_date` 
  
  ...
[0m17:58:31.628418 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:31.630915 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    rename table `default`.`dim_date__dbt_tmp` to `default`.`dim_date` 
  
  ...
[0m17:58:31.639783 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:31.671937 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  ...
[0m17:58:31.676993 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:31.682036 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202ab3ea50>]}
[0m17:58:31.683778 [info ] [Thread-1 (]: 1 of 7 OK created sql table model `default`.`dim_date` ......................... [[32mOK[0m in 0.40s]
[0m17:58:31.685163 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m17:58:31.686556 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m17:58:31.687825 [info ] [Thread-1 (]: 2 of 7 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m17:58:31.689332 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m17:58:31.690479 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m17:58:31.694089 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m17:58:31.698011 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m17:58:31.703424 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment__dbt_tmp`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m17:58:31.735266 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:31.740057 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment__dbt_tmp'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:31.749245 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:31.752483 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m17:58:31.755768 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment__dbt_tmp`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m17:58:31.793935 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m17:58:31.800795 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    drop table if exists `default`.`dim_payment__dbt_backup` 
  
  ...
[0m17:58:31.807173 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:31.811163 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    rename table `default`.`dim_payment` to `default`.`dim_payment__dbt_backup` 
  
  ...
[0m17:58:31.818591 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:31.826973 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    drop table if exists `default`.`dim_payment` 
  
  ...
[0m17:58:31.834640 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:31.841038 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    rename table `default`.`dim_payment__dbt_tmp` to `default`.`dim_payment` 
  
  ...
[0m17:58:31.852574 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:31.868157 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  ...
[0m17:58:31.875539 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:31.879640 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c51c910>]}
[0m17:58:31.882564 [info ] [Thread-1 (]: 2 of 7 OK created sql table model `default`.`dim_payment` ...................... [[32mOK[0m in 0.19s]
[0m17:58:31.884155 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m17:58:31.886500 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m17:58:31.888759 [info ] [Thread-1 (]: 3 of 7 START sql table model `default`.`dim_product` ........................... [RUN]
[0m17:58:31.890571 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m17:58:31.892572 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m17:58:31.899646 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m17:58:31.903378 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m17:58:31.913504 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product__dbt_tmp`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m17:58:31.960442 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m17:58:31.970101 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product__dbt_tmp'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:31.984990 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:31.989633 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m17:58:31.995765 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product__dbt_tmp`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m17:58:32.034643 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m17:58:32.040723 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    drop table if exists `default`.`dim_product__dbt_backup` 
  
  ...
[0m17:58:32.047413 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.050605 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    rename table `default`.`dim_product` to `default`.`dim_product__dbt_backup` 
  
  ...
[0m17:58:32.058716 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.067801 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    drop table if exists `default`.`dim_product` 
  
  ...
[0m17:58:32.073758 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.076902 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    rename table `default`.`dim_product__dbt_tmp` to `default`.`dim_product` 
  
  ...
[0m17:58:32.086445 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.095319 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  ...
[0m17:58:32.101474 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.104939 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c51c190>]}
[0m17:58:32.107050 [info ] [Thread-1 (]: 3 of 7 OK created sql table model `default`.`dim_product` ...................... [[32mOK[0m in 0.21s]
[0m17:58:32.109731 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m17:58:32.111568 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m17:58:32.114042 [info ] [Thread-1 (]: 4 of 7 START sql table model `default`.`dim_store` ............................. [RUN]
[0m17:58:32.116609 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m17:58:32.118701 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m17:58:32.126044 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m17:58:32.130576 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m17:58:32.141685 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store__dbt_tmp`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m17:58:32.173750 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:32.181512 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_tmp'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:32.194653 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.199116 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m17:58:32.202672 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store__dbt_tmp`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m17:58:32.244858 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m17:58:32.257806 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    drop table if exists `default`.`dim_store__dbt_backup` 
  
  ...
[0m17:58:32.264070 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.267007 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    rename table `default`.`dim_store` to `default`.`dim_store__dbt_backup` 
  
  ...
[0m17:58:32.275266 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.282537 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    drop table if exists `default`.`dim_store` 
  
  ...
[0m17:58:32.286898 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.289124 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    rename table `default`.`dim_store__dbt_tmp` to `default`.`dim_store` 
  
  ...
[0m17:58:32.299972 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.307733 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  ...
[0m17:58:32.314390 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.318325 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c6b4250>]}
[0m17:58:32.320324 [info ] [Thread-1 (]: 4 of 7 OK created sql table model `default`.`dim_store` ........................ [[32mOK[0m in 0.20s]
[0m17:58:32.322615 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m17:58:32.324305 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m17:58:32.326476 [info ] [Thread-1 (]: 5 of 7 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m17:58:32.330324 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m17:58:32.331390 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m17:58:32.336579 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m17:58:32.339763 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m17:58:32.348300 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier__dbt_tmp`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m17:58:32.382627 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:32.387014 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier__dbt_tmp'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:32.396565 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.399113 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m17:58:32.401725 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier__dbt_tmp`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m17:58:32.441695 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m17:58:32.447012 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    drop table if exists `default`.`dim_supplier__dbt_backup` 
  
  ...
[0m17:58:32.452225 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.454761 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    rename table `default`.`dim_supplier` to `default`.`dim_supplier__dbt_backup` 
  
  ...
[0m17:58:32.463026 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.471913 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    drop table if exists `default`.`dim_supplier` 
  
  ...
[0m17:58:32.477251 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.479633 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    rename table `default`.`dim_supplier__dbt_tmp` to `default`.`dim_supplier` 
  
  ...
[0m17:58:32.489359 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.495528 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  ...
[0m17:58:32.500856 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.503068 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c616010>]}
[0m17:58:32.504633 [info ] [Thread-1 (]: 5 of 7 OK created sql table model `default`.`dim_supplier` ..................... [[32mOK[0m in 0.17s]
[0m17:58:32.507219 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m17:58:32.509284 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:58:32.511721 [info ] [Thread-1 (]: 6 of 7 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m17:58:32.513731 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m17:58:32.515355 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:58:32.520414 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:58:32.524553 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:58:32.533978 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer__dbt_tmp`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m17:58:32.560730 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:58:32.567703 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer__dbt_tmp'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:32.580422 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.583986 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:58:32.587478 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer__dbt_tmp`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m17:58:32.616851 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:32.624195 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  
  ...
[0m17:58:32.630367 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.632481 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    rename table `default`.`stg_dim_customer` to `default`.`stg_dim_customer__dbt_backup` 
  
  ...
[0m17:58:32.639177 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.644143 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    drop table if exists `default`.`stg_dim_customer` 
  
  ...
[0m17:58:32.647697 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.649850 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    rename table `default`.`stg_dim_customer__dbt_tmp` to `default`.`stg_dim_customer` 
  
  ...
[0m17:58:32.658795 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.665344 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  ...
[0m17:58:32.674477 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.678460 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c4c0590>]}
[0m17:58:32.680279 [info ] [Thread-1 (]: 6 of 7 OK created sql table model `default`.`stg_dim_customer` ................. [[32mOK[0m in 0.16s]
[0m17:58:32.681968 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:58:32.684392 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m17:58:32.686029 [info ] [Thread-1 (]: 7 of 7 START sql table model `default`.`dim_customer` .......................... [RUN]
[0m17:58:32.687478 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.stg_dim_customer, now model.clickhouse_dbt_demo.dim_customer)
[0m17:58:32.688903 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_customer
[0m17:58:32.693967 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_customer"
[0m17:58:32.696110 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_customer
[0m17:58:32.702939 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

            

    
        create table `default`.`dim_customer__dbt_tmp`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
          )
        
        ...
[0m17:58:32.734144 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:32.738983 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer__dbt_tmp'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:32.747459 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.750164 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_customer"
[0m17:58:32.752301 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`dim_customer__dbt_tmp`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
  ...
[0m17:58:32.787018 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:32.790941 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    drop table if exists `default`.`dim_customer__dbt_backup` 
  
  ...
[0m17:58:32.795231 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.797028 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    rename table `default`.`dim_customer` to `default`.`dim_customer__dbt_backup` 
  
  ...
[0m17:58:32.801191 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.805648 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    drop table if exists `default`.`dim_customer` 
  
  ...
[0m17:58:32.810337 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.813482 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    rename table `default`.`dim_customer__dbt_tmp` to `default`.`dim_customer` 
  
  ...
[0m17:58:32.821691 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:32.831555 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */
drop table if exists `default`.`dim_customer__dbt_backup` 
  ...
[0m17:58:32.836735 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m17:58:32.839143 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f04d6b1-1b60-4939-91d6-088c50af20f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202a710f50>]}
[0m17:58:32.840194 [info ] [Thread-1 (]: 7 of 7 OK created sql table model `default`.`dim_customer` ..................... [[32mOK[0m in 0.15s]
[0m17:58:32.841814 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m17:58:32.845502 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:58:32.846561 [debug] [MainThread]: Connection 'list_' was left open.
[0m17:58:32.847293 [debug] [MainThread]: On list_: Close
[0m17:58:32.848170 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.dim_customer' was left open.
[0m17:58:32.848946 [debug] [MainThread]: On model.clickhouse_dbt_demo.dim_customer: Close
[0m17:58:32.849961 [info ] [MainThread]: 
[0m17:58:32.850850 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 1.87 seconds (1.87s).
[0m17:58:32.852831 [debug] [MainThread]: Command end result
[0m17:58:32.927363 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:58:32.932957 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:58:32.947712 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m17:58:32.948988 [info ] [MainThread]: 
[0m17:58:32.950766 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:58:32.952336 [info ] [MainThread]: 
[0m17:58:32.953838 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m17:58:32.957032 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.0811367, "process_in_blocks": "0", "process_kernel_time": 0.407535, "process_mem_max_rss": "124388", "process_out_blocks": "3295", "process_user_time": 4.400977}
[0m17:58:32.959069 [debug] [MainThread]: Command `dbt run` succeeded at 17:58:32.958719 after 4.08 seconds
[0m17:58:32.960808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202d930a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202ca3b450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f202c863310>]}
[0m17:58:32.962566 [debug] [MainThread]: Flushing usage events
[0m17:58:33.673431 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:58:37.377570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf504c990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf5136250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf5005d50>]}


============================== 17:58:37.381704 | a2593982-bc98-4f55-b7e3-5d7c77de2104 ==============================
[0m17:58:37.381704 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:58:37.382780 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/dbt', 'fail_fast': 'False', 'partial_parse': 'True', 'warn_error': 'None', 'quiet': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'no_print': 'None', 'invocation_command': 'dbt run', 'introspect': 'True', 'version_check': 'True', 'target_path': 'None', 'debug': 'False', 'use_colors': 'True', 'log_path': '/dbt/logs', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'indirect_selection': 'eager'}
[0m17:58:37.575128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf5010890>]}
[0m17:58:37.647702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf556a9d0>]}
[0m17:58:37.649288 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m17:58:37.724269 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:58:37.850937 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:58:37.851787 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:58:37.894737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf4ac3550>]}
[0m17:58:37.999315 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:58:38.002833 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:58:38.031364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf4e00250>]}
[0m17:58:38.032506 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m17:58:38.033531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf6e53010>]}
[0m17:58:38.036399 [info ] [MainThread]: 
[0m17:58:38.037615 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:58:38.038811 [info ] [MainThread]: 
[0m17:58:38.040353 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m17:58:38.049087 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m17:58:38.067274 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:58:38.193503 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:58:38.194730 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m17:58:38.201905 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:38.286550 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m17:58:38.293986 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:58:38.372044 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m17:58:38.373581 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m17:58:38.385877 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:38.395743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf49e52d0>]}
[0m17:58:38.400544 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m17:58:38.401514 [info ] [Thread-1 (]: 1 of 7 START sql table model `default`.`dim_date` .............................. [RUN]
[0m17:58:38.402432 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m17:58:38.403267 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m17:58:38.415945 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m17:58:38.420360 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m17:58:38.502576 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m17:58:38.530024 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:38.555274 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:38.568598 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:38.577387 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m17:58:38.581030 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date__dbt_backup`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m17:58:38.612573 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:38.622504 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
EXCHANGE TABLES `default`.`dim_date__dbt_backup` AND `default`.`dim_date` 
  
  ...
[0m17:58:38.634126 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:38.672019 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  ...
[0m17:58:38.678365 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  
[0m17:58:38.679807 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m17:58:38.687729 [debug] [Thread-1 (]: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.39e454c7-b895-4ad7-a6f7-e3cc1621a6ad.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m17:58:38.690557 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf4a32c10>]}
[0m17:58:38.692352 [error] [Thread-1 (]: 1 of 7 ERROR creating sql table model `default`.`dim_date` ..................... [[31mERROR[0m in 0.29s]
[0m17:58:38.693885 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m17:58:38.695219 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m17:58:38.696041 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_date' to be skipped because of status 'error'.  Reason: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.39e454c7-b895-4ad7-a6f7-e3cc1621a6ad.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql.
[0m17:58:38.697630 [info ] [Thread-1 (]: 2 of 7 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m17:58:38.700877 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m17:58:38.702036 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m17:58:38.707792 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m17:58:38.711030 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m17:58:38.716562 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m17:58:38.741551 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:58:38.746223 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:38.755609 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:38.760422 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m17:58:38.764568 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m17:58:38.793780 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:38.795559 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
EXCHANGE TABLES `default`.`dim_payment__dbt_backup` AND `default`.`dim_payment` 
  
  ...
[0m17:58:38.804956 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:38.812351 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  ...
[0m17:58:38.819370 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  
[0m17:58:38.820887 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m17:58:38.827839 [debug] [Thread-1 (]: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.05808391-5488-4a6f-9345-784a5fa33d69.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m17:58:38.829423 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf3b98f50>]}
[0m17:58:38.830973 [error] [Thread-1 (]: 2 of 7 ERROR creating sql table model `default`.`dim_payment` .................. [[31mERROR[0m in 0.13s]
[0m17:58:38.832532 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m17:58:38.833917 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m17:58:38.834547 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_payment' to be skipped because of status 'error'.  Reason: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.05808391-5488-4a6f-9345-784a5fa33d69.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql.
[0m17:58:38.835736 [info ] [Thread-1 (]: 3 of 7 START sql table model `default`.`dim_product` ........................... [RUN]
[0m17:58:38.837816 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m17:58:38.839006 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m17:58:38.843317 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m17:58:38.847312 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m17:58:38.852044 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m17:58:38.881683 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:38.889420 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:38.899656 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:38.902290 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m17:58:38.906147 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m17:58:38.939713 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:38.941672 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
EXCHANGE TABLES `default`.`dim_product__dbt_backup` AND `default`.`dim_product` 
  
  ...
[0m17:58:38.950719 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:38.955434 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  ...
[0m17:58:38.961405 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  
[0m17:58:38.963143 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m17:58:38.970464 [debug] [Thread-1 (]: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.6b3dafb9-7c7e-4580-8506-326fa49b4932.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m17:58:38.972220 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf4dba550>]}
[0m17:58:38.974213 [error] [Thread-1 (]: 3 of 7 ERROR creating sql table model `default`.`dim_product` .................. [[31mERROR[0m in 0.13s]
[0m17:58:38.976227 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m17:58:38.977829 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m17:58:38.978921 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_product' to be skipped because of status 'error'.  Reason: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.6b3dafb9-7c7e-4580-8506-326fa49b4932.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql.
[0m17:58:38.980500 [info ] [Thread-1 (]: 4 of 7 START sql table model `default`.`dim_store` ............................. [RUN]
[0m17:58:38.983407 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m17:58:38.984777 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m17:58:38.988808 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m17:58:38.992454 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m17:58:38.996957 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m17:58:39.027343 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:39.033287 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:39.043657 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:39.046463 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m17:58:39.049870 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store__dbt_backup`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m17:58:39.079237 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:39.081685 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
EXCHANGE TABLES `default`.`dim_store__dbt_backup` AND `default`.`dim_store` 
  
  ...
[0m17:58:39.091336 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:39.095433 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  ...
[0m17:58:39.100068 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  
[0m17:58:39.101658 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m17:58:39.107475 [debug] [Thread-1 (]: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.dd492706-0ec7-449c-b691-436f4300f8bb.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m17:58:39.109426 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf4bf90d0>]}
[0m17:58:39.111242 [error] [Thread-1 (]: 4 of 7 ERROR creating sql table model `default`.`dim_store` .................... [[31mERROR[0m in 0.13s]
[0m17:58:39.113558 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m17:58:39.115054 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m17:58:39.116320 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_store' to be skipped because of status 'error'.  Reason: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.dd492706-0ec7-449c-b691-436f4300f8bb.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql.
[0m17:58:39.117787 [info ] [Thread-1 (]: 5 of 7 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m17:58:39.120547 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m17:58:39.121915 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m17:58:39.128033 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m17:58:39.131885 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m17:58:39.137016 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m17:58:39.165108 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:39.172863 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:39.183752 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:39.186997 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m17:58:39.190998 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier__dbt_backup`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m17:58:39.221557 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m17:58:39.224936 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
EXCHANGE TABLES `default`.`dim_supplier__dbt_backup` AND `default`.`dim_supplier` 
  
  ...
[0m17:58:39.234279 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:39.239083 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  ...
[0m17:58:39.244390 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  
[0m17:58:39.245702 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m17:58:39.250583 [debug] [Thread-1 (]: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.99212418-5d08-41d8-9b2a-0bb9300f45ae.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m17:58:39.252111 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf3cec710>]}
[0m17:58:39.253770 [error] [Thread-1 (]: 5 of 7 ERROR creating sql table model `default`.`dim_supplier` ................. [[31mERROR[0m in 0.13s]
[0m17:58:39.255770 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m17:58:39.257574 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:58:39.258644 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_supplier' to be skipped because of status 'error'.  Reason: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.99212418-5d08-41d8-9b2a-0bb9300f45ae.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql.
[0m17:58:39.260192 [info ] [Thread-1 (]: 6 of 7 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m17:58:39.263639 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m17:58:39.265106 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:58:39.272410 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:58:39.276395 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:58:39.281896 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m17:58:39.303383 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:58:39.311268 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m17:58:39.323086 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:39.328676 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m17:58:39.332616 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m17:58:39.355483 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m17:58:39.359714 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
EXCHANGE TABLES `default`.`stg_dim_customer__dbt_backup` AND `default`.`stg_dim_customer` 
  
  ...
[0m17:58:39.372652 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m17:58:39.379739 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  ...
[0m17:58:39.384790 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  
[0m17:58:39.386497 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m17:58:39.390776 [debug] [Thread-1 (]: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.ef3e6c9e-fb15-4990-94bf-fe0a0755ea74.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:58:39.392045 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2593982-bc98-4f55-b7e3-5d7c77de2104', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf3ceebd0>]}
[0m17:58:39.393764 [error] [Thread-1 (]: 6 of 7 ERROR creating sql table model `default`.`stg_dim_customer` ............. [[31mERROR[0m in 0.13s]
[0m17:58:39.395134 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m17:58:39.396924 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.stg_dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.ef3e6c9e-fb15-4990-94bf-fe0a0755ea74.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql.
[0m17:58:39.399271 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m17:58:39.400311 [info ] [Thread-1 (]: 7 of 7 SKIP relation default.dim_customer ...................................... [[33mSKIP[0m]
[0m17:58:39.401358 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m17:58:39.403892 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:58:39.405233 [debug] [MainThread]: Connection 'list_' was left open.
[0m17:58:39.406459 [debug] [MainThread]: On list_: Close
[0m17:58:39.407623 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.stg_dim_customer' was left open.
[0m17:58:39.408840 [debug] [MainThread]: On model.clickhouse_dbt_demo.stg_dim_customer: Close
[0m17:58:39.410596 [info ] [MainThread]: 
[0m17:58:39.411917 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 1.37 seconds (1.37s).
[0m17:58:39.415932 [debug] [MainThread]: Command end result
[0m17:58:39.484680 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m17:58:39.489479 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m17:58:39.499253 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m17:58:39.500035 [info ] [MainThread]: 
[0m17:58:39.500968 [info ] [MainThread]: [31mCompleted with 6 errors, 0 partial successes, and 0 warnings:[0m
[0m17:58:39.502035 [info ] [MainThread]: 
[0m17:58:39.503365 [error] [MainThread]: [31mFailure in model dim_date (models/marts/dim_date.sql)[0m
[0m17:58:39.504813 [error] [MainThread]:   Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.39e454c7-b895-4ad7-a6f7-e3cc1621a6ad.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m17:58:39.506734 [info ] [MainThread]: 
[0m17:58:39.508627 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m17:58:39.509956 [info ] [MainThread]: 
[0m17:58:39.511745 [error] [MainThread]: [31mFailure in model dim_payment (models/marts/dim_payment.sql)[0m
[0m17:58:39.513377 [error] [MainThread]:   Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.05808391-5488-4a6f-9345-784a5fa33d69.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m17:58:39.514695 [info ] [MainThread]: 
[0m17:58:39.516404 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m17:58:39.517698 [info ] [MainThread]: 
[0m17:58:39.519430 [error] [MainThread]: [31mFailure in model dim_product (models/marts/dim_product.sql)[0m
[0m17:58:39.520779 [error] [MainThread]:   Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.6b3dafb9-7c7e-4580-8506-326fa49b4932.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m17:58:39.522350 [info ] [MainThread]: 
[0m17:58:39.523842 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m17:58:39.525271 [info ] [MainThread]: 
[0m17:58:39.526665 [error] [MainThread]: [31mFailure in model dim_store (models/marts/dim_store.sql)[0m
[0m17:58:39.528318 [error] [MainThread]:   Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.dd492706-0ec7-449c-b691-436f4300f8bb.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m17:58:39.529636 [info ] [MainThread]: 
[0m17:58:39.531233 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m17:58:39.532344 [info ] [MainThread]: 
[0m17:58:39.533516 [error] [MainThread]: [31mFailure in model dim_supplier (models/marts/dim_supplier.sql)[0m
[0m17:58:39.534793 [error] [MainThread]:   Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.99212418-5d08-41d8-9b2a-0bb9300f45ae.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m17:58:39.536320 [info ] [MainThread]: 
[0m17:58:39.537987 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m17:58:39.542077 [info ] [MainThread]: 
[0m17:58:39.543891 [error] [MainThread]: [31mFailure in model stg_dim_customer (models/staging/stg_dim_customer.sql)[0m
[0m17:58:39.545496 [error] [MainThread]:   Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.ef3e6c9e-fb15-4990-94bf-fe0a0755ea74.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:58:39.546660 [info ] [MainThread]: 
[0m17:58:39.548054 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m17:58:39.549441 [info ] [MainThread]: 
[0m17:58:39.551309 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=6 SKIP=1 NO-OP=0 TOTAL=7
[0m17:58:39.553407 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.2491114, "process_in_blocks": "0", "process_kernel_time": 0.400139, "process_mem_max_rss": "120632", "process_out_blocks": "2258", "process_user_time": 3.031394}
[0m17:58:39.554570 [debug] [MainThread]: Command `dbt run` failed at 17:58:39.554382 after 2.25 seconds
[0m17:58:39.555651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf5012990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf99b85d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdf99b8e90>]}
[0m17:58:39.556775 [debug] [MainThread]: Flushing usage events
[0m17:58:40.199627 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:02:35.729639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb2457aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb2467b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb2467b250>]}


============================== 18:02:35.737308 | 7d6f303c-27b8-4718-9ac6-c3a11032711f ==============================
[0m18:02:35.737308 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:02:35.738977 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'profiles_dir': '/dbt', 'debug': 'False', 'log_path': '/dbt/logs', 'invocation_command': 'dbt debug', 'log_cache_events': 'False', 'empty': 'None', 'write_json': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'printer_width': '80', 'partial_parse': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error': 'None', 'log_format': 'default'}
[0m18:02:35.752601 [info ] [MainThread]: dbt version: 1.10.13
[0m18:02:35.753767 [info ] [MainThread]: python version: 3.11.14
[0m18:02:35.755026 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m18:02:35.756127 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m18:02:35.845925 [info ] [MainThread]: Using profiles dir at /dbt
[0m18:02:35.847475 [info ] [MainThread]: Using profiles.yml file at /dbt/profiles.yml
[0m18:02:35.848659 [info ] [MainThread]: Using dbt_project.yml file at /dbt/dbt_project.yml
[0m18:02:35.850379 [info ] [MainThread]: adapter type: clickhouse
[0m18:02:35.851905 [info ] [MainThread]: adapter version: 1.9.5
[0m18:02:36.000973 [info ] [MainThread]: Configuration:
[0m18:02:36.002546 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:02:36.003953 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:02:36.005206 [info ] [MainThread]: Required dependencies:
[0m18:02:36.006585 [debug] [MainThread]: Executing "git --help"
[0m18:02:36.020154 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:02:36.021703 [debug] [MainThread]: STDERR: "b''"
[0m18:02:36.022826 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:02:36.024123 [info ] [MainThread]: Connection:
[0m18:02:36.025933 [info ] [MainThread]:   driver: None
[0m18:02:36.027371 [info ] [MainThread]:   host: clickhouse-server
[0m18:02:36.028599 [info ] [MainThread]:   port: 8123
[0m18:02:36.029923 [info ] [MainThread]:   user: default
[0m18:02:36.030980 [info ] [MainThread]:   schema: default
[0m18:02:36.032272 [info ] [MainThread]:   retries: 1
[0m18:02:36.033466 [info ] [MainThread]:   cluster: None
[0m18:02:36.034634 [info ] [MainThread]:   database_engine: None
[0m18:02:36.035713 [info ] [MainThread]:   cluster_mode: False
[0m18:02:36.036651 [info ] [MainThread]:   secure: False
[0m18:02:36.037993 [info ] [MainThread]:   verify: True
[0m18:02:36.039316 [info ] [MainThread]:   client_cert: None
[0m18:02:36.040559 [info ] [MainThread]:   client_cert_key: None
[0m18:02:36.042313 [info ] [MainThread]:   connect_timeout: 10
[0m18:02:36.043771 [info ] [MainThread]:   send_receive_timeout: 300
[0m18:02:36.045755 [info ] [MainThread]:   sync_request_timeout: 5
[0m18:02:36.047356 [info ] [MainThread]:   compress_block_size: 1048576
[0m18:02:36.048975 [info ] [MainThread]:   compression: 
[0m18:02:36.050943 [info ] [MainThread]:   check_exchange: True
[0m18:02:36.052398 [info ] [MainThread]:   custom_settings: None
[0m18:02:36.053759 [info ] [MainThread]:   use_lw_deletes: False
[0m18:02:36.055405 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m18:02:36.057138 [info ] [MainThread]:   tcp_keepalive: False
[0m18:02:36.058783 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:02:36.141292 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m18:02:36.142302 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:02:36.207904 [debug] [MainThread]: dbt_clickhouse adapter: Got a retryable error when attempting to open a clickhouse connection.
1 attempts remaining. Retrying in 1 seconds.
Error:
Error HTTPConnectionPool(host='clickhouse-server', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdb24169290>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://clickhouse-server:8123)
[0m18:02:37.217655 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m18:02:37.220448 [info ] [MainThread]: [31m1 check failed:[0m
[0m18:02:37.222060 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  Error HTTPConnectionPool(host='clickhouse-server', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdb2416b150>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://clickhouse-server:8123)

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m18:02:37.225729 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 1.5701692, "process_in_blocks": "0", "process_kernel_time": 0.557046, "process_mem_max_rss": "108132", "process_out_blocks": "2135", "process_user_time": 2.342103}
[0m18:02:37.227724 [debug] [MainThread]: Command `dbt debug` failed at 18:02:37.227367 after 1.57 seconds
[0m18:02:37.228864 [debug] [MainThread]: Connection 'debug' was left open.
[0m18:02:37.229787 [debug] [MainThread]: On debug: No close available on handle
[0m18:02:37.230758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb246686d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb2467b8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb2467bb50>]}
[0m18:02:37.231764 [debug] [MainThread]: Flushing usage events
[0m18:02:37.823588 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:05:42.947803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd613c99850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd613d7ba50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd613c98990>]}


============================== 18:05:42.955833 | 7c37835e-d6b0-452a-adfa-54f0f5fc2185 ==============================
[0m18:05:42.955833 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:05:42.957864 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'write_json': 'True', 'target_path': 'None', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'no_print': 'None', 'profiles_dir': '/dbt', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'quiet': 'False', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'printer_width': '80', 'empty': 'None', 'version_check': 'True', 'warn_error': 'None', 'introspect': 'True', 'invocation_command': 'dbt debug', 'log_path': '/dbt/logs', 'static_parser': 'True', 'log_cache_events': 'False'}
[0m18:05:42.970246 [info ] [MainThread]: dbt version: 1.10.13
[0m18:05:42.971731 [info ] [MainThread]: python version: 3.11.14
[0m18:05:42.973090 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m18:05:42.974180 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m18:05:43.173779 [info ] [MainThread]: Using profiles dir at /dbt
[0m18:05:43.175024 [info ] [MainThread]: Using profiles.yml file at /dbt/profiles.yml
[0m18:05:43.176159 [info ] [MainThread]: Using dbt_project.yml file at /dbt/dbt_project.yml
[0m18:05:43.179811 [info ] [MainThread]: adapter type: clickhouse
[0m18:05:43.181797 [info ] [MainThread]: adapter version: 1.9.5
[0m18:05:43.327710 [info ] [MainThread]: Configuration:
[0m18:05:43.329788 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:05:43.331864 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:05:43.333072 [info ] [MainThread]: Required dependencies:
[0m18:05:43.334259 [debug] [MainThread]: Executing "git --help"
[0m18:05:43.338002 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:05:43.339058 [debug] [MainThread]: STDERR: "b''"
[0m18:05:43.339743 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:05:43.340590 [info ] [MainThread]: Connection:
[0m18:05:43.341809 [info ] [MainThread]:   driver: None
[0m18:05:43.342988 [info ] [MainThread]:   host: clickhouse-server
[0m18:05:43.343986 [info ] [MainThread]:   port: 8123
[0m18:05:43.345005 [info ] [MainThread]:   user: default
[0m18:05:43.346238 [info ] [MainThread]:   schema: default
[0m18:05:43.347708 [info ] [MainThread]:   retries: 1
[0m18:05:43.348804 [info ] [MainThread]:   cluster: None
[0m18:05:43.350147 [info ] [MainThread]:   database_engine: None
[0m18:05:43.351283 [info ] [MainThread]:   cluster_mode: False
[0m18:05:43.352704 [info ] [MainThread]:   secure: False
[0m18:05:43.353692 [info ] [MainThread]:   verify: True
[0m18:05:43.354749 [info ] [MainThread]:   client_cert: None
[0m18:05:43.355732 [info ] [MainThread]:   client_cert_key: None
[0m18:05:43.356865 [info ] [MainThread]:   connect_timeout: 10
[0m18:05:43.357959 [info ] [MainThread]:   send_receive_timeout: 300
[0m18:05:43.359112 [info ] [MainThread]:   sync_request_timeout: 5
[0m18:05:43.360428 [info ] [MainThread]:   compress_block_size: 1048576
[0m18:05:43.361634 [info ] [MainThread]:   compression: 
[0m18:05:43.362660 [info ] [MainThread]:   check_exchange: True
[0m18:05:43.363649 [info ] [MainThread]:   custom_settings: None
[0m18:05:43.364605 [info ] [MainThread]:   use_lw_deletes: False
[0m18:05:43.365844 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m18:05:43.366913 [info ] [MainThread]:   tcp_keepalive: False
[0m18:05:43.369223 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:05:43.455364 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m18:05:43.456705 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:05:43.530984 [debug] [MainThread]: dbt_clickhouse adapter: Got a retryable error when attempting to open a clickhouse connection.
1 attempts remaining. Retrying in 1 seconds.
Error:
Error HTTPConnectionPool(host='clickhouse-server', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd613880f10>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://clickhouse-server:8123)
[0m18:05:44.535935 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m18:05:44.537233 [info ] [MainThread]: [31m1 check failed:[0m
[0m18:05:44.538347 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  Error HTTPConnectionPool(host='clickhouse-server', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd613882d50>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://clickhouse-server:8123)

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m18:05:44.540053 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 1.6508665, "process_in_blocks": "0", "process_kernel_time": 0.470257, "process_mem_max_rss": "108324", "process_out_blocks": "2135", "process_user_time": 2.35887}
[0m18:05:44.540968 [debug] [MainThread]: Command `dbt debug` failed at 18:05:44.540812 after 1.65 seconds
[0m18:05:44.541632 [debug] [MainThread]: Connection 'debug' was left open.
[0m18:05:44.542197 [debug] [MainThread]: On debug: No close available on handle
[0m18:05:44.542782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd613c6d510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd613c6f750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd613c791d0>]}
[0m18:05:44.543618 [debug] [MainThread]: Flushing usage events
[0m18:05:45.106090 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:07:59.896402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42fa0aaa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42fa736b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42fa2ea910>]}


============================== 18:07:59.910042 | af7b5c92-8641-4cfa-92ac-d209072dca3e ==============================
[0m18:07:59.910042 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:07:59.918488 [debug] [MainThread]: running dbt with arguments {'log_path': '/dbt/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'introspect': 'True', 'write_json': 'True', 'fail_fast': 'False', 'log_format': 'default', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'use_experimental_parser': 'False', 'profiles_dir': '/dbt', 'log_cache_events': 'False', 'debug': 'False', 'warn_error': 'None', 'empty': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'static_parser': 'True', 'version_check': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'invocation_command': 'dbt debug', 'partial_parse': 'True'}
[0m18:07:59.943422 [info ] [MainThread]: dbt version: 1.10.13
[0m18:07:59.954159 [info ] [MainThread]: python version: 3.11.14
[0m18:07:59.968369 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m18:07:59.976592 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m18:08:00.166419 [info ] [MainThread]: Using profiles dir at /dbt
[0m18:08:00.175939 [info ] [MainThread]: Using profiles.yml file at /dbt/profiles.yml
[0m18:08:00.187683 [info ] [MainThread]: Using dbt_project.yml file at /dbt/dbt_project.yml
[0m18:08:00.196186 [info ] [MainThread]: adapter type: clickhouse
[0m18:08:00.209163 [info ] [MainThread]: adapter version: 1.9.5
[0m18:08:00.418100 [info ] [MainThread]: Configuration:
[0m18:08:00.429098 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:08:00.443514 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:08:00.454068 [info ] [MainThread]: Required dependencies:
[0m18:08:00.465895 [debug] [MainThread]: Executing "git --help"
[0m18:08:00.478827 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:08:00.494386 [debug] [MainThread]: STDERR: "b''"
[0m18:08:00.507931 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:08:00.515898 [info ] [MainThread]: Connection:
[0m18:08:00.524417 [info ] [MainThread]:   driver: None
[0m18:08:00.532566 [info ] [MainThread]:   host: clickhouse-server
[0m18:08:00.540398 [info ] [MainThread]:   port: 8123
[0m18:08:00.550675 [info ] [MainThread]:   user: default
[0m18:08:00.562270 [info ] [MainThread]:   schema: default
[0m18:08:00.571644 [info ] [MainThread]:   retries: 1
[0m18:08:00.578919 [info ] [MainThread]:   cluster: None
[0m18:08:00.588874 [info ] [MainThread]:   database_engine: None
[0m18:08:00.601819 [info ] [MainThread]:   cluster_mode: False
[0m18:08:00.613746 [info ] [MainThread]:   secure: False
[0m18:08:00.624337 [info ] [MainThread]:   verify: True
[0m18:08:00.634645 [info ] [MainThread]:   client_cert: None
[0m18:08:00.650391 [info ] [MainThread]:   client_cert_key: None
[0m18:08:00.661765 [info ] [MainThread]:   connect_timeout: 10
[0m18:08:00.668719 [info ] [MainThread]:   send_receive_timeout: 300
[0m18:08:00.677732 [info ] [MainThread]:   sync_request_timeout: 5
[0m18:08:00.689510 [info ] [MainThread]:   compress_block_size: 1048576
[0m18:08:00.701097 [info ] [MainThread]:   compression: 
[0m18:08:00.709114 [info ] [MainThread]:   check_exchange: True
[0m18:08:00.720961 [info ] [MainThread]:   custom_settings: None
[0m18:08:00.734517 [info ] [MainThread]:   use_lw_deletes: False
[0m18:08:00.746057 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m18:08:00.755661 [info ] [MainThread]:   tcp_keepalive: False
[0m18:08:00.764913 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:08:00.888200 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m18:08:00.900568 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:08:01.284804 [info ] [MainThread]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:08:01.287242 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m18:08:01.296353 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:08:01.335974 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m18:08:01.341760 [info ] [MainThread]: [32mAll checks passed![0m
[0m18:08:01.347939 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 1.6832821, "process_in_blocks": "0", "process_kernel_time": 0.525111, "process_mem_max_rss": "113064", "process_out_blocks": "2133", "process_user_time": 2.965034}
[0m18:08:01.351034 [debug] [MainThread]: Command `dbt debug` succeeded at 18:08:01.350720 after 1.69 seconds
[0m18:08:01.353724 [debug] [MainThread]: Connection 'debug' was left open.
[0m18:08:01.357079 [debug] [MainThread]: On debug: Close
[0m18:08:01.360165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f9fd1850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f9ec7b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f9e99590>]}
[0m18:08:01.363726 [debug] [MainThread]: Flushing usage events
[0m18:08:01.970848 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:09:48.240566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16362cc9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1636000e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1638d6c250>]}


============================== 18:09:48.244281 | 24919748-fef7-4201-8b75-3cf2300d95f4 ==============================
[0m18:09:48.244281 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:09:48.245701 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'empty': 'False', 'debug': 'False', 'quiet': 'False', 'no_print': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'warn_error': 'None', 'version_check': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run', 'printer_width': '80', 'profiles_dir': '/dbt', 'log_path': '/dbt/logs', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'fail_fast': 'False'}
[0m18:09:48.432694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1636027750>]}
[0m18:09:48.499658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16365908d0>]}
[0m18:09:48.501433 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:09:48.580666 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:09:48.732725 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:09:48.733912 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:09:48.780810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1635b27e50>]}
[0m18:09:48.877431 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:09:48.880700 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:09:48.910930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1635dc3950>]}
[0m18:09:48.912092 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:09:48.912964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1638a7f4d0>]}
[0m18:09:48.915750 [info ] [MainThread]: 
[0m18:09:48.917094 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:09:48.918187 [info ] [MainThread]: 
[0m18:09:48.919569 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:09:48.927488 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:09:48.940625 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:09:49.061644 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:09:49.062712 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:09:49.069665 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:49.154964 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m18:09:49.162880 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:09:49.257208 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:09:49.258541 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:09:49.288345 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:09:49.306477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1638d96490>]}
[0m18:09:49.317569 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m18:09:49.319062 [info ] [Thread-1 (]: 1 of 7 START sql table model `default`.`dim_date` .............................. [RUN]
[0m18:09:49.320657 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m18:09:49.322171 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m18:09:49.331881 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m18:09:49.337227 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m18:09:49.462115 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m18:09:49.487479 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:09:49.509895 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:09:49.520598 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:49.526255 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m18:09:49.529534 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date__dbt_backup`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m18:09:49.560416 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:09:49.566121 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
EXCHANGE TABLES `default`.`dim_date__dbt_backup` AND `default`.`dim_date` 
  
  ...
[0m18:09:49.573714 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:49.603783 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  ...
[0m18:09:49.609179 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  
[0m18:09:49.610865 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:09:49.617557 [debug] [Thread-1 (]: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.ef8cdcd6-3f79-4792-8081-da86c6fc98e4.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m18:09:49.619618 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1635ff9150>]}
[0m18:09:49.620936 [error] [Thread-1 (]: 1 of 7 ERROR creating sql table model `default`.`dim_date` ..................... [[31mERROR[0m in 0.30s]
[0m18:09:49.622394 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m18:09:49.623559 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m18:09:49.624291 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_date' to be skipped because of status 'error'.  Reason: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.ef8cdcd6-3f79-4792-8081-da86c6fc98e4.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql.
[0m18:09:49.625347 [info ] [Thread-1 (]: 2 of 7 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m18:09:49.628128 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m18:09:49.628850 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m18:09:49.632697 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:09:49.636277 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m18:09:49.641501 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:09:49.667529 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:09:49.671989 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:09:49.681078 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:49.683675 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:09:49.686969 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:09:49.717332 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:09:49.719441 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
EXCHANGE TABLES `default`.`dim_payment__dbt_backup` AND `default`.`dim_payment` 
  
  ...
[0m18:09:49.728511 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:49.733630 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  ...
[0m18:09:49.739723 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  
[0m18:09:49.741166 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:09:49.745561 [debug] [Thread-1 (]: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.68128245-a25f-49aa-bfb3-bcaf4a2d3444.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m18:09:49.746692 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1634ccd8d0>]}
[0m18:09:49.748562 [error] [Thread-1 (]: 2 of 7 ERROR creating sql table model `default`.`dim_payment` .................. [[31mERROR[0m in 0.12s]
[0m18:09:49.750206 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m18:09:49.751311 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m18:09:49.751831 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_payment' to be skipped because of status 'error'.  Reason: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.68128245-a25f-49aa-bfb3-bcaf4a2d3444.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql.
[0m18:09:49.753027 [info ] [Thread-1 (]: 3 of 7 START sql table model `default`.`dim_product` ........................... [RUN]
[0m18:09:49.755289 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m18:09:49.756433 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m18:09:49.760140 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m18:09:49.762726 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m18:09:49.767193 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:09:49.788754 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:09:49.798143 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:09:49.809149 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:49.811695 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m18:09:49.814532 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:09:49.837305 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:09:49.839523 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
EXCHANGE TABLES `default`.`dim_product__dbt_backup` AND `default`.`dim_product` 
  
  ...
[0m18:09:49.851150 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:49.855778 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  ...
[0m18:09:49.861439 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  
[0m18:09:49.862520 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:09:49.866357 [debug] [Thread-1 (]: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.87e5412a-6f15-40a3-8962-fec884270f92.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m18:09:49.867505 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1634130490>]}
[0m18:09:49.868772 [error] [Thread-1 (]: 3 of 7 ERROR creating sql table model `default`.`dim_product` .................. [[31mERROR[0m in 0.11s]
[0m18:09:49.870270 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m18:09:49.871570 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m18:09:49.872224 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_product' to be skipped because of status 'error'.  Reason: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.87e5412a-6f15-40a3-8962-fec884270f92.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql.
[0m18:09:49.873063 [info ] [Thread-1 (]: 4 of 7 START sql table model `default`.`dim_store` ............................. [RUN]
[0m18:09:49.874499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m18:09:49.875273 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m18:09:49.878258 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m18:09:49.880320 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m18:09:49.884549 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m18:09:49.910381 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:09:49.916256 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:09:49.924788 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:49.927451 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m18:09:49.929393 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store__dbt_backup`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m18:09:49.962185 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:09:49.964324 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
EXCHANGE TABLES `default`.`dim_store__dbt_backup` AND `default`.`dim_store` 
  
  ...
[0m18:09:49.971118 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:49.975125 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  ...
[0m18:09:49.978968 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  
[0m18:09:49.980215 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:09:49.986139 [debug] [Thread-1 (]: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.b8aa5506-c8ef-4755-a543-933509c12c23.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m18:09:49.987750 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f163611b890>]}
[0m18:09:49.989228 [error] [Thread-1 (]: 4 of 7 ERROR creating sql table model `default`.`dim_store` .................... [[31mERROR[0m in 0.11s]
[0m18:09:49.991314 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m18:09:49.992606 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m18:09:49.993334 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_store' to be skipped because of status 'error'.  Reason: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.b8aa5506-c8ef-4755-a543-933509c12c23.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql.
[0m18:09:49.994252 [info ] [Thread-1 (]: 5 of 7 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m18:09:49.996177 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m18:09:49.997200 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m18:09:50.000770 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:09:50.004057 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m18:09:50.008617 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m18:09:50.025254 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:09:50.031518 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:09:50.044293 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:50.048259 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:09:50.052055 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier__dbt_backup`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m18:09:50.077436 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:09:50.079231 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
EXCHANGE TABLES `default`.`dim_supplier__dbt_backup` AND `default`.`dim_supplier` 
  
  ...
[0m18:09:50.089676 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:50.094642 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  ...
[0m18:09:50.099643 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  
[0m18:09:50.101187 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:09:50.105268 [debug] [Thread-1 (]: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.1b05bf23-62a0-44fe-8a7c-8bcb5ca06052.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m18:09:50.106366 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16341afc90>]}
[0m18:09:50.107685 [error] [Thread-1 (]: 5 of 7 ERROR creating sql table model `default`.`dim_supplier` ................. [[31mERROR[0m in 0.11s]
[0m18:09:50.109485 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m18:09:50.110598 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:09:50.111454 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_supplier' to be skipped because of status 'error'.  Reason: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.1b05bf23-62a0-44fe-8a7c-8bcb5ca06052.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql.
[0m18:09:50.112407 [info ] [Thread-1 (]: 6 of 7 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m18:09:50.114413 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m18:09:50.115368 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:09:50.119538 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:09:50.122833 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:09:50.127239 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m18:09:50.160103 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:09:50.165020 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:09:50.172675 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:50.175704 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:09:50.178184 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m18:09:50.204680 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:09:50.207102 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
EXCHANGE TABLES `default`.`stg_dim_customer__dbt_backup` AND `default`.`stg_dim_customer` 
  
  ...
[0m18:09:50.216002 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:09:50.219878 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  ...
[0m18:09:50.223539 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  
[0m18:09:50.224446 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:09:50.228509 [debug] [Thread-1 (]: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.ee6aa609-0716-4759-8eed-2c3911afe08c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m18:09:50.229476 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24919748-fef7-4201-8b75-3cf2300d95f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1634ce9990>]}
[0m18:09:50.230938 [error] [Thread-1 (]: 6 of 7 ERROR creating sql table model `default`.`stg_dim_customer` ............. [[31mERROR[0m in 0.12s]
[0m18:09:50.232554 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:09:50.233781 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.stg_dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.ee6aa609-0716-4759-8eed-2c3911afe08c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql.
[0m18:09:50.235338 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m18:09:50.236288 [info ] [Thread-1 (]: 7 of 7 SKIP relation default.dim_customer ...................................... [[33mSKIP[0m]
[0m18:09:50.237512 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m18:09:50.240666 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:09:50.241640 [debug] [MainThread]: Connection 'list_' was left open.
[0m18:09:50.242356 [debug] [MainThread]: On list_: Close
[0m18:09:50.243246 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.stg_dim_customer' was left open.
[0m18:09:50.244226 [debug] [MainThread]: On model.clickhouse_dbt_demo.stg_dim_customer: Close
[0m18:09:50.245284 [info ] [MainThread]: 
[0m18:09:50.246244 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 1.33 seconds (1.33s).
[0m18:09:50.248606 [debug] [MainThread]: Command end result
[0m18:09:50.304668 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:09:50.308956 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:09:50.317652 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:09:50.318596 [info ] [MainThread]: 
[0m18:09:50.319419 [info ] [MainThread]: [31mCompleted with 6 errors, 0 partial successes, and 0 warnings:[0m
[0m18:09:50.320333 [info ] [MainThread]: 
[0m18:09:50.321317 [error] [MainThread]: [31mFailure in model dim_date (models/marts/dim_date.sql)[0m
[0m18:09:50.322186 [error] [MainThread]:   Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.ef8cdcd6-3f79-4792-8081-da86c6fc98e4.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m18:09:50.322989 [info ] [MainThread]: 
[0m18:09:50.323991 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m18:09:50.324759 [info ] [MainThread]: 
[0m18:09:50.325732 [error] [MainThread]: [31mFailure in model dim_payment (models/marts/dim_payment.sql)[0m
[0m18:09:50.327098 [error] [MainThread]:   Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.68128245-a25f-49aa-bfb3-bcaf4a2d3444.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m18:09:50.328421 [info ] [MainThread]: 
[0m18:09:50.329325 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m18:09:50.330328 [info ] [MainThread]: 
[0m18:09:50.331558 [error] [MainThread]: [31mFailure in model dim_product (models/marts/dim_product.sql)[0m
[0m18:09:50.332666 [error] [MainThread]:   Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.87e5412a-6f15-40a3-8962-fec884270f92.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m18:09:50.334041 [info ] [MainThread]: 
[0m18:09:50.335189 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m18:09:50.336333 [info ] [MainThread]: 
[0m18:09:50.337334 [error] [MainThread]: [31mFailure in model dim_store (models/marts/dim_store.sql)[0m
[0m18:09:50.338172 [error] [MainThread]:   Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.b8aa5506-c8ef-4755-a543-933509c12c23.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m18:09:50.339347 [info ] [MainThread]: 
[0m18:09:50.340802 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m18:09:50.342081 [info ] [MainThread]: 
[0m18:09:50.343660 [error] [MainThread]: [31mFailure in model dim_supplier (models/marts/dim_supplier.sql)[0m
[0m18:09:50.345110 [error] [MainThread]:   Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.1b05bf23-62a0-44fe-8a7c-8bcb5ca06052.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m18:09:50.346519 [info ] [MainThread]: 
[0m18:09:50.348162 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m18:09:50.349502 [info ] [MainThread]: 
[0m18:09:50.351239 [error] [MainThread]: [31mFailure in model stg_dim_customer (models/staging/stg_dim_customer.sql)[0m
[0m18:09:50.352413 [error] [MainThread]:   Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/1fd/1fdeb73b-477c-49af-b44c-e30aef565680/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.ee6aa609-0716-4759-8eed-2c3911afe08c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m18:09:50.354124 [info ] [MainThread]: 
[0m18:09:50.355353 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m18:09:50.357535 [info ] [MainThread]: 
[0m18:09:50.360285 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=6 SKIP=1 NO-OP=0 TOTAL=7
[0m18:09:50.363042 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.1848865, "process_in_blocks": "0", "process_kernel_time": 0.373084, "process_mem_max_rss": "121384", "process_out_blocks": "2378", "process_user_time": 2.784024}
[0m18:09:50.364113 [debug] [MainThread]: Command `dbt run` failed at 18:09:50.363808 after 2.19 seconds
[0m18:09:50.364948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f163aae5590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1638d6f9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f163619da10>]}
[0m18:09:50.365636 [debug] [MainThread]: Flushing usage events
[0m18:09:51.088542 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:14:33.724596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b8dacc510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b8e24eb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b8dacd690>]}


============================== 18:14:33.732005 | d639e1d7-5272-4293-9d8c-03bfd511a8d9 ==============================
[0m18:14:33.732005 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:14:33.734085 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'profiles_dir': '/dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'partial_parse': 'True', 'log_path': '/dbt/logs', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_format': 'default', 'introspect': 'True', 'version_check': 'True', 'empty': 'None', 'invocation_command': 'dbt debug', 'target_path': 'None', 'cache_selected_only': 'False', 'debug': 'False', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error': 'None', 'use_colors': 'True', 'no_print': 'None', 'printer_width': '80', 'log_cache_events': 'False', 'fail_fast': 'False'}
[0m18:14:33.749900 [info ] [MainThread]: dbt version: 1.10.13
[0m18:14:33.751380 [info ] [MainThread]: python version: 3.11.14
[0m18:14:33.753299 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m18:14:33.754762 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m18:14:33.834753 [info ] [MainThread]: Using profiles dir at /dbt
[0m18:14:33.836086 [info ] [MainThread]: Using profiles.yml file at /dbt/profiles.yml
[0m18:14:33.837260 [info ] [MainThread]: Using dbt_project.yml file at /dbt/dbt_project.yml
[0m18:14:33.839133 [info ] [MainThread]: adapter type: clickhouse
[0m18:14:33.840932 [info ] [MainThread]: adapter version: 1.9.5
[0m18:14:33.989904 [info ] [MainThread]: Configuration:
[0m18:14:33.991639 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:14:33.993160 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:14:33.994650 [info ] [MainThread]: Required dependencies:
[0m18:14:33.996344 [debug] [MainThread]: Executing "git --help"
[0m18:14:34.000685 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:14:34.001837 [debug] [MainThread]: STDERR: "b''"
[0m18:14:34.003061 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:14:34.004661 [info ] [MainThread]: Connection:
[0m18:14:34.005868 [info ] [MainThread]:   driver: None
[0m18:14:34.007348 [info ] [MainThread]:   host: clickhouse-server
[0m18:14:34.011966 [info ] [MainThread]:   port: 8123
[0m18:14:34.013459 [info ] [MainThread]:   user: default
[0m18:14:34.014759 [info ] [MainThread]:   schema: default
[0m18:14:34.016151 [info ] [MainThread]:   retries: 1
[0m18:14:34.017588 [info ] [MainThread]:   cluster: None
[0m18:14:34.018546 [info ] [MainThread]:   database_engine: None
[0m18:14:34.019889 [info ] [MainThread]:   cluster_mode: False
[0m18:14:34.021168 [info ] [MainThread]:   secure: False
[0m18:14:34.022544 [info ] [MainThread]:   verify: True
[0m18:14:34.023734 [info ] [MainThread]:   client_cert: None
[0m18:14:34.025032 [info ] [MainThread]:   client_cert_key: None
[0m18:14:34.026391 [info ] [MainThread]:   connect_timeout: 10
[0m18:14:34.027793 [info ] [MainThread]:   send_receive_timeout: 300
[0m18:14:34.032727 [info ] [MainThread]:   sync_request_timeout: 5
[0m18:14:34.036212 [info ] [MainThread]:   compress_block_size: 1048576
[0m18:14:34.038952 [info ] [MainThread]:   compression: 
[0m18:14:34.041754 [info ] [MainThread]:   check_exchange: True
[0m18:14:34.043296 [info ] [MainThread]:   custom_settings: None
[0m18:14:34.044995 [info ] [MainThread]:   use_lw_deletes: False
[0m18:14:34.047288 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m18:14:34.048788 [info ] [MainThread]:   tcp_keepalive: False
[0m18:14:34.050821 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:14:34.225959 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m18:14:34.232182 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:14:34.437004 [debug] [MainThread]: dbt_clickhouse adapter: Got a retryable error when attempting to open a clickhouse connection.
1 attempts remaining. Retrying in 1 seconds.
Error:
Error HTTPConnectionPool(host='clickhouse-server', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7b8d6b4e50>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://clickhouse-server:8123)
[0m18:14:35.564728 [info ] [MainThread]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:14:35.566317 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m18:14:35.572425 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:14:35.606315 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m18:14:35.608058 [info ] [MainThread]: [32mAll checks passed![0m
[0m18:14:35.611793 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 1.9668038, "process_in_blocks": "0", "process_kernel_time": 0.53401, "process_mem_max_rss": "112908", "process_out_blocks": "2134", "process_user_time": 2.972508}
[0m18:14:35.613421 [debug] [MainThread]: Command `dbt debug` succeeded at 18:14:35.613168 after 1.97 seconds
[0m18:14:35.614730 [debug] [MainThread]: Connection 'debug' was left open.
[0m18:14:35.615786 [debug] [MainThread]: On debug: Close
[0m18:14:35.616865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b8dacc510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b8dacd790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b8d70c4d0>]}
[0m18:14:35.618419 [debug] [MainThread]: Flushing usage events
[0m18:14:36.179990 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:14:52.571626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7ca6ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7cd34290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7ca6ff90>]}


============================== 18:14:52.575636 | 647e1bfd-94ed-4f1e-91b7-f7bebd24caa4 ==============================
[0m18:14:52.575636 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:14:52.576813 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'no_print': 'None', 'partial_parse': 'True', 'target_path': 'None', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'indirect_selection': 'eager', 'log_path': '/dbt/logs', 'warn_error': 'None', 'printer_width': '80', 'write_json': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'empty': 'False', 'use_colors': 'True', 'fail_fast': 'False', 'profiles_dir': '/dbt', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default'}
[0m18:14:52.798254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7cb4ef90>]}
[0m18:14:52.867601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7d19c990>]}
[0m18:14:52.869353 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:14:52.944573 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:14:53.135768 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:14:53.136618 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:14:53.175584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7ca5db90>]}
[0m18:14:53.266366 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:14:53.269618 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:14:53.292676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7cab1050>]}
[0m18:14:53.293634 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:14:53.294709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7c85b550>]}
[0m18:14:53.297916 [info ] [MainThread]: 
[0m18:14:53.299198 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:14:53.300588 [info ] [MainThread]: 
[0m18:14:53.302460 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:14:53.311220 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:14:53.324075 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:14:53.434217 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:14:53.435963 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:14:53.443921 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:14:53.525980 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m18:14:53.532757 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:14:53.551227 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:14:53.554453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7c7f8810>]}
[0m18:14:53.563408 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m18:14:53.564529 [info ] [Thread-1 (]: 1 of 7 START sql table model `default`.`dim_date` .............................. [RUN]
[0m18:14:53.565492 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m18:14:53.566266 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m18:14:53.574365 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m18:14:53.577039 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m18:14:53.603565 [debug] [Thread-1 (]: Creating new relation dim_date
[0m18:14:53.660930 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m18:14:53.666018 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        
[0m18:14:53.673916 [debug] [Thread-1 (]: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_date' in scope SELECT * FROM default.stg_dim_date. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:14:53.676232 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7d18b810>]}
[0m18:14:53.677567 [error] [Thread-1 (]: 1 of 7 ERROR creating sql table model `default`.`dim_date` ..................... [[31mERROR[0m in 0.11s]
[0m18:14:53.679063 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m18:14:53.680430 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m18:14:53.681266 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_date' to be skipped because of status 'error'.  Reason: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_date' in scope SELECT * FROM default.stg_dim_date. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:14:53.682543 [info ] [Thread-1 (]: 2 of 7 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m18:14:53.686741 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m18:14:53.688478 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m18:14:53.693672 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:14:53.697646 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m18:14:53.701789 [debug] [Thread-1 (]: Creating new relation dim_payment
[0m18:14:53.704177 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:14:53.709679 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        
[0m18:14:53.757470 [debug] [Thread-1 (]: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:14:53.760376 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7cab2350>]}
[0m18:14:53.764669 [error] [Thread-1 (]: 2 of 7 ERROR creating sql table model `default`.`dim_payment` .................. [[31mERROR[0m in 0.07s]
[0m18:14:53.767709 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m18:14:53.769595 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m18:14:53.770802 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_payment' to be skipped because of status 'error'.  Reason: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:14:53.771875 [info ] [Thread-1 (]: 3 of 7 START sql table model `default`.`dim_product` ........................... [RUN]
[0m18:14:53.774665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m18:14:53.776287 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m18:14:53.781713 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m18:14:53.784830 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m18:14:53.790308 [debug] [Thread-1 (]: Creating new relation dim_product
[0m18:14:53.792523 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:14:53.799422 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        
[0m18:14:53.806573 [debug] [Thread-1 (]: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:14:53.808237 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7c81bc10>]}
[0m18:14:53.810128 [error] [Thread-1 (]: 3 of 7 ERROR creating sql table model `default`.`dim_product` .................. [[31mERROR[0m in 0.03s]
[0m18:14:53.811708 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m18:14:53.813395 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m18:14:53.814140 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_product' to be skipped because of status 'error'.  Reason: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:14:53.815225 [info ] [Thread-1 (]: 4 of 7 START sql table model `default`.`dim_store` ............................. [RUN]
[0m18:14:53.816864 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m18:14:53.817743 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m18:14:53.821244 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m18:14:53.823591 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m18:14:53.826580 [debug] [Thread-1 (]: Creating new relation dim_store
[0m18:14:53.828176 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m18:14:53.833328 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        
[0m18:14:53.840338 [debug] [Thread-1 (]: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_store' in scope SELECT * FROM default.stg_dim_store. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:14:53.842069 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7faa4cd0>]}
[0m18:14:53.843692 [error] [Thread-1 (]: 4 of 7 ERROR creating sql table model `default`.`dim_store` .................... [[31mERROR[0m in 0.03s]
[0m18:14:53.845475 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m18:14:53.847226 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m18:14:53.848030 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_store' to be skipped because of status 'error'.  Reason: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_store' in scope SELECT * FROM default.stg_dim_store. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:14:53.849581 [info ] [Thread-1 (]: 5 of 7 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m18:14:53.853825 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m18:14:53.855398 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m18:14:53.859994 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:14:53.862676 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m18:14:53.866151 [debug] [Thread-1 (]: Creating new relation dim_supplier
[0m18:14:53.868522 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m18:14:53.873366 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        
[0m18:14:53.877666 [debug] [Thread-1 (]: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_supplier' in scope SELECT * FROM default.stg_dim_supplier. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:14:53.878740 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7d1f6c10>]}
[0m18:14:53.879719 [error] [Thread-1 (]: 5 of 7 ERROR creating sql table model `default`.`dim_supplier` ................. [[31mERROR[0m in 0.03s]
[0m18:14:53.880741 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m18:14:53.881475 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:14:53.883620 [info ] [Thread-1 (]: 6 of 7 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m18:14:53.881978 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_supplier' to be skipped because of status 'error'.  Reason: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_supplier' in scope SELECT * FROM default.stg_dim_supplier. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:14:53.885765 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m18:14:53.888455 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:14:53.893828 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:14:53.898527 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:14:53.902153 [debug] [Thread-1 (]: Creating new relation stg_dim_customer
[0m18:14:53.904793 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m18:14:53.923538 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:14:53.953275 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:14:53.966393 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:14:53.980917 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:14:53.988281 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m18:14:54.016896 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:14:54.045141 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7b8e7b50>]}
[0m18:14:54.051028 [info ] [Thread-1 (]: 6 of 7 OK created sql table model `default`.`stg_dim_customer` ................. [[32mOK[0m in 0.16s]
[0m18:14:54.066122 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:14:54.078938 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m18:14:54.082582 [info ] [Thread-1 (]: 7 of 7 START sql table model `default`.`dim_customer` .......................... [RUN]
[0m18:14:54.085357 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.stg_dim_customer, now model.clickhouse_dbt_demo.dim_customer)
[0m18:14:54.086813 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_customer
[0m18:14:54.097573 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_customer"
[0m18:14:54.180430 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_customer
[0m18:14:54.219723 [debug] [Thread-1 (]: Creating new relation dim_customer
[0m18:14:54.223504 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

            

    
        create table `default`.`dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
          )
        
        ...
[0m18:14:54.288335 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m18:14:54.310912 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:14:54.331421 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:14:54.340229 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_customer"
[0m18:14:54.347207 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`dim_customer`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
  ...
[0m18:14:54.401767 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m18:14:54.406289 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '647e1bfd-94ed-4f1e-91b7-f7bebd24caa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7b7f0a50>]}
[0m18:14:54.408185 [info ] [Thread-1 (]: 7 of 7 OK created sql table model `default`.`dim_customer` ..................... [[32mOK[0m in 0.32s]
[0m18:14:54.410927 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m18:14:54.415274 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:14:54.416598 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.dim_customer' was left open.
[0m18:14:54.417705 [debug] [MainThread]: On model.clickhouse_dbt_demo.dim_customer: Close
[0m18:14:54.419511 [info ] [MainThread]: 
[0m18:14:54.420753 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 1.12 seconds (1.12s).
[0m18:14:54.423637 [debug] [MainThread]: Command end result
[0m18:14:54.638664 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:14:54.644898 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:14:54.660696 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:14:54.661962 [info ] [MainThread]: 
[0m18:14:54.663373 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m18:14:54.664437 [info ] [MainThread]: 
[0m18:14:54.665777 [error] [MainThread]: [31mFailure in model dim_date (models/marts/dim_date.sql)[0m
[0m18:14:54.666904 [error] [MainThread]:   Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_date' in scope SELECT * FROM default.stg_dim_date. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:14:54.668212 [info ] [MainThread]: 
[0m18:14:54.669546 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m18:14:54.671267 [info ] [MainThread]: 
[0m18:14:54.672514 [error] [MainThread]: [31mFailure in model dim_payment (models/marts/dim_payment.sql)[0m
[0m18:14:54.673502 [error] [MainThread]:   Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:14:54.674395 [info ] [MainThread]: 
[0m18:14:54.675413 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m18:14:54.676399 [info ] [MainThread]: 
[0m18:14:54.677301 [error] [MainThread]: [31mFailure in model dim_product (models/marts/dim_product.sql)[0m
[0m18:14:54.678241 [error] [MainThread]:   Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:14:54.679047 [info ] [MainThread]: 
[0m18:14:54.680114 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m18:14:54.680871 [info ] [MainThread]: 
[0m18:14:54.682129 [error] [MainThread]: [31mFailure in model dim_store (models/marts/dim_store.sql)[0m
[0m18:14:54.683562 [error] [MainThread]:   Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_store' in scope SELECT * FROM default.stg_dim_store. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:14:54.685293 [info ] [MainThread]: 
[0m18:14:54.686864 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m18:14:54.688476 [info ] [MainThread]: 
[0m18:14:54.690401 [error] [MainThread]: [31mFailure in model dim_supplier (models/marts/dim_supplier.sql)[0m
[0m18:14:54.691965 [error] [MainThread]:   Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_supplier' in scope SELECT * FROM default.stg_dim_supplier. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:14:54.693701 [info ] [MainThread]: 
[0m18:14:54.695556 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m18:14:54.697579 [info ] [MainThread]: 
[0m18:14:54.699410 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=5 SKIP=0 NO-OP=0 TOTAL=7
[0m18:14:54.704718 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.1995747, "process_in_blocks": "0", "process_kernel_time": 0.426584, "process_mem_max_rss": "120544", "process_out_blocks": "2344", "process_user_time": 3.034691}
[0m18:14:54.707538 [debug] [MainThread]: Command `dbt run` failed at 18:14:54.707238 after 2.20 seconds
[0m18:14:54.708652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7ca8fe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7b87b150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d81601310>]}
[0m18:14:54.709510 [debug] [MainThread]: Flushing usage events
[0m18:14:55.356750 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:15:32.599427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389fb03b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a18a49d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389fb01a90>]}


============================== 18:15:32.603300 | 5ef7c35e-540f-45cf-894a-9438a045996c ==============================
[0m18:15:32.603300 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:15:32.604688 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'invocation_command': 'dbt run', 'log_format': 'default', 'quiet': 'False', 'log_path': '/dbt/logs', 'no_print': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'printer_width': '80', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'write_json': 'True', 'empty': 'False', 'debug': 'False', 'target_path': 'None', 'partial_parse': 'True', 'profiles_dir': '/dbt', 'indirect_selection': 'eager', 'use_colors': 'True', 'introspect': 'True', 'warn_error': 'None'}
[0m18:15:32.784476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a0986a90>]}
[0m18:15:32.846260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a0094890>]}
[0m18:15:32.847785 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:15:32.923921 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:15:33.043487 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:15:33.044367 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:15:33.083415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389fb40d10>]}
[0m18:15:33.177733 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:15:33.180986 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:15:33.197896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389f8e0810>]}
[0m18:15:33.199183 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:15:33.200266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389f70e750>]}
[0m18:15:33.203591 [info ] [MainThread]: 
[0m18:15:33.204574 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:15:33.205510 [info ] [MainThread]: 
[0m18:15:33.207024 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:15:33.215176 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:15:33.227216 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:15:33.342511 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:15:33.343698 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:15:33.351750 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:15:33.436058 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m18:15:33.443552 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:15:33.518611 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:15:33.519937 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:15:33.530291 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:15:33.537781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389f6f9f90>]}
[0m18:15:33.543063 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m18:15:33.544712 [info ] [Thread-1 (]: 1 of 7 START sql table model `default`.`dim_date` .............................. [RUN]
[0m18:15:33.546222 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m18:15:33.547306 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m18:15:33.555862 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m18:15:33.559600 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m18:15:33.582701 [debug] [Thread-1 (]: Creating new relation dim_date
[0m18:15:33.632525 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m18:15:33.637159 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        
[0m18:15:33.644976 [debug] [Thread-1 (]: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_date' in scope SELECT * FROM default.stg_dim_date. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:15:33.647447 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389e6683d0>]}
[0m18:15:33.648978 [error] [Thread-1 (]: 1 of 7 ERROR creating sql table model `default`.`dim_date` ..................... [[31mERROR[0m in 0.10s]
[0m18:15:33.650655 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m18:15:33.651860 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m18:15:33.652589 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_date' to be skipped because of status 'error'.  Reason: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_date' in scope SELECT * FROM default.stg_dim_date. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:15:33.653836 [info ] [Thread-1 (]: 2 of 7 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m18:15:33.657505 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m18:15:33.658835 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m18:15:33.664955 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:15:33.668011 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m18:15:33.671177 [debug] [Thread-1 (]: Creating new relation dim_payment
[0m18:15:33.673638 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:15:33.678541 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        
[0m18:15:33.684851 [debug] [Thread-1 (]: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:15:33.686671 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a17389d0>]}
[0m18:15:33.690496 [error] [Thread-1 (]: 2 of 7 ERROR creating sql table model `default`.`dim_payment` .................. [[31mERROR[0m in 0.03s]
[0m18:15:33.694088 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m18:15:33.695979 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m18:15:33.697531 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_payment' to be skipped because of status 'error'.  Reason: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:15:33.699001 [info ] [Thread-1 (]: 3 of 7 START sql table model `default`.`dim_product` ........................... [RUN]
[0m18:15:33.701461 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m18:15:33.702783 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m18:15:33.708659 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m18:15:33.712459 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m18:15:33.715939 [debug] [Thread-1 (]: Creating new relation dim_product
[0m18:15:33.717908 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:15:33.723376 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        
[0m18:15:33.727906 [debug] [Thread-1 (]: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:15:33.729102 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389e666610>]}
[0m18:15:33.733116 [error] [Thread-1 (]: 3 of 7 ERROR creating sql table model `default`.`dim_product` .................. [[31mERROR[0m in 0.03s]
[0m18:15:33.736724 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m18:15:33.739573 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m18:15:33.741146 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_product' to be skipped because of status 'error'.  Reason: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:15:33.742931 [info ] [Thread-1 (]: 4 of 7 START sql table model `default`.`dim_store` ............................. [RUN]
[0m18:15:33.746431 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m18:15:33.748332 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m18:15:33.753454 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m18:15:33.787753 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m18:15:33.803295 [debug] [Thread-1 (]: Creating new relation dim_store
[0m18:15:33.806804 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m18:15:33.814102 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        
[0m18:15:33.820159 [debug] [Thread-1 (]: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_store' in scope SELECT * FROM default.stg_dim_store. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:15:33.821488 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389e6a8cd0>]}
[0m18:15:33.822677 [error] [Thread-1 (]: 4 of 7 ERROR creating sql table model `default`.`dim_store` .................... [[31mERROR[0m in 0.08s]
[0m18:15:33.824002 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m18:15:33.825477 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m18:15:33.826832 [info ] [Thread-1 (]: 5 of 7 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m18:15:33.825978 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_store' to be skipped because of status 'error'.  Reason: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_store' in scope SELECT * FROM default.stg_dim_store. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:15:33.828407 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m18:15:33.830323 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m18:15:33.834664 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:15:33.837998 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m18:15:33.841462 [debug] [Thread-1 (]: Creating new relation dim_supplier
[0m18:15:33.843707 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m18:15:33.849301 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        
[0m18:15:33.854718 [debug] [Thread-1 (]: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_supplier' in scope SELECT * FROM default.stg_dim_supplier. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:15:33.855809 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389f379310>]}
[0m18:15:33.857056 [error] [Thread-1 (]: 5 of 7 ERROR creating sql table model `default`.`dim_supplier` ................. [[31mERROR[0m in 0.03s]
[0m18:15:33.858766 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m18:15:33.860053 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:15:33.862550 [info ] [Thread-1 (]: 6 of 7 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m18:15:33.861287 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_supplier' to be skipped because of status 'error'.  Reason: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_supplier' in scope SELECT * FROM default.stg_dim_supplier. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:15:33.864053 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m18:15:33.866446 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:15:33.869633 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:15:33.872321 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:15:33.881000 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m18:15:33.909069 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:15:33.933652 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:15:33.942928 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:15:33.949891 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:15:33.953880 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m18:15:33.975334 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:15:33.981625 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
EXCHANGE TABLES `default`.`stg_dim_customer__dbt_backup` AND `default`.`stg_dim_customer` 
  
  ...
[0m18:15:33.994315 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:15:34.025341 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  ...
[0m18:15:34.030817 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  
[0m18:15:34.032472 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:15:34.040430 [debug] [Thread-1 (]: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.b79d1bf5-5b44-44b9-8954-245dcaa0ae3c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m18:15:34.042155 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ef7c35e-540f-45cf-894a-9438a045996c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389e531cd0>]}
[0m18:15:34.044320 [error] [Thread-1 (]: 6 of 7 ERROR creating sql table model `default`.`stg_dim_customer` ............. [[31mERROR[0m in 0.18s]
[0m18:15:34.046450 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:15:34.048451 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.stg_dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.b79d1bf5-5b44-44b9-8954-245dcaa0ae3c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql.
[0m18:15:34.050425 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m18:15:34.051889 [info ] [Thread-1 (]: 7 of 7 SKIP relation default.dim_customer ...................................... [[33mSKIP[0m]
[0m18:15:34.053498 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m18:15:34.056730 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:15:34.057641 [debug] [MainThread]: Connection 'list_' was left open.
[0m18:15:34.058571 [debug] [MainThread]: On list_: Close
[0m18:15:34.059324 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.stg_dim_customer' was left open.
[0m18:15:34.060240 [debug] [MainThread]: On model.clickhouse_dbt_demo.stg_dim_customer: Close
[0m18:15:34.061458 [info ] [MainThread]: 
[0m18:15:34.062369 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 0.85 seconds (0.85s).
[0m18:15:34.064616 [debug] [MainThread]: Command end result
[0m18:15:34.122331 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:15:34.125643 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:15:34.134829 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:15:34.135998 [info ] [MainThread]: 
[0m18:15:34.137274 [info ] [MainThread]: [31mCompleted with 6 errors, 0 partial successes, and 0 warnings:[0m
[0m18:15:34.138553 [info ] [MainThread]: 
[0m18:15:34.139911 [error] [MainThread]: [31mFailure in model dim_date (models/marts/dim_date.sql)[0m
[0m18:15:34.141574 [error] [MainThread]:   Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_date' in scope SELECT * FROM default.stg_dim_date. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:15:34.143744 [info ] [MainThread]: 
[0m18:15:34.145065 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m18:15:34.146607 [info ] [MainThread]: 
[0m18:15:34.148416 [error] [MainThread]: [31mFailure in model dim_payment (models/marts/dim_payment.sql)[0m
[0m18:15:34.149971 [error] [MainThread]:   Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:15:34.151461 [info ] [MainThread]: 
[0m18:15:34.152872 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m18:15:34.154753 [info ] [MainThread]: 
[0m18:15:34.156415 [error] [MainThread]: [31mFailure in model dim_product (models/marts/dim_product.sql)[0m
[0m18:15:34.157621 [error] [MainThread]:   Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_product' in scope SELECT * FROM default.stg_dim_product. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:15:34.158997 [info ] [MainThread]: 
[0m18:15:34.160347 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m18:15:34.161176 [info ] [MainThread]: 
[0m18:15:34.162289 [error] [MainThread]: [31mFailure in model dim_store (models/marts/dim_store.sql)[0m
[0m18:15:34.163288 [error] [MainThread]:   Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_store' in scope SELECT * FROM default.stg_dim_store. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:15:34.164177 [info ] [MainThread]: 
[0m18:15:34.165245 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m18:15:34.166151 [info ] [MainThread]: 
[0m18:15:34.167162 [error] [MainThread]: [31mFailure in model dim_supplier (models/marts/dim_supplier.sql)[0m
[0m18:15:34.168170 [error] [MainThread]:   Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'default.stg_dim_supplier' in scope SELECT * FROM default.stg_dim_supplier. (UNKNOWN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:15:34.168969 [info ] [MainThread]: 
[0m18:15:34.170016 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m18:15:34.170819 [info ] [MainThread]: 
[0m18:15:34.171990 [error] [MainThread]: [31mFailure in model stg_dim_customer (models/staging/stg_dim_customer.sql)[0m
[0m18:15:34.173232 [error] [MainThread]:   Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.b79d1bf5-5b44-44b9-8954-245dcaa0ae3c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m18:15:34.175074 [info ] [MainThread]: 
[0m18:15:34.177892 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m18:15:34.179976 [info ] [MainThread]: 
[0m18:15:34.181636 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=6 SKIP=1 NO-OP=0 TOTAL=7
[0m18:15:34.183780 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6444154, "process_in_blocks": "0", "process_kernel_time": 0.346838, "process_mem_max_rss": "120268", "process_out_blocks": "2225", "process_user_time": 2.752831}
[0m18:15:34.184821 [debug] [MainThread]: Command `dbt run` failed at 18:15:34.184648 after 1.65 seconds
[0m18:15:34.185795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389fa29990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a18f9910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a0b38a50>]}
[0m18:15:34.186701 [debug] [MainThread]: Flushing usage events
[0m18:15:34.842233 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:16:44.075999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1dfc41d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1dfb9ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1dfba1d0>]}


============================== 18:16:44.080714 | 8262553f-193e-4910-addf-1fa4edf49fb5 ==============================
[0m18:16:44.080714 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:16:44.081769 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'log_path': '/dbt/logs', 'use_colors': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'invocation_command': 'dbt seed', 'cache_selected_only': 'False', 'quiet': 'False', 'version_check': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'empty': 'None', 'log_cache_events': 'False', 'warn_error': 'None', 'write_json': 'True', 'log_format': 'default', 'no_print': 'None', 'profiles_dir': '/dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'introspect': 'True'}
[0m18:16:44.280390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8262553f-193e-4910-addf-1fa4edf49fb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1e591d10>]}
[0m18:16:44.344572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8262553f-193e-4910-addf-1fa4edf49fb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1e53c8d0>]}
[0m18:16:44.346016 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:16:44.421794 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:16:44.550595 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:16:44.551427 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:16:44.591899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8262553f-193e-4910-addf-1fa4edf49fb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1da30190>]}
[0m18:16:44.694226 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:16:44.699223 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:16:44.715806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8262553f-193e-4910-addf-1fa4edf49fb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1dc16710>]}
[0m18:16:44.716801 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:16:44.717660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8262553f-193e-4910-addf-1fa4edf49fb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1ddb10d0>]}
[0m18:16:44.720212 [info ] [MainThread]: 
[0m18:16:44.721161 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:16:44.722149 [info ] [MainThread]: 
[0m18:16:44.723858 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:16:44.732131 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:16:44.744344 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:16:44.848223 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:16:44.849434 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:16:44.856018 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:16:44.937681 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m18:16:44.944804 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:16:44.954309 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:16:44.959881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8262553f-193e-4910-addf-1fa4edf49fb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd20cae650>]}
[0m18:16:44.964118 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:16:44.965164 [info ] [Thread-1 (]: 1 of 5 START seed file `default`.`stg_dim_date` ................................ [RUN]
[0m18:16:44.966210 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now seed.clickhouse_dbt_demo.stg_dim_date)
[0m18:16:44.967107 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:16:44.967850 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:16:45.012583 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */

    create table `default`.`stg_dim_date` 
   ("DateKey" Int32,"FullDate" Date,"Year" Int32,"Month" Int32,"Day" Int32,"DayOfWeek" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m18:16:45.027235 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:16:45.038487 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */
insert into `default`.`stg_dim_date` ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")
      
      format CSV
      1,2025-09-18,2025,9,18,Thursday
2,2025-09-19,2025,9,19,Friday
3,2025-09-20,2025,9,20,Saturday
...
[0m18:16:45.055182 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:16:45.061926 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_date"
[0m18:16:45.090247 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8262553f-193e-4910-addf-1fa4edf49fb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1ccf32d0>]}
[0m18:16:45.091493 [info ] [Thread-1 (]: 1 of 5 OK loaded seed file default.stg_dim_date ................................ [[32mINSERT 3[0m in 0.12s]
[0m18:16:45.093084 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:16:45.094208 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:16:45.095299 [info ] [Thread-1 (]: 2 of 5 START seed file `default`.`stg_dim_payment` ............................. [RUN]
[0m18:16:45.096677 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_date, now seed.clickhouse_dbt_demo.stg_dim_payment)
[0m18:16:45.097681 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:16:45.098511 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:16:45.103881 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */

    create table `default`.`stg_dim_payment` 
   ("PaymentKey" Int32,"PaymentType" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m18:16:45.123130 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:16:45.126602 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */
insert into `default`.`stg_dim_payment` ("PaymentKey", "PaymentType")
      
      format CSV
      1,Cash
2,Card
3,Voucher
...
[0m18:16:45.149252 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:16:45.151320 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_payment"
[0m18:16:45.157431 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8262553f-193e-4910-addf-1fa4edf49fb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1cc6c090>]}
[0m18:16:45.158658 [info ] [Thread-1 (]: 2 of 5 OK loaded seed file default.stg_dim_payment ............................. [[32mINSERT 3[0m in 0.06s]
[0m18:16:45.160255 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:16:45.161311 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:16:45.162257 [info ] [Thread-1 (]: 3 of 5 START seed file `default`.`stg_dim_product` ............................. [RUN]
[0m18:16:45.163233 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_payment, now seed.clickhouse_dbt_demo.stg_dim_product)
[0m18:16:45.164144 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:16:45.164899 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:16:45.170193 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */

    create table `default`.`stg_dim_product` 
   ("ProductKey" Int32,"ProductName" String,"Category" String,"Brand" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m18:16:45.191872 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:16:45.195599 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */
insert into `default`.`stg_dim_product` ("ProductKey", "ProductName", "Category", "Brand")
      
      format CSV
      1,Apple,Fruit,FreshFarm
2,Banana,Fruit,Tropicana
3,Milk,Dairy,DairyBest
4,Bread,Bakery,BakeHouse
...
[0m18:16:45.216857 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:16:45.218013 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_product"
[0m18:16:45.223014 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8262553f-193e-4910-addf-1fa4edf49fb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1ee44b10>]}
[0m18:16:45.225257 [info ] [Thread-1 (]: 3 of 5 OK loaded seed file default.stg_dim_product ............................. [[32mINSERT 4[0m in 0.06s]
[0m18:16:45.228101 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:16:45.229688 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:16:45.231282 [info ] [Thread-1 (]: 4 of 5 START seed file `default`.`stg_dim_store` ............................... [RUN]
[0m18:16:45.233226 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_product, now seed.clickhouse_dbt_demo.stg_dim_store)
[0m18:16:45.234703 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:16:45.235862 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:16:45.242700 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */

    create table `default`.`stg_dim_store` 
   ("StoreKey" Int32,"StoreName" String,"City" String,"Region" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m18:16:45.266558 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:16:45.269253 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */
insert into `default`.`stg_dim_store` ("StoreKey", "StoreName", "City", "Region")
      
      format CSV
      1,SuperMart Downtown,Tallinn,North
2,SuperMart Suburb,Tartu,South
...
[0m18:16:45.306770 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m18:16:45.309411 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_store"
[0m18:16:45.316331 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8262553f-193e-4910-addf-1fa4edf49fb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1cb754d0>]}
[0m18:16:45.317931 [info ] [Thread-1 (]: 4 of 5 OK loaded seed file default.stg_dim_store ............................... [[32mINSERT 2[0m in 0.08s]
[0m18:16:45.319865 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:16:45.321471 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:16:45.323820 [info ] [Thread-1 (]: 5 of 5 START seed file `default`.`stg_dim_supplier` ............................ [RUN]
[0m18:16:45.327228 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_store, now seed.clickhouse_dbt_demo.stg_dim_supplier)
[0m18:16:45.329126 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:16:45.331498 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:16:45.346687 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */

    create table `default`.`stg_dim_supplier` 
   ("SupplierKey" Int32,"SupplierName" String,"ContactInfo" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m18:16:45.409769 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m18:16:45.412411 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */
insert into `default`.`stg_dim_supplier` ("SupplierKey", "SupplierName", "ContactInfo")
      
      format CSV
      1,FreshFarm Supplier,fresh@farm.com
2,Tropicana Supplier,contact@tropicana.com
3,DairyBest Supplier,sales@dairybest.com
4,BakeHouse Supplier,info@bakehouse.com
...
[0m18:16:45.437937 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:16:45.439701 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_supplier"
[0m18:16:45.447047 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8262553f-193e-4910-addf-1fa4edf49fb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1cb71dd0>]}
[0m18:16:45.448895 [info ] [Thread-1 (]: 5 of 5 OK loaded seed file default.stg_dim_supplier ............................ [[32mINSERT 4[0m in 0.12s]
[0m18:16:45.451142 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:16:45.455406 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:16:45.456580 [debug] [MainThread]: Connection 'seed.clickhouse_dbt_demo.stg_dim_supplier' was left open.
[0m18:16:45.457640 [debug] [MainThread]: On seed.clickhouse_dbt_demo.stg_dim_supplier: Close
[0m18:16:45.458575 [info ] [MainThread]: 
[0m18:16:45.459407 [info ] [MainThread]: Finished running 5 seeds in 0 hours 0 minutes and 0.74 seconds (0.74s).
[0m18:16:45.462087 [debug] [MainThread]: Command end result
[0m18:16:45.539816 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:16:45.547826 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:16:45.562651 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:16:45.563539 [info ] [MainThread]: 
[0m18:16:45.564666 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:16:45.565805 [info ] [MainThread]: 
[0m18:16:45.566778 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m18:16:45.568461 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 1.5679369, "process_in_blocks": "0", "process_kernel_time": 0.40314, "process_mem_max_rss": "119308", "process_out_blocks": "2184", "process_user_time": 2.722496}
[0m18:16:45.569826 [debug] [MainThread]: Command `dbt seed` succeeded at 18:16:45.569613 after 1.57 seconds
[0m18:16:45.570644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd22918510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd229184d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd22919510>]}
[0m18:16:45.571530 [debug] [MainThread]: Flushing usage events
[0m18:16:46.166760 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:19:54.453257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dbe01310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dbfb9790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dbe016d0>]}


============================== 18:19:54.458236 | 3a020b52-084a-47d8-a3ad-67b5bfccae0a ==============================
[0m18:19:54.458236 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:19:54.459428 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'no_print': 'None', 'invocation_command': 'dbt run --full-refresh', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'debug': 'False', 'write_json': 'True', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'fail_fast': 'False', 'introspect': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'partial_parse': 'True', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default', 'target_path': 'None', 'profiles_dir': '/dbt', 'warn_error': 'None', 'log_path': '/dbt/logs'}
[0m18:19:54.666338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dbbbad90>]}
[0m18:19:54.735686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dc39c910>]}
[0m18:19:54.737408 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:19:54.819547 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:19:54.952864 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:19:54.953941 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:19:54.991501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0db926c50>]}
[0m18:19:55.084677 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:19:55.088024 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:19:55.104098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0db939710>]}
[0m18:19:55.104996 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:19:55.105843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0db95d4d0>]}
[0m18:19:55.109711 [info ] [MainThread]: 
[0m18:19:55.111972 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:19:55.113494 [info ] [MainThread]: 
[0m18:19:55.115854 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:19:55.125336 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:19:55.142305 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:19:55.254847 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:19:55.255833 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:19:55.267581 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:19:55.351430 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m18:19:55.358699 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:19:55.370202 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:19:55.376552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0db864f10>]}
[0m18:19:55.380566 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m18:19:55.381513 [info ] [Thread-1 (]: 1 of 7 START sql table model `default`.`dim_date` .............................. [RUN]
[0m18:19:55.382383 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m18:19:55.383044 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m18:19:55.395172 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m18:19:55.398278 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m18:19:55.422814 [debug] [Thread-1 (]: Creating new relation dim_date
[0m18:19:55.462616 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m18:19:55.481859 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:19:55.504878 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:19:55.515185 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:19:55.521733 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m18:19:55.525593 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m18:19:55.548810 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:19:55.575170 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dc3d9290>]}
[0m18:19:55.576756 [info ] [Thread-1 (]: 1 of 7 OK created sql table model `default`.`dim_date` ......................... [[32mOK[0m in 0.19s]
[0m18:19:55.578979 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m18:19:55.580577 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m18:19:55.583017 [info ] [Thread-1 (]: 2 of 7 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m18:19:55.585949 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m18:19:55.587823 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m18:19:55.592117 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:19:55.597489 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m18:19:55.600573 [debug] [Thread-1 (]: Creating new relation dim_payment
[0m18:19:55.602762 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:19:55.633036 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:19:55.641060 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:19:55.650498 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:19:55.653663 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:19:55.655629 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:19:55.691129 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:19:55.694333 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0daa98d50>]}
[0m18:19:55.695784 [info ] [Thread-1 (]: 2 of 7 OK created sql table model `default`.`dim_payment` ...................... [[32mOK[0m in 0.11s]
[0m18:19:55.697182 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m18:19:55.698688 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m18:19:55.699993 [info ] [Thread-1 (]: 3 of 7 START sql table model `default`.`dim_product` ........................... [RUN]
[0m18:19:55.702975 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m18:19:55.704650 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m18:19:55.709706 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m18:19:55.715609 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m18:19:55.721648 [debug] [Thread-1 (]: Creating new relation dim_product
[0m18:19:55.725481 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:19:55.749172 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:19:55.753226 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:19:55.762599 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:19:55.766867 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m18:19:55.770594 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:19:55.795751 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:19:55.798319 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0daa98750>]}
[0m18:19:55.799373 [info ] [Thread-1 (]: 3 of 7 OK created sql table model `default`.`dim_product` ...................... [[32mOK[0m in 0.10s]
[0m18:19:55.800743 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m18:19:55.802873 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m18:19:55.804909 [info ] [Thread-1 (]: 4 of 7 START sql table model `default`.`dim_store` ............................. [RUN]
[0m18:19:55.810415 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m18:19:55.811957 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m18:19:55.819993 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m18:19:55.824436 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m18:19:55.831798 [debug] [Thread-1 (]: Creating new relation dim_store
[0m18:19:55.835358 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m18:19:55.856328 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:19:55.860984 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:19:55.873399 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:19:55.877735 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m18:19:55.881357 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m18:19:55.905539 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:19:55.908202 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da987190>]}
[0m18:19:55.909544 [info ] [Thread-1 (]: 4 of 7 OK created sql table model `default`.`dim_store` ........................ [[32mOK[0m in 0.10s]
[0m18:19:55.911630 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m18:19:55.913536 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m18:19:55.917880 [info ] [Thread-1 (]: 5 of 7 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m18:19:55.920565 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m18:19:55.922500 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m18:19:55.932087 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:19:55.936113 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m18:19:55.940699 [debug] [Thread-1 (]: Creating new relation dim_supplier
[0m18:19:55.944327 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m18:19:55.965756 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:19:55.975064 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:19:55.986065 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:19:55.990240 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:19:55.993637 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m18:19:56.024021 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:19:56.029357 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da9c3010>]}
[0m18:19:56.031719 [info ] [Thread-1 (]: 5 of 7 OK created sql table model `default`.`dim_supplier` ..................... [[32mOK[0m in 0.11s]
[0m18:19:56.033921 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m18:19:56.035893 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:19:56.039074 [info ] [Thread-1 (]: 6 of 7 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m18:19:56.042494 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m18:19:56.043756 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:19:56.047824 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:19:56.050336 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:19:56.070730 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  ...
[0m18:19:56.080508 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  
[0m18:19:56.081552 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:19:56.088300 [debug] [Thread-1 (]: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.b79d1bf5-5b44-44b9-8954-245dcaa0ae3c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:19:56.090033 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a020b52-084a-47d8-a3ad-67b5bfccae0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da987bd0>]}
[0m18:19:56.091862 [error] [Thread-1 (]: 6 of 7 ERROR creating sql table model `default`.`stg_dim_customer` ............. [[31mERROR[0m in 0.05s]
[0m18:19:56.093447 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:19:56.095317 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.stg_dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.b79d1bf5-5b44-44b9-8954-245dcaa0ae3c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:19:56.100947 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m18:19:56.102847 [info ] [Thread-1 (]: 7 of 7 SKIP relation default.dim_customer ...................................... [[33mSKIP[0m]
[0m18:19:56.104441 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m18:19:56.107919 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:19:56.108706 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.stg_dim_customer' was left open.
[0m18:19:56.109881 [debug] [MainThread]: On model.clickhouse_dbt_demo.stg_dim_customer: Close
[0m18:19:56.112629 [info ] [MainThread]: 
[0m18:19:56.114352 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 1.00 seconds (1.00s).
[0m18:19:56.117981 [debug] [MainThread]: Command end result
[0m18:19:56.169005 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:19:56.172463 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:19:56.181668 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:19:56.182598 [info ] [MainThread]: 
[0m18:19:56.183429 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:19:56.184309 [info ] [MainThread]: 
[0m18:19:56.185411 [error] [MainThread]: [31mFailure in model stg_dim_customer (models/staging/stg_dim_customer.sql)[0m
[0m18:19:56.186654 [error] [MainThread]:   Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.b79d1bf5-5b44-44b9-8954-245dcaa0ae3c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:19:56.188561 [info ] [MainThread]: 
[0m18:19:56.189637 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m18:19:56.191506 [info ] [MainThread]: 
[0m18:19:56.193519 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=7
[0m18:19:56.196663 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.8100566, "process_in_blocks": "0", "process_kernel_time": 0.429545, "process_mem_max_rss": "120404", "process_out_blocks": "2208", "process_user_time": 2.770002}
[0m18:19:56.197852 [debug] [MainThread]: Command `dbt run` failed at 18:19:56.197660 after 1.81 seconds
[0m18:19:56.198968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dbc8e9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0db903350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dbc8e8d0>]}
[0m18:19:56.200699 [debug] [MainThread]: Flushing usage events
[0m18:19:56.866581 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:21:14.729625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006db05690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006db0d510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006dcbdc90>]}


============================== 18:21:14.734209 | b87f09c9-80fc-4eff-999c-817377a4f9a5 ==============================
[0m18:21:14.734209 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:21:14.735574 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'no_print': 'None', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'write_json': 'True', 'log_format': 'default', 'fail_fast': 'False', 'profiles_dir': '/dbt', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --full-refresh', 'version_check': 'True', 'log_path': '/dbt/logs', 'empty': 'False', 'indirect_selection': 'eager', 'partial_parse': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'static_parser': 'True', 'use_colors': 'True', 'target_path': 'None', 'debug': 'False'}
[0m18:21:15.042165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006d9498d0>]}
[0m18:21:15.124161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006e09cd90>]}
[0m18:21:15.126082 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:21:15.221272 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:21:15.365630 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:21:15.366523 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:21:15.410528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006db0d590>]}
[0m18:21:15.547251 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:21:15.552067 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:21:15.575214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006d909f50>]}
[0m18:21:15.576553 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:21:15.578456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006d6dd450>]}
[0m18:21:15.588853 [info ] [MainThread]: 
[0m18:21:15.590547 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:21:15.593070 [info ] [MainThread]: 
[0m18:21:15.594731 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:21:15.611574 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:21:15.630089 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:21:15.817891 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:21:15.819950 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:21:15.839237 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:21:15.934033 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m18:21:15.940839 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:21:16.015637 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:21:16.017667 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:21:16.031295 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:21:16.043387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006c7dd6d0>]}
[0m18:21:16.048558 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m18:21:16.050928 [info ] [Thread-1 (]: 1 of 7 START sql table model `default`.`dim_date` .............................. [RUN]
[0m18:21:16.054473 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m18:21:16.056596 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m18:21:16.066394 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m18:21:16.072149 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m18:21:16.147225 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m18:21:16.166582 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:21:16.190086 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:21:16.198988 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:21:16.204328 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m18:21:16.207916 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date__dbt_backup`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m18:21:16.233136 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:21:16.238372 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
EXCHANGE TABLES `default`.`dim_date__dbt_backup` AND `default`.`dim_date` 
  
  ...
[0m18:21:16.246363 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:21:16.281156 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  ...
[0m18:21:16.285903 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  
[0m18:21:16.287242 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:21:16.295950 [debug] [Thread-1 (]: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.70b57a0d-c290-447d-95bb-c9b36d0696c0.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m18:21:16.300145 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006c7da2d0>]}
[0m18:21:16.302050 [error] [Thread-1 (]: 1 of 7 ERROR creating sql table model `default`.`dim_date` ..................... [[31mERROR[0m in 0.24s]
[0m18:21:16.305151 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m18:21:16.308724 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m18:21:16.310444 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_date' to be skipped because of status 'error'.  Reason: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.70b57a0d-c290-447d-95bb-c9b36d0696c0.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql.
[0m18:21:16.312615 [info ] [Thread-1 (]: 2 of 7 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m18:21:16.318467 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m18:21:16.322266 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m18:21:16.330392 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:21:16.334282 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m18:21:16.341683 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:21:16.377154 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:21:16.384773 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:21:16.395520 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:21:16.400618 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:21:16.404368 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:21:16.438514 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:21:16.442127 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
EXCHANGE TABLES `default`.`dim_payment__dbt_backup` AND `default`.`dim_payment` 
  
  ...
[0m18:21:16.452646 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:21:16.460935 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  ...
[0m18:21:16.467334 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  
[0m18:21:16.468635 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:21:16.474560 [debug] [Thread-1 (]: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.c52c26b9-8757-426f-bee6-d83f948fa2d9.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m18:21:16.476082 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006c68f450>]}
[0m18:21:16.477227 [error] [Thread-1 (]: 2 of 7 ERROR creating sql table model `default`.`dim_payment` .................. [[31mERROR[0m in 0.16s]
[0m18:21:16.479509 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m18:21:16.481163 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m18:21:16.481996 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_payment' to be skipped because of status 'error'.  Reason: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.c52c26b9-8757-426f-bee6-d83f948fa2d9.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql.
[0m18:21:16.483364 [info ] [Thread-1 (]: 3 of 7 START sql table model `default`.`dim_product` ........................... [RUN]
[0m18:21:16.488697 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m18:21:16.490019 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m18:21:16.493342 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m18:21:16.496734 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m18:21:16.507134 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:21:16.538631 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:21:16.546246 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:21:16.558614 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:21:16.561642 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m18:21:16.566616 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:21:16.593883 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:21:16.595624 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
EXCHANGE TABLES `default`.`dim_product__dbt_backup` AND `default`.`dim_product` 
  
  ...
[0m18:21:16.608654 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:21:16.617487 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  ...
[0m18:21:16.624146 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  
[0m18:21:16.625696 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:21:16.631234 [debug] [Thread-1 (]: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.ee9f779c-ab33-4491-a2df-fa4505f09c75.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m18:21:16.632999 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006c5766d0>]}
[0m18:21:16.634404 [error] [Thread-1 (]: 3 of 7 ERROR creating sql table model `default`.`dim_product` .................. [[31mERROR[0m in 0.14s]
[0m18:21:16.636179 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m18:21:16.638142 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m18:21:16.638827 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_product' to be skipped because of status 'error'.  Reason: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.ee9f779c-ab33-4491-a2df-fa4505f09c75.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql.
[0m18:21:16.640185 [info ] [Thread-1 (]: 4 of 7 START sql table model `default`.`dim_store` ............................. [RUN]
[0m18:21:16.641951 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m18:21:16.643010 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m18:21:16.647206 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m18:21:16.651335 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m18:21:16.659298 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m18:21:16.688301 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:21:16.692235 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:21:16.703676 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:21:16.708527 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m18:21:16.711999 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store__dbt_backup`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m18:21:16.740373 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:21:16.742224 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
EXCHANGE TABLES `default`.`dim_store__dbt_backup` AND `default`.`dim_store` 
  
  ...
[0m18:21:16.752744 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:21:16.760960 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  ...
[0m18:21:16.766411 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  
[0m18:21:16.767733 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:21:16.772285 [debug] [Thread-1 (]: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.dfa7704e-b93d-48d8-8311-67ace5cf321d.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m18:21:16.773563 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006d63d910>]}
[0m18:21:16.775148 [error] [Thread-1 (]: 4 of 7 ERROR creating sql table model `default`.`dim_store` .................... [[31mERROR[0m in 0.13s]
[0m18:21:16.776576 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m18:21:16.778000 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m18:21:16.779231 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_store' to be skipped because of status 'error'.  Reason: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.dfa7704e-b93d-48d8-8311-67ace5cf321d.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql.
[0m18:21:16.780909 [info ] [Thread-1 (]: 5 of 7 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m18:21:16.787491 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m18:21:16.788595 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m18:21:16.792325 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:21:16.795701 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m18:21:16.804065 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m18:21:16.836981 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:21:16.840575 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:21:16.854013 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:21:16.857847 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:21:16.861541 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier__dbt_backup`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m18:21:16.890555 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:21:16.892682 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
EXCHANGE TABLES `default`.`dim_supplier__dbt_backup` AND `default`.`dim_supplier` 
  
  ...
[0m18:21:16.903539 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:21:16.911635 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  ...
[0m18:21:16.918375 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  
[0m18:21:16.920011 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:21:16.924409 [debug] [Thread-1 (]: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.66c1dffd-8f8b-42bd-9685-66346b903a62.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m18:21:16.926099 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006c5ac450>]}
[0m18:21:16.927731 [error] [Thread-1 (]: 5 of 7 ERROR creating sql table model `default`.`dim_supplier` ................. [[31mERROR[0m in 0.14s]
[0m18:21:16.929727 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m18:21:16.931642 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:21:16.935058 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_supplier' to be skipped because of status 'error'.  Reason: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.66c1dffd-8f8b-42bd-9685-66346b903a62.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql.
[0m18:21:16.938044 [info ] [Thread-1 (]: 6 of 7 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m18:21:16.940487 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m18:21:16.941342 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:21:16.946323 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:21:16.950322 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:21:16.960638 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  ...
[0m18:21:16.966645 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  
[0m18:21:16.970171 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:21:16.974166 [debug] [Thread-1 (]: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.b79d1bf5-5b44-44b9-8954-245dcaa0ae3c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:21:16.975397 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b87f09c9-80fc-4eff-999c-817377a4f9a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006c5b7610>]}
[0m18:21:16.976562 [error] [Thread-1 (]: 6 of 7 ERROR creating sql table model `default`.`stg_dim_customer` ............. [[31mERROR[0m in 0.03s]
[0m18:21:16.978273 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:21:16.979965 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.stg_dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.b79d1bf5-5b44-44b9-8954-245dcaa0ae3c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m18:21:16.982421 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m18:21:16.984207 [info ] [Thread-1 (]: 7 of 7 SKIP relation default.dim_customer ...................................... [[33mSKIP[0m]
[0m18:21:16.986101 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m18:21:16.989739 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:21:16.991204 [debug] [MainThread]: Connection 'list_' was left open.
[0m18:21:16.991884 [debug] [MainThread]: On list_: Close
[0m18:21:16.992475 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.stg_dim_customer' was left open.
[0m18:21:16.992993 [debug] [MainThread]: On model.clickhouse_dbt_demo.stg_dim_customer: Close
[0m18:21:16.993729 [info ] [MainThread]: 
[0m18:21:16.994651 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 1.40 seconds (1.40s).
[0m18:21:16.997190 [debug] [MainThread]: Command end result
[0m18:21:17.053276 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:21:17.056851 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:21:17.066380 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:21:17.067700 [info ] [MainThread]: 
[0m18:21:17.069385 [info ] [MainThread]: [31mCompleted with 6 errors, 0 partial successes, and 0 warnings:[0m
[0m18:21:17.070789 [info ] [MainThread]: 
[0m18:21:17.072127 [error] [MainThread]: [31mFailure in model dim_date (models/marts/dim_date.sql)[0m
[0m18:21:17.073236 [error] [MainThread]:   Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.70b57a0d-c290-447d-95bb-c9b36d0696c0.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m18:21:17.074882 [info ] [MainThread]: 
[0m18:21:17.076457 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m18:21:17.078170 [info ] [MainThread]: 
[0m18:21:17.079550 [error] [MainThread]: [31mFailure in model dim_payment (models/marts/dim_payment.sql)[0m
[0m18:21:17.081048 [error] [MainThread]:   Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.c52c26b9-8757-426f-bee6-d83f948fa2d9.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m18:21:17.082826 [info ] [MainThread]: 
[0m18:21:17.084021 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m18:21:17.085289 [info ] [MainThread]: 
[0m18:21:17.087509 [error] [MainThread]: [31mFailure in model dim_product (models/marts/dim_product.sql)[0m
[0m18:21:17.091224 [error] [MainThread]:   Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.ee9f779c-ab33-4491-a2df-fa4505f09c75.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m18:21:17.092900 [info ] [MainThread]: 
[0m18:21:17.094023 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m18:21:17.095057 [info ] [MainThread]: 
[0m18:21:17.096456 [error] [MainThread]: [31mFailure in model dim_store (models/marts/dim_store.sql)[0m
[0m18:21:17.098307 [error] [MainThread]:   Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.dfa7704e-b93d-48d8-8311-67ace5cf321d.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m18:21:17.099558 [info ] [MainThread]: 
[0m18:21:17.101082 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m18:21:17.102528 [info ] [MainThread]: 
[0m18:21:17.106446 [error] [MainThread]: [31mFailure in model dim_supplier (models/marts/dim_supplier.sql)[0m
[0m18:21:17.108497 [error] [MainThread]:   Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.66c1dffd-8f8b-42bd-9685-66346b903a62.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m18:21:17.110180 [info ] [MainThread]: 
[0m18:21:17.111954 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m18:21:17.113346 [info ] [MainThread]: 
[0m18:21:17.114568 [error] [MainThread]: [31mFailure in model stg_dim_customer (models/staging/stg_dim_customer.sql)[0m
[0m18:21:17.116108 [error] [MainThread]:   Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.b79d1bf5-5b44-44b9-8954-245dcaa0ae3c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m18:21:17.117183 [info ] [MainThread]: 
[0m18:21:17.119596 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m18:21:17.121906 [info ] [MainThread]: 
[0m18:21:17.123271 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=6 SKIP=1 NO-OP=0 TOTAL=7
[0m18:21:17.125801 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.522894, "process_in_blocks": "0", "process_kernel_time": 0.397581, "process_mem_max_rss": "120460", "process_out_blocks": "2251", "process_user_time": 3.090387}
[0m18:21:17.126889 [debug] [MainThread]: Command `dbt run` failed at 18:21:17.126680 after 2.52 seconds
[0m18:21:17.127606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00724c8750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006c541d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f006c543110>]}
[0m18:21:17.128477 [debug] [MainThread]: Flushing usage events
[0m18:21:17.835877 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:32:21.763970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98547aab90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98548aed50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98547ab650>]}


============================== 18:32:21.779133 | 10cd2826-2c59-4341-9e49-44340a9c0089 ==============================
[0m18:32:21.779133 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:32:21.788165 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt debug', 'introspect': 'True', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'log_format': 'default', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'printer_width': '80', 'warn_error': 'None', 'version_check': 'True', 'quiet': 'False', 'target_path': 'None', 'log_path': '/dbt/logs', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True', 'empty': 'None', 'profiles_dir': '/dbt', 'debug': 'False', 'partial_parse': 'True'}
[0m18:32:21.809702 [info ] [MainThread]: dbt version: 1.10.13
[0m18:32:21.819447 [info ] [MainThread]: python version: 3.11.14
[0m18:32:21.831355 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m18:32:21.839420 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m18:32:22.008778 [info ] [MainThread]: Using profiles dir at /dbt
[0m18:32:22.019492 [info ] [MainThread]: Using profiles.yml file at /dbt/profiles.yml
[0m18:32:22.031593 [info ] [MainThread]: Using dbt_project.yml file at /dbt/dbt_project.yml
[0m18:32:22.041000 [info ] [MainThread]: adapter type: clickhouse
[0m18:32:22.058985 [info ] [MainThread]: adapter version: 1.9.5
[0m18:32:22.259448 [info ] [MainThread]: Configuration:
[0m18:32:22.271157 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:32:22.282399 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:32:22.291608 [info ] [MainThread]: Required dependencies:
[0m18:32:22.304353 [debug] [MainThread]: Executing "git --help"
[0m18:32:22.320225 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:32:22.330978 [debug] [MainThread]: STDERR: "b''"
[0m18:32:22.340707 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:32:22.349943 [info ] [MainThread]: Connection:
[0m18:32:22.360979 [info ] [MainThread]:   driver: None
[0m18:32:22.369871 [info ] [MainThread]:   host: clickhouse-server
[0m18:32:22.383831 [info ] [MainThread]:   port: 8123
[0m18:32:22.393971 [info ] [MainThread]:   user: default
[0m18:32:22.402536 [info ] [MainThread]:   schema: default
[0m18:32:22.413138 [info ] [MainThread]:   retries: 1
[0m18:32:22.423642 [info ] [MainThread]:   cluster: None
[0m18:32:22.436944 [info ] [MainThread]:   database_engine: None
[0m18:32:22.445787 [info ] [MainThread]:   cluster_mode: False
[0m18:32:22.456419 [info ] [MainThread]:   secure: False
[0m18:32:22.468304 [info ] [MainThread]:   verify: True
[0m18:32:22.482162 [info ] [MainThread]:   client_cert: None
[0m18:32:22.496281 [info ] [MainThread]:   client_cert_key: None
[0m18:32:22.507345 [info ] [MainThread]:   connect_timeout: 10
[0m18:32:22.519554 [info ] [MainThread]:   send_receive_timeout: 300
[0m18:32:22.533614 [info ] [MainThread]:   sync_request_timeout: 5
[0m18:32:22.545160 [info ] [MainThread]:   compress_block_size: 1048576
[0m18:32:22.556973 [info ] [MainThread]:   compression: 
[0m18:32:22.571459 [info ] [MainThread]:   check_exchange: True
[0m18:32:22.586062 [info ] [MainThread]:   custom_settings: None
[0m18:32:22.599172 [info ] [MainThread]:   use_lw_deletes: False
[0m18:32:22.610563 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m18:32:22.624422 [info ] [MainThread]:   tcp_keepalive: False
[0m18:32:22.637195 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:32:22.747691 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m18:32:22.756047 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:32:23.159237 [info ] [MainThread]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:32:23.161830 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m18:32:23.170163 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:32:23.208155 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m18:32:23.211607 [info ] [MainThread]: [32mAll checks passed![0m
[0m18:32:23.215800 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 1.6384878, "process_in_blocks": "0", "process_kernel_time": 0.744702, "process_mem_max_rss": "112928", "process_out_blocks": "2133", "process_user_time": 3.069654}
[0m18:32:23.218269 [debug] [MainThread]: Command `dbt debug` succeeded at 18:32:23.217964 after 1.64 seconds
[0m18:32:23.220015 [debug] [MainThread]: Connection 'debug' was left open.
[0m18:32:23.221724 [debug] [MainThread]: On debug: Close
[0m18:32:23.223826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98547ab410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9854820d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9854555a50>]}
[0m18:32:23.226061 [debug] [MainThread]: Flushing usage events
[0m18:32:23.817096 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:34:09.387881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f6cde810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f6d47910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f6e96050>]}


============================== 18:34:09.393067 | 74125023-a7ce-4e42-b4d4-03e6d52fd383 ==============================
[0m18:34:09.393067 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:34:09.394152 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'static_parser': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'introspect': 'True', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'quiet': 'False', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'partial_parse': 'True', 'fail_fast': 'False', 'printer_width': '80', 'invocation_command': 'dbt seed', 'profiles_dir': '/dbt', 'log_path': '/dbt/logs'}
[0m18:34:09.609298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '74125023-a7ce-4e42-b4d4-03e6d52fd383', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f6abb910>]}
[0m18:34:09.682488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '74125023-a7ce-4e42-b4d4-03e6d52fd383', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f7278990>]}
[0m18:34:09.684176 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:34:09.775351 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:34:09.949238 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:34:09.950168 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:34:09.990521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '74125023-a7ce-4e42-b4d4-03e6d52fd383', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f6810390>]}
[0m18:34:10.102434 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:34:10.105760 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:34:10.142631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '74125023-a7ce-4e42-b4d4-03e6d52fd383', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f6a94050>]}
[0m18:34:10.143986 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:34:10.145106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '74125023-a7ce-4e42-b4d4-03e6d52fd383', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f68b9d90>]}
[0m18:34:10.150410 [info ] [MainThread]: 
[0m18:34:10.153015 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:34:10.154476 [info ] [MainThread]: 
[0m18:34:10.156361 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:34:10.172786 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:34:10.191050 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:34:10.318501 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:34:10.320363 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:34:10.332479 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:10.419230 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m18:34:10.426724 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:34:10.455326 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:10.460642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '74125023-a7ce-4e42-b4d4-03e6d52fd383', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f59b9410>]}
[0m18:34:10.472899 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:34:10.474244 [info ] [Thread-1 (]: 1 of 5 START seed file `default`.`stg_dim_date` ................................ [RUN]
[0m18:34:10.475842 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now seed.clickhouse_dbt_demo.stg_dim_date)
[0m18:34:10.477941 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:34:10.481269 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:34:10.524296 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */
truncate table `default`.`stg_dim_date` 
  ...
[0m18:34:10.546011 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:10.555209 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */
insert into `default`.`stg_dim_date` ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")
      
      format CSV
      1,2025-09-18,2025,9,18,Thursday
2,2025-09-19,2025,9,19,Friday
3,2025-09-20,2025,9,20,Saturday
...
[0m18:34:10.582368 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:10.589769 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_date"
[0m18:34:10.618483 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74125023-a7ce-4e42-b4d4-03e6d52fd383', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f971c350>]}
[0m18:34:10.620133 [info ] [Thread-1 (]: 1 of 5 OK loaded seed file default.stg_dim_date ................................ [[32mINSERT 3[0m in 0.14s]
[0m18:34:10.622098 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:34:10.623972 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:34:10.626191 [info ] [Thread-1 (]: 2 of 5 START seed file `default`.`stg_dim_payment` ............................. [RUN]
[0m18:34:10.628955 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_date, now seed.clickhouse_dbt_demo.stg_dim_payment)
[0m18:34:10.631777 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:34:10.633200 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:34:10.642706 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */
truncate table `default`.`stg_dim_payment` 
  ...
[0m18:34:10.668261 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:10.672863 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */
insert into `default`.`stg_dim_payment` ("PaymentKey", "PaymentType")
      
      format CSV
      1,Cash
2,Card
3,Voucher
...
[0m18:34:10.695073 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:10.696187 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_payment"
[0m18:34:10.700853 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74125023-a7ce-4e42-b4d4-03e6d52fd383', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f591a5d0>]}
[0m18:34:10.702201 [info ] [Thread-1 (]: 2 of 5 OK loaded seed file default.stg_dim_payment ............................. [[32mINSERT 3[0m in 0.07s]
[0m18:34:10.703857 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:34:10.704875 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:34:10.705923 [info ] [Thread-1 (]: 3 of 5 START seed file `default`.`stg_dim_product` ............................. [RUN]
[0m18:34:10.706945 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_payment, now seed.clickhouse_dbt_demo.stg_dim_product)
[0m18:34:10.708148 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:34:10.709798 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:34:10.724215 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */
truncate table `default`.`stg_dim_product` 
  ...
[0m18:34:10.749233 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:10.751350 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */
insert into `default`.`stg_dim_product` ("ProductKey", "ProductName", "Category", "Brand")
      
      format CSV
      1,Apple,Fruit,FreshFarm
2,Banana,Fruit,Tropicana
3,Milk,Dairy,DairyBest
4,Bread,Bakery,BakeHouse
...
[0m18:34:10.778991 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:10.780951 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_product"
[0m18:34:10.789859 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74125023-a7ce-4e42-b4d4-03e6d52fd383', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f5862910>]}
[0m18:34:10.791071 [info ] [Thread-1 (]: 3 of 5 OK loaded seed file default.stg_dim_product ............................. [[32mINSERT 4[0m in 0.08s]
[0m18:34:10.792361 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:34:10.793394 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:34:10.795185 [info ] [Thread-1 (]: 4 of 5 START seed file `default`.`stg_dim_store` ............................... [RUN]
[0m18:34:10.799065 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_product, now seed.clickhouse_dbt_demo.stg_dim_store)
[0m18:34:10.801014 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:34:10.802775 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:34:10.813183 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */
truncate table `default`.`stg_dim_store` 
  ...
[0m18:34:10.842632 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:10.844915 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */
insert into `default`.`stg_dim_store` ("StoreKey", "StoreName", "City", "Region")
      
      format CSV
      1,SuperMart Downtown,Tallinn,North
2,SuperMart Suburb,Tartu,South
...
[0m18:34:10.861856 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:10.864154 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_store"
[0m18:34:10.871457 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74125023-a7ce-4e42-b4d4-03e6d52fd383', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f6cfb790>]}
[0m18:34:10.873237 [info ] [Thread-1 (]: 4 of 5 OK loaded seed file default.stg_dim_store ............................... [[32mINSERT 2[0m in 0.07s]
[0m18:34:10.875500 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:34:10.877534 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:34:10.880376 [info ] [Thread-1 (]: 5 of 5 START seed file `default`.`stg_dim_supplier` ............................ [RUN]
[0m18:34:10.884401 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_store, now seed.clickhouse_dbt_demo.stg_dim_supplier)
[0m18:34:10.886217 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:34:10.887650 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:34:10.895905 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */
truncate table `default`.`stg_dim_supplier` 
  ...
[0m18:34:10.924889 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:10.928452 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */
insert into `default`.`stg_dim_supplier` ("SupplierKey", "SupplierName", "ContactInfo")
      
      format CSV
      1,FreshFarm Supplier,fresh@farm.com
2,Tropicana Supplier,contact@tropicana.com
3,DairyBest Supplier,sales@dairybest.com
4,BakeHouse Supplier,info@bakehouse.com
...
[0m18:34:10.947203 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:10.948930 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_supplier"
[0m18:34:10.953515 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74125023-a7ce-4e42-b4d4-03e6d52fd383', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f6a96450>]}
[0m18:34:10.954609 [info ] [Thread-1 (]: 5 of 5 OK loaded seed file default.stg_dim_supplier ............................ [[32mINSERT 4[0m in 0.07s]
[0m18:34:10.955775 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:34:10.959075 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:34:10.960631 [debug] [MainThread]: Connection 'seed.clickhouse_dbt_demo.stg_dim_supplier' was left open.
[0m18:34:10.962250 [debug] [MainThread]: On seed.clickhouse_dbt_demo.stg_dim_supplier: Close
[0m18:34:10.963975 [info ] [MainThread]: 
[0m18:34:10.965629 [info ] [MainThread]: Finished running 5 seeds in 0 hours 0 minutes and 0.81 seconds (0.81s).
[0m18:34:10.972064 [debug] [MainThread]: Command end result
[0m18:34:11.044694 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:34:11.047938 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:34:11.055688 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:34:11.056567 [info ] [MainThread]: 
[0m18:34:11.057847 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:34:11.059276 [info ] [MainThread]: 
[0m18:34:11.063674 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m18:34:11.067885 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 1.7434647, "process_in_blocks": "0", "process_kernel_time": 0.395409, "process_mem_max_rss": "120252", "process_out_blocks": "2301", "process_user_time": 2.75455}
[0m18:34:11.070098 [debug] [MainThread]: Command `dbt seed` succeeded at 18:34:11.069787 after 1.75 seconds
[0m18:34:11.073406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12fb714e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12fb714550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12fb715510>]}
[0m18:34:11.075821 [debug] [MainThread]: Flushing usage events
[0m18:34:11.822131 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:34:15.861712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4a7bd950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4a648dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4a648290>]}


============================== 18:34:15.865924 | b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2 ==============================
[0m18:34:15.865924 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:34:15.868069 [debug] [MainThread]: running dbt with arguments {'log_path': '/dbt/logs', 'write_json': 'True', 'target_path': 'None', 'empty': 'False', 'profiles_dir': '/dbt', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'warn_error': 'None', 'version_check': 'True', 'quiet': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default', 'cache_selected_only': 'False', 'use_colors': 'True'}
[0m18:34:16.071466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4abf5d10>]}
[0m18:34:16.153368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4aba0850>]}
[0m18:34:16.155111 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:34:16.284019 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:34:16.489148 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:34:16.490172 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:34:16.545373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4a2c6690>]}
[0m18:34:16.655102 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:34:16.659416 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:34:16.683128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4a3f1d50>]}
[0m18:34:16.684164 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:34:16.685178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4a1f0ad0>]}
[0m18:34:16.689298 [info ] [MainThread]: 
[0m18:34:16.692746 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:34:16.694405 [info ] [MainThread]: 
[0m18:34:16.696840 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:34:16.708247 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:34:16.734533 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:34:16.869221 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:34:16.871177 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:34:16.884787 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:16.970880 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m18:34:16.981809 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:34:16.993637 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:17.000100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c493bbbd0>]}
[0m18:34:17.005395 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m18:34:17.006983 [info ] [Thread-1 (]: 1 of 7 START sql table model `default`.`dim_date` .............................. [RUN]
[0m18:34:17.008874 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m18:34:17.010325 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m18:34:17.024874 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m18:34:17.031001 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m18:34:17.055511 [debug] [Thread-1 (]: Creating new relation dim_date
[0m18:34:17.106897 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m18:34:17.136116 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:17.171324 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:17.183618 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:17.190854 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m18:34:17.194703 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m18:34:17.231888 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m18:34:17.261328 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4a06bed0>]}
[0m18:34:17.264323 [info ] [Thread-1 (]: 1 of 7 OK created sql table model `default`.`dim_date` ......................... [[32mOK[0m in 0.25s]
[0m18:34:17.268410 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m18:34:17.274140 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m18:34:17.276250 [info ] [Thread-1 (]: 2 of 7 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m18:34:17.279052 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m18:34:17.283287 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m18:34:17.288937 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:34:17.292779 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m18:34:17.298105 [debug] [Thread-1 (]: Creating new relation dim_payment
[0m18:34:17.303277 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:34:17.334061 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:17.343351 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:17.354601 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:17.358605 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:34:17.363248 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:34:17.399387 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:17.403419 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c49182c10>]}
[0m18:34:17.405221 [info ] [Thread-1 (]: 2 of 7 OK created sql table model `default`.`dim_payment` ...................... [[32mOK[0m in 0.12s]
[0m18:34:17.407720 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m18:34:17.410555 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m18:34:17.415128 [info ] [Thread-1 (]: 3 of 7 START sql table model `default`.`dim_product` ........................... [RUN]
[0m18:34:17.417994 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m18:34:17.420822 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m18:34:17.428395 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m18:34:17.434681 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m18:34:17.439449 [debug] [Thread-1 (]: Creating new relation dim_product
[0m18:34:17.442353 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:34:17.474182 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:17.481658 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:17.493402 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:17.497465 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m18:34:17.500946 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:34:17.533083 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:17.536714 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4a3bcc50>]}
[0m18:34:17.538132 [info ] [Thread-1 (]: 3 of 7 OK created sql table model `default`.`dim_product` ...................... [[32mOK[0m in 0.12s]
[0m18:34:17.539789 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m18:34:17.541087 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m18:34:17.542243 [info ] [Thread-1 (]: 4 of 7 START sql table model `default`.`dim_store` ............................. [RUN]
[0m18:34:17.543540 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m18:34:17.544502 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m18:34:17.550831 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m18:34:17.555810 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m18:34:17.566947 [debug] [Thread-1 (]: Creating new relation dim_store
[0m18:34:17.571217 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m18:34:17.598266 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:17.602250 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:17.612617 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:17.616860 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m18:34:17.620997 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m18:34:17.651686 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:17.654084 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c491a3a90>]}
[0m18:34:17.655095 [info ] [Thread-1 (]: 4 of 7 OK created sql table model `default`.`dim_store` ........................ [[32mOK[0m in 0.11s]
[0m18:34:17.656058 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m18:34:17.657357 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m18:34:17.659693 [info ] [Thread-1 (]: 5 of 7 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m18:34:17.666892 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m18:34:17.668486 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m18:34:17.674473 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:34:17.679711 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m18:34:17.684333 [debug] [Thread-1 (]: Creating new relation dim_supplier
[0m18:34:17.686620 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m18:34:17.709472 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:17.723656 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:17.735771 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:17.739118 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:34:17.742250 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m18:34:17.772691 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:17.777334 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c491c9d10>]}
[0m18:34:17.779804 [info ] [Thread-1 (]: 5 of 7 OK created sql table model `default`.`dim_supplier` ..................... [[32mOK[0m in 0.11s]
[0m18:34:17.781326 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m18:34:17.782394 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:34:17.783820 [info ] [Thread-1 (]: 6 of 7 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m18:34:17.785029 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m18:34:17.786075 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:34:17.788842 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:34:17.791786 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:34:17.794837 [debug] [Thread-1 (]: Creating new relation stg_dim_customer
[0m18:34:17.798194 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m18:34:17.829377 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:17.836828 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:17.845892 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:17.850570 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:34:17.853861 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m18:34:17.886253 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:17.889588 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4918fad0>]}
[0m18:34:17.890886 [info ] [Thread-1 (]: 6 of 7 OK created sql table model `default`.`stg_dim_customer` ................. [[32mOK[0m in 0.10s]
[0m18:34:17.892200 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:34:17.894709 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m18:34:17.895885 [info ] [Thread-1 (]: 7 of 7 START sql table model `default`.`dim_customer` .......................... [RUN]
[0m18:34:17.899067 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.stg_dim_customer, now model.clickhouse_dbt_demo.dim_customer)
[0m18:34:17.900100 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_customer
[0m18:34:17.904077 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_customer"
[0m18:34:17.907109 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_customer
[0m18:34:17.911972 [debug] [Thread-1 (]: Creating new relation dim_customer
[0m18:34:17.917966 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

            

    
        create table `default`.`dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
          )
        
        ...
[0m18:34:17.951945 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:17.955891 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:17.970126 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:17.975331 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_customer"
[0m18:34:17.979431 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`dim_customer`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
  ...
[0m18:34:18.010523 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:18.015122 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b295e04d-30cb-4fbb-bcbc-a6eb9fee97c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4918d410>]}
[0m18:34:18.017197 [info ] [Thread-1 (]: 7 of 7 OK created sql table model `default`.`dim_customer` ..................... [[32mOK[0m in 0.12s]
[0m18:34:18.020466 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m18:34:18.024685 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:34:18.026017 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.dim_customer' was left open.
[0m18:34:18.027330 [debug] [MainThread]: On model.clickhouse_dbt_demo.dim_customer: Close
[0m18:34:18.029335 [info ] [MainThread]: 
[0m18:34:18.032057 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 1.33 seconds (1.33s).
[0m18:34:18.037024 [debug] [MainThread]: Command end result
[0m18:34:18.127104 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:34:18.133544 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:34:18.145326 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:34:18.146502 [info ] [MainThread]: 
[0m18:34:18.148307 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:34:18.150196 [info ] [MainThread]: 
[0m18:34:18.153386 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m18:34:18.158824 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.3707469, "process_in_blocks": "0", "process_kernel_time": 0.357535, "process_mem_max_rss": "119620", "process_out_blocks": "2214", "process_user_time": 3.071511}
[0m18:34:18.160904 [debug] [MainThread]: Command `dbt run` succeeded at 18:34:18.160299 after 2.37 seconds
[0m18:34:18.162858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4f10b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4abf5950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c4ef99010>]}
[0m18:34:18.166009 [debug] [MainThread]: Flushing usage events
[0m18:34:18.828404 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:34:28.652899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa815a6bd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa815a6e390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa815a6eb10>]}


============================== 18:34:28.657203 | 363c48a5-4f91-4528-bbe9-5e2ae042f914 ==============================
[0m18:34:28.657203 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:34:28.658756 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'cache_selected_only': 'False', 'log_path': '/dbt/logs', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'partial_parse': 'True', 'fail_fast': 'False', 'log_cache_events': 'False', 'use_colors': 'True', 'profiles_dir': '/dbt', 'write_json': 'True', 'no_print': 'None', 'quiet': 'False', 'warn_error': 'None', 'invocation_command': 'dbt run', 'version_check': 'True', 'introspect': 'True', 'target_path': 'None'}
[0m18:34:28.890610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa815a6c350>]}
[0m18:34:28.965533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa816198a50>]}
[0m18:34:28.967134 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:34:29.058260 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:34:29.258104 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:34:29.259717 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:34:29.315287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8156eb250>]}
[0m18:34:29.441728 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:34:29.445617 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:34:29.465727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa815a6f2d0>]}
[0m18:34:29.467836 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:34:29.470307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa815a0d490>]}
[0m18:34:29.477416 [info ] [MainThread]: 
[0m18:34:29.479311 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:34:29.480942 [info ] [MainThread]: 
[0m18:34:29.482753 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:34:29.495750 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:34:29.513569 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:34:29.635269 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m18:34:29.636632 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:34:29.647537 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:29.738908 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m18:34:29.747036 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:34:29.759779 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:29.774362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa815817d90>]}
[0m18:34:29.780603 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m18:34:29.782122 [info ] [Thread-1 (]: 1 of 7 START sql table model `default`.`dim_date` .............................. [RUN]
[0m18:34:29.784031 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m18:34:29.785906 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m18:34:29.799198 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m18:34:29.801776 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m18:34:29.912069 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m18:34:29.940516 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:29.975159 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:29.987160 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:29.994231 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m18:34:29.997398 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date__dbt_backup`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m18:34:30.031194 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:30.037898 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
EXCHANGE TABLES `default`.`dim_date__dbt_backup` AND `default`.`dim_date` 
  
  ...
[0m18:34:30.046338 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:30.083987 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  ...
[0m18:34:30.089406 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  
[0m18:34:30.090392 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:34:30.095991 [debug] [Thread-1 (]: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.0eb8a083-9c5d-4670-94d5-605e5d3165ed.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m18:34:30.098243 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8157efb50>]}
[0m18:34:30.099909 [error] [Thread-1 (]: 1 of 7 ERROR creating sql table model `default`.`dim_date` ..................... [[31mERROR[0m in 0.31s]
[0m18:34:30.101669 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m18:34:30.103268 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m18:34:30.104222 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_date' to be skipped because of status 'error'.  Reason: Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.0eb8a083-9c5d-4670-94d5-605e5d3165ed.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql.
[0m18:34:30.106126 [info ] [Thread-1 (]: 2 of 7 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m18:34:30.113468 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m18:34:30.114920 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m18:34:30.127377 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:34:30.131284 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m18:34:30.135781 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:34:30.160722 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:30.167763 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:30.180972 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:30.184166 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:34:30.187913 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:34:30.210812 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:30.214159 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
EXCHANGE TABLES `default`.`dim_payment__dbt_backup` AND `default`.`dim_payment` 
  
  ...
[0m18:34:30.226582 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:30.233421 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  ...
[0m18:34:30.239402 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  
[0m18:34:30.240752 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:34:30.245046 [debug] [Thread-1 (]: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.9aa46e1b-d0ef-4658-8ee8-f90c5b80b710.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m18:34:30.246056 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8148a3490>]}
[0m18:34:30.247178 [error] [Thread-1 (]: 2 of 7 ERROR creating sql table model `default`.`dim_payment` .................. [[31mERROR[0m in 0.13s]
[0m18:34:30.248874 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m18:34:30.250136 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m18:34:30.251090 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_payment' to be skipped because of status 'error'.  Reason: Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.9aa46e1b-d0ef-4658-8ee8-f90c5b80b710.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql.
[0m18:34:30.252731 [info ] [Thread-1 (]: 3 of 7 START sql table model `default`.`dim_product` ........................... [RUN]
[0m18:34:30.258596 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m18:34:30.260434 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m18:34:30.267904 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m18:34:30.271757 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m18:34:30.281283 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:34:30.302670 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:30.311338 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:30.325346 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:30.330383 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m18:34:30.333889 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:34:30.355888 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:30.359106 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
EXCHANGE TABLES `default`.`dim_product__dbt_backup` AND `default`.`dim_product` 
  
  ...
[0m18:34:30.371151 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:30.379032 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  ...
[0m18:34:30.384248 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  
[0m18:34:30.385227 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:34:30.389423 [debug] [Thread-1 (]: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.f4baf1cb-392e-4993-85c9-2445fd8978ca.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m18:34:30.390440 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8146038d0>]}
[0m18:34:30.391766 [error] [Thread-1 (]: 3 of 7 ERROR creating sql table model `default`.`dim_product` .................. [[31mERROR[0m in 0.13s]
[0m18:34:30.393227 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m18:34:30.394961 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m18:34:30.395766 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_product' to be skipped because of status 'error'.  Reason: Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.f4baf1cb-392e-4993-85c9-2445fd8978ca.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql.
[0m18:34:30.398463 [info ] [Thread-1 (]: 4 of 7 START sql table model `default`.`dim_store` ............................. [RUN]
[0m18:34:30.401216 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m18:34:30.402156 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m18:34:30.408309 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m18:34:30.412843 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m18:34:30.428465 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m18:34:30.452181 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:30.459057 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:30.471948 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:30.477217 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m18:34:30.481277 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store__dbt_backup`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m18:34:30.505099 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:30.508383 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
EXCHANGE TABLES `default`.`dim_store__dbt_backup` AND `default`.`dim_store` 
  
  ...
[0m18:34:30.520808 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:30.528072 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  ...
[0m18:34:30.534090 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  
[0m18:34:30.535216 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:34:30.539081 [debug] [Thread-1 (]: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.8095f5aa-f6ec-4add-ad3a-fe649ddccab3.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m18:34:30.540173 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81462ff10>]}
[0m18:34:30.541383 [error] [Thread-1 (]: 4 of 7 ERROR creating sql table model `default`.`dim_store` .................... [[31mERROR[0m in 0.14s]
[0m18:34:30.542955 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m18:34:30.544356 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m18:34:30.545162 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_store' to be skipped because of status 'error'.  Reason: Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.8095f5aa-f6ec-4add-ad3a-fe649ddccab3.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql.
[0m18:34:30.547118 [info ] [Thread-1 (]: 5 of 7 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m18:34:30.550311 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m18:34:30.551655 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m18:34:30.556399 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:34:30.562286 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m18:34:30.569844 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m18:34:30.598954 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:30.602435 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:30.616056 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:30.620578 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:34:30.624828 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier__dbt_backup`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m18:34:30.649160 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:30.651124 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
EXCHANGE TABLES `default`.`dim_supplier__dbt_backup` AND `default`.`dim_supplier` 
  
  ...
[0m18:34:30.661146 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:30.669638 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  ...
[0m18:34:30.676146 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  
[0m18:34:30.677868 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:34:30.682934 [debug] [Thread-1 (]: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.e319cff9-db53-4598-bcef-9a0d4b1a3362.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m18:34:30.684368 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8148e3dd0>]}
[0m18:34:30.686110 [error] [Thread-1 (]: 5 of 7 ERROR creating sql table model `default`.`dim_supplier` ................. [[31mERROR[0m in 0.13s]
[0m18:34:30.687985 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m18:34:30.689592 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:34:30.690445 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.dim_supplier' to be skipped because of status 'error'.  Reason: Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.e319cff9-db53-4598-bcef-9a0d4b1a3362.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql.
[0m18:34:30.692878 [info ] [Thread-1 (]: 6 of 7 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m18:34:30.696813 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m18:34:30.697813 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:34:30.700573 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:34:30.703095 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:34:30.711566 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m18:34:30.744997 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:34:30.749212 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:34:30.761242 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:30.766538 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:34:30.771064 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m18:34:30.796817 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:34:30.798483 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
EXCHANGE TABLES `default`.`stg_dim_customer__dbt_backup` AND `default`.`stg_dim_customer` 
  
  ...
[0m18:34:30.806878 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:34:30.819403 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  ...
[0m18:34:30.825936 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  
[0m18:34:30.827692 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m18:34:30.832649 [debug] [Thread-1 (]: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.0f44aa8b-8357-42f4-880e-8567d99b2c40.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m18:34:30.834046 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '363c48a5-4f91-4528-bbe9-5e2ae042f914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa814644690>]}
[0m18:34:30.835534 [error] [Thread-1 (]: 6 of 7 ERROR creating sql table model `default`.`stg_dim_customer` ............. [[31mERROR[0m in 0.14s]
[0m18:34:30.837009 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:34:30.838972 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.stg_dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.0f44aa8b-8357-42f4-880e-8567d99b2c40.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql.
[0m18:34:30.842826 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m18:34:30.844657 [info ] [Thread-1 (]: 7 of 7 SKIP relation default.dim_customer ...................................... [[33mSKIP[0m]
[0m18:34:30.845975 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m18:34:30.849003 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:34:30.849811 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.stg_dim_customer' was left open.
[0m18:34:30.850531 [debug] [MainThread]: On model.clickhouse_dbt_demo.stg_dim_customer: Close
[0m18:34:30.851361 [info ] [MainThread]: 
[0m18:34:30.852140 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 1.37 seconds (1.37s).
[0m18:34:30.854572 [debug] [MainThread]: Command end result
[0m18:34:30.924614 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:34:30.930788 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:34:30.943264 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:34:30.944626 [info ] [MainThread]: 
[0m18:34:30.945883 [info ] [MainThread]: [31mCompleted with 6 errors, 0 partial successes, and 0 warnings:[0m
[0m18:34:30.947731 [info ] [MainThread]: 
[0m18:34:30.949404 [error] [MainThread]: [31mFailure in model dim_date (models/marts/dim_date.sql)[0m
[0m18:34:30.952909 [error] [MainThread]:   Database Error in model dim_date (models/marts/dim_date.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_date__dbt_backup.0eb8a083-9c5d-4670-94d5-605e5d3165ed.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m18:34:30.955064 [info ] [MainThread]: 
[0m18:34:30.957288 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_date.sql
[0m18:34:30.959501 [info ] [MainThread]: 
[0m18:34:30.964084 [error] [MainThread]: [31mFailure in model dim_payment (models/marts/dim_payment.sql)[0m
[0m18:34:30.966410 [error] [MainThread]:   Database Error in model dim_payment (models/marts/dim_payment.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_payment__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_payment__dbt_backup.9aa46e1b-d0ef-4658-8ee8-f90c5b80b710.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m18:34:30.968715 [info ] [MainThread]: 
[0m18:34:30.970782 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_payment.sql
[0m18:34:30.972799 [info ] [MainThread]: 
[0m18:34:30.978060 [error] [MainThread]: [31mFailure in model dim_product (models/marts/dim_product.sql)[0m
[0m18:34:30.982052 [error] [MainThread]:   Database Error in model dim_product (models/marts/dim_product.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_product__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_product__dbt_backup.f4baf1cb-392e-4993-85c9-2445fd8978ca.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m18:34:30.983784 [info ] [MainThread]: 
[0m18:34:30.986141 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_product.sql
[0m18:34:30.987874 [info ] [MainThread]: 
[0m18:34:30.990960 [error] [MainThread]: [31mFailure in model dim_store (models/marts/dim_store.sql)[0m
[0m18:34:30.994932 [error] [MainThread]:   Database Error in model dim_store (models/marts/dim_store.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_store__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_store__dbt_backup.8095f5aa-f6ec-4add-ad3a-fe649ddccab3.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m18:34:30.996837 [info ] [MainThread]: 
[0m18:34:30.998923 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_store.sql
[0m18:34:31.000298 [info ] [MainThread]: 
[0m18:34:31.002095 [error] [MainThread]: [31mFailure in model dim_supplier (models/marts/dim_supplier.sql)[0m
[0m18:34:31.004203 [error] [MainThread]:   Database Error in model dim_supplier (models/marts/dim_supplier.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/dim_supplier__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.dim_supplier__dbt_backup.e319cff9-db53-4598-bcef-9a0d4b1a3362.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m18:34:31.006076 [info ] [MainThread]: 
[0m18:34:31.009851 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/dim_supplier.sql
[0m18:34:31.011686 [info ] [MainThread]: 
[0m18:34:31.013876 [error] [MainThread]: [31mFailure in model stg_dim_customer (models/staging/stg_dim_customer.sql)[0m
[0m18:34:31.015427 [error] [MainThread]:   Database Error in model stg_dim_customer (models/staging/stg_dim_customer.sql)
  Received ClickHouse exception, code: 1001, server response: std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/c4c/c4c3d523-1822-4254-bf66-e3c66d22f75e/stg_dim_customer__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/default.stg_dim_customer__dbt_backup.0f44aa8b-8357-42f4-880e-8567d99b2c40.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m18:34:31.017033 [info ] [MainThread]: 
[0m18:34:31.018844 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/staging/stg_dim_customer.sql
[0m18:34:31.020616 [info ] [MainThread]: 
[0m18:34:31.022294 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=6 SKIP=1 NO-OP=0 TOTAL=7
[0m18:34:31.028048 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.4479604, "process_in_blocks": "0", "process_kernel_time": 0.34479, "process_mem_max_rss": "120280", "process_out_blocks": "2258", "process_user_time": 3.242476}
[0m18:34:31.029992 [debug] [MainThread]: Command `dbt run` failed at 18:34:31.029673 after 2.45 seconds
[0m18:34:31.031131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa814819f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81a609310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa816c40a10>]}
[0m18:34:31.032009 [debug] [MainThread]: Flushing usage events
[0m18:34:31.684240 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:40:02.779421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e32caaa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e32caaa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e32cab690>]}


============================== 18:40:02.786248 | 773fdffd-4f4f-48e6-bf94-e33d681e8715 ==============================
[0m18:40:02.786248 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:40:02.787623 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/dbt', 'log_path': '/dbt/logs', 'printer_width': '80', 'log_cache_events': 'False', 'warn_error': 'None', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'use_experimental_parser': 'False', 'static_parser': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'empty': 'None', 'use_colors': 'True', 'no_print': 'None', 'version_check': 'True', 'debug': 'False'}
[0m18:40:02.800660 [info ] [MainThread]: dbt version: 1.10.13
[0m18:40:02.802031 [info ] [MainThread]: python version: 3.11.14
[0m18:40:02.803163 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m18:40:02.804435 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m18:40:02.877224 [info ] [MainThread]: Using profiles dir at /dbt
[0m18:40:02.878737 [info ] [MainThread]: Using profiles.yml file at /dbt/profiles.yml
[0m18:40:02.879976 [info ] [MainThread]: Using dbt_project.yml file at /dbt/dbt_project.yml
[0m18:40:02.881522 [info ] [MainThread]: adapter type: clickhouse
[0m18:40:02.882506 [info ] [MainThread]: adapter version: 1.9.5
[0m18:40:02.990182 [info ] [MainThread]: Configuration:
[0m18:40:02.991542 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:40:02.992703 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:40:02.994225 [info ] [MainThread]: Required dependencies:
[0m18:40:02.995529 [debug] [MainThread]: Executing "git --help"
[0m18:40:02.999691 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:40:03.000564 [debug] [MainThread]: STDERR: "b''"
[0m18:40:03.001205 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:40:03.001950 [info ] [MainThread]: Connection:
[0m18:40:03.003231 [info ] [MainThread]:   driver: None
[0m18:40:03.004267 [info ] [MainThread]:   host: clickhouse-server
[0m18:40:03.005116 [info ] [MainThread]:   port: 8123
[0m18:40:03.006081 [info ] [MainThread]:   user: default
[0m18:40:03.007004 [info ] [MainThread]:   schema: default
[0m18:40:03.007864 [info ] [MainThread]:   retries: 1
[0m18:40:03.008773 [info ] [MainThread]:   cluster: None
[0m18:40:03.010040 [info ] [MainThread]:   database_engine: None
[0m18:40:03.010894 [info ] [MainThread]:   cluster_mode: False
[0m18:40:03.011749 [info ] [MainThread]:   secure: False
[0m18:40:03.012692 [info ] [MainThread]:   verify: True
[0m18:40:03.013579 [info ] [MainThread]:   client_cert: None
[0m18:40:03.014494 [info ] [MainThread]:   client_cert_key: None
[0m18:40:03.015504 [info ] [MainThread]:   connect_timeout: 10
[0m18:40:03.016381 [info ] [MainThread]:   send_receive_timeout: 300
[0m18:40:03.017264 [info ] [MainThread]:   sync_request_timeout: 5
[0m18:40:03.018187 [info ] [MainThread]:   compress_block_size: 1048576
[0m18:40:03.019065 [info ] [MainThread]:   compression: 
[0m18:40:03.019958 [info ] [MainThread]:   check_exchange: True
[0m18:40:03.020756 [info ] [MainThread]:   custom_settings: None
[0m18:40:03.021713 [info ] [MainThread]:   use_lw_deletes: False
[0m18:40:03.022638 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m18:40:03.023497 [info ] [MainThread]:   tcp_keepalive: False
[0m18:40:03.024476 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:40:03.093343 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m18:40:03.094521 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:40:03.152689 [debug] [MainThread]: dbt_clickhouse adapter: Got a retryable error when attempting to open a clickhouse connection.
1 attempts remaining. Retrying in 1 seconds.
Error:
Error HTTPConnectionPool(host='clickhouse-server', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8e328b4c10>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://clickhouse-server:8123)
[0m18:40:04.160617 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m18:40:04.162565 [info ] [MainThread]: [31m1 check failed:[0m
[0m18:40:04.164510 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  Error HTTPConnectionPool(host='clickhouse-server', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8e328b6b50>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://clickhouse-server:8123)

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m18:40:04.166756 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 1.4470848, "process_in_blocks": "0", "process_kernel_time": 0.528359, "process_mem_max_rss": "108080", "process_out_blocks": "2135", "process_user_time": 2.110346}
[0m18:40:04.168084 [debug] [MainThread]: Command `dbt debug` failed at 18:40:04.167804 after 1.45 seconds
[0m18:40:04.168939 [debug] [MainThread]: Connection 'debug' was left open.
[0m18:40:04.169954 [debug] [MainThread]: On debug: No close available on handle
[0m18:40:04.170792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e32ccbe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e32da7110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e32da7b90>]}
[0m18:40:04.171689 [debug] [MainThread]: Flushing usage events
[0m18:40:04.715598 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:42:10.123975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ebf9e750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ebf9cf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ebf9e910>]}


============================== 18:42:10.130533 | 66c73d55-9963-437a-bdb5-55c31db14178 ==============================
[0m18:42:10.130533 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:42:10.131771 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'no_print': 'None', 'empty': 'None', 'partial_parse': 'True', 'introspect': 'True', 'warn_error': 'None', 'printer_width': '80', 'invocation_command': 'dbt debug', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'log_format': 'default', 'log_cache_events': 'False', 'static_parser': 'True', 'log_path': '/dbt/logs', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'profiles_dir': '/dbt', 'write_json': 'True', 'quiet': 'False', 'debug': 'False', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True'}
[0m18:42:10.143120 [info ] [MainThread]: dbt version: 1.10.13
[0m18:42:10.144505 [info ] [MainThread]: python version: 3.11.14
[0m18:42:10.145815 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m18:42:10.147238 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.41
[0m18:42:10.221265 [info ] [MainThread]: Using profiles dir at /dbt
[0m18:42:10.222515 [info ] [MainThread]: Using profiles.yml file at /dbt/profiles.yml
[0m18:42:10.223911 [info ] [MainThread]: Using dbt_project.yml file at /dbt/dbt_project.yml
[0m18:42:10.225492 [info ] [MainThread]: adapter type: clickhouse
[0m18:42:10.226818 [info ] [MainThread]: adapter version: 1.9.5
[0m18:42:10.334691 [info ] [MainThread]: Configuration:
[0m18:42:10.335915 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:42:10.337231 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:42:10.338423 [info ] [MainThread]: Required dependencies:
[0m18:42:10.339625 [debug] [MainThread]: Executing "git --help"
[0m18:42:10.343247 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:42:10.344890 [debug] [MainThread]: STDERR: "b''"
[0m18:42:10.345988 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:42:10.347026 [info ] [MainThread]: Connection:
[0m18:42:10.348230 [info ] [MainThread]:   driver: None
[0m18:42:10.349561 [info ] [MainThread]:   host: clickhouse-server
[0m18:42:10.350638 [info ] [MainThread]:   port: 8123
[0m18:42:10.351920 [info ] [MainThread]:   user: default
[0m18:42:10.353166 [info ] [MainThread]:   schema: default
[0m18:42:10.354278 [info ] [MainThread]:   retries: 1
[0m18:42:10.355429 [info ] [MainThread]:   cluster: None
[0m18:42:10.356410 [info ] [MainThread]:   database_engine: None
[0m18:42:10.357428 [info ] [MainThread]:   cluster_mode: False
[0m18:42:10.358549 [info ] [MainThread]:   secure: False
[0m18:42:10.359727 [info ] [MainThread]:   verify: True
[0m18:42:10.361080 [info ] [MainThread]:   client_cert: None
[0m18:42:10.361900 [info ] [MainThread]:   client_cert_key: None
[0m18:42:10.362847 [info ] [MainThread]:   connect_timeout: 10
[0m18:42:10.363730 [info ] [MainThread]:   send_receive_timeout: 300
[0m18:42:10.364717 [info ] [MainThread]:   sync_request_timeout: 5
[0m18:42:10.365666 [info ] [MainThread]:   compress_block_size: 1048576
[0m18:42:10.366557 [info ] [MainThread]:   compression: 
[0m18:42:10.367644 [info ] [MainThread]:   check_exchange: True
[0m18:42:10.368840 [info ] [MainThread]:   custom_settings: None
[0m18:42:10.369889 [info ] [MainThread]:   use_lw_deletes: False
[0m18:42:10.371031 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m18:42:10.372194 [info ] [MainThread]:   tcp_keepalive: False
[0m18:42:10.374426 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:42:10.443393 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m18:42:10.444557 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:42:10.504892 [debug] [MainThread]: dbt_clickhouse adapter: Got a retryable error when attempting to open a clickhouse connection.
1 attempts remaining. Retrying in 1 seconds.
Error:
Error HTTPConnectionPool(host='clickhouse-server', port=8123): Max retries exceeded with url: /? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb6ebaacc50>: Failed to establish a new connection: [Errno 111] Connection refused')) executing HTTP request attempt 1 (http://clickhouse-server:8123)
[0m18:42:11.562634 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m18:42:11.566531 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:11.587739 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m18:42:11.589044 [info ] [MainThread]: [32mAll checks passed![0m
[0m18:42:11.591403 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 1.5277047, "process_in_blocks": "0", "process_kernel_time": 0.455928, "process_mem_max_rss": "113156", "process_out_blocks": "2134", "process_user_time": 2.228297}
[0m18:42:11.592503 [debug] [MainThread]: Command `dbt debug` succeeded at 18:42:11.592339 after 1.53 seconds
[0m18:42:11.593303 [debug] [MainThread]: Connection 'debug' was left open.
[0m18:42:11.594108 [debug] [MainThread]: On debug: Close
[0m18:42:11.594905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ec1fa490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ec2d9f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ebdf5b50>]}
[0m18:42:11.596064 [debug] [MainThread]: Flushing usage events
[0m18:42:12.163431 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:42:39.387624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639d71a650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639d71b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639d5f4c50>]}


============================== 18:42:39.391674 | 72a05862-d8c3-4b9c-aa5c-457b5c36bf82 ==============================
[0m18:42:39.391674 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:42:39.393517 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': '/dbt', 'use_colors': 'True', 'version_check': 'True', 'empty': 'None', 'warn_error': 'None', 'log_format': 'default', 'introspect': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'invocation_command': 'dbt seed', 'quiet': 'False', 'fail_fast': 'False', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'no_print': 'None', 'log_path': '/dbt/logs', 'debug': 'False', 'static_parser': 'True', 'use_experimental_parser': 'False', 'write_json': 'True'}
[0m18:42:39.594345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '72a05862-d8c3-4b9c-aa5c-457b5c36bf82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639d461410>]}
[0m18:42:39.662809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '72a05862-d8c3-4b9c-aa5c-457b5c36bf82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639db90990>]}
[0m18:42:39.664405 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:42:39.745471 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:42:39.877710 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:42:39.878629 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:42:39.915337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '72a05862-d8c3-4b9c-aa5c-457b5c36bf82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639d258210>]}
[0m18:42:40.007218 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:42:40.010494 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:42:40.034470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '72a05862-d8c3-4b9c-aa5c-457b5c36bf82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639d205110>]}
[0m18:42:40.035888 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:42:40.037396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '72a05862-d8c3-4b9c-aa5c-457b5c36bf82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639d10f550>]}
[0m18:42:40.044698 [info ] [MainThread]: 
[0m18:42:40.047482 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:42:40.049377 [info ] [MainThread]: 
[0m18:42:40.051794 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:42:40.068615 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:42:40.089366 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:42:40.198686 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:42:40.204363 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:40.281716 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m18:42:40.289344 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:42:40.339185 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:42:40.353042 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:40.355414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '72a05862-d8c3-4b9c-aa5c-457b5c36bf82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63a02e0390>]}
[0m18:42:40.366313 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:42:40.367547 [info ] [Thread-1 (]: 1 of 5 START seed file `default`.`stg_dim_date` ................................ [RUN]
[0m18:42:40.368874 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now seed.clickhouse_dbt_demo.stg_dim_date)
[0m18:42:40.370302 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:42:40.372929 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:42:40.426305 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */

    create table `default`.`stg_dim_date` 
   ("DateKey" Int32,"FullDate" Date,"Year" Int32,"Month" Int32,"Day" Int32,"DayOfWeek" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m18:42:40.437156 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:40.445759 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */
insert into `default`.`stg_dim_date` ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")
      
      format CSV
      1,2025-09-18,2025,9,18,Thursday
2,2025-09-19,2025,9,19,Friday
3,2025-09-20,2025,9,20,Saturday
...
[0m18:42:40.451799 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:40.458674 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_date"
[0m18:42:40.489250 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '72a05862-d8c3-4b9c-aa5c-457b5c36bf82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639cea4590>]}
[0m18:42:40.490633 [info ] [Thread-1 (]: 1 of 5 OK loaded seed file default.stg_dim_date ................................ [[32mINSERT 3[0m in 0.12s]
[0m18:42:40.491994 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:42:40.493433 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:42:40.495356 [info ] [Thread-1 (]: 2 of 5 START seed file `default`.`stg_dim_payment` ............................. [RUN]
[0m18:42:40.499139 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_date, now seed.clickhouse_dbt_demo.stg_dim_payment)
[0m18:42:40.501342 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:42:40.502713 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:42:40.509097 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */

    create table `default`.`stg_dim_payment` 
   ("PaymentKey" Int32,"PaymentType" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m18:42:40.521701 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:40.523790 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */
insert into `default`.`stg_dim_payment` ("PaymentKey", "PaymentType")
      
      format CSV
      1,Cash
2,Card
3,Voucher
...
[0m18:42:40.531266 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:40.532639 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_payment"
[0m18:42:40.536981 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '72a05862-d8c3-4b9c-aa5c-457b5c36bf82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639e60ca50>]}
[0m18:42:40.538116 [info ] [Thread-1 (]: 2 of 5 OK loaded seed file default.stg_dim_payment ............................. [[32mINSERT 3[0m in 0.04s]
[0m18:42:40.539350 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:42:40.540550 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:42:40.541908 [info ] [Thread-1 (]: 3 of 5 START seed file `default`.`stg_dim_product` ............................. [RUN]
[0m18:42:40.543803 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_payment, now seed.clickhouse_dbt_demo.stg_dim_product)
[0m18:42:40.548100 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:42:40.549431 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:42:40.557354 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */

    create table `default`.`stg_dim_product` 
   ("ProductKey" Int32,"ProductName" String,"Category" String,"Brand" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m18:42:40.568685 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:40.570889 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */
insert into `default`.`stg_dim_product` ("ProductKey", "ProductName", "Category", "Brand")
      
      format CSV
      1,Apple,Fruit,FreshFarm
2,Banana,Fruit,Tropicana
3,Milk,Dairy,DairyBest
4,Bread,Bakery,BakeHouse
...
[0m18:42:40.576433 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:40.578877 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_product"
[0m18:42:40.583356 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '72a05862-d8c3-4b9c-aa5c-457b5c36bf82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639d3e3590>]}
[0m18:42:40.584957 [info ] [Thread-1 (]: 3 of 5 OK loaded seed file default.stg_dim_product ............................. [[32mINSERT 4[0m in 0.04s]
[0m18:42:40.586548 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:42:40.587726 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:42:40.588947 [info ] [Thread-1 (]: 4 of 5 START seed file `default`.`stg_dim_store` ............................... [RUN]
[0m18:42:40.590266 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_product, now seed.clickhouse_dbt_demo.stg_dim_store)
[0m18:42:40.591870 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:42:40.593525 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:42:40.600960 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */

    create table `default`.`stg_dim_store` 
   ("StoreKey" Int32,"StoreName" String,"City" String,"Region" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m18:42:40.612836 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:40.615295 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */
insert into `default`.`stg_dim_store` ("StoreKey", "StoreName", "City", "Region")
      
      format CSV
      1,SuperMart Downtown,Tallinn,North
2,SuperMart Suburb,Tartu,South
...
[0m18:42:40.620480 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:40.621607 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_store"
[0m18:42:40.625550 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '72a05862-d8c3-4b9c-aa5c-457b5c36bf82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639d3cdb10>]}
[0m18:42:40.626633 [info ] [Thread-1 (]: 4 of 5 OK loaded seed file default.stg_dim_store ............................... [[32mINSERT 2[0m in 0.04s]
[0m18:42:40.629007 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:42:40.630676 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:42:40.631673 [info ] [Thread-1 (]: 5 of 5 START seed file `default`.`stg_dim_supplier` ............................ [RUN]
[0m18:42:40.633334 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_store, now seed.clickhouse_dbt_demo.stg_dim_supplier)
[0m18:42:40.635735 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:42:40.636853 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:42:40.642637 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */

    create table `default`.`stg_dim_supplier` 
   ("SupplierKey" Int32,"SupplierName" String,"ContactInfo" String)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m18:42:40.655293 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:40.657250 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */
insert into `default`.`stg_dim_supplier` ("SupplierKey", "SupplierName", "ContactInfo")
      
      format CSV
      1,FreshFarm Supplier,fresh@farm.com
2,Tropicana Supplier,contact@tropicana.com
3,DairyBest Supplier,sales@dairybest.com
4,BakeHouse Supplier,info@bakehouse.com
...
[0m18:42:40.664886 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:40.666180 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_supplier"
[0m18:42:40.670255 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '72a05862-d8c3-4b9c-aa5c-457b5c36bf82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f639d15ac10>]}
[0m18:42:40.671295 [info ] [Thread-1 (]: 5 of 5 OK loaded seed file default.stg_dim_supplier ............................ [[32mINSERT 4[0m in 0.04s]
[0m18:42:40.672616 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:42:40.675539 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:42:40.676254 [debug] [MainThread]: Connection 'list_' was left open.
[0m18:42:40.677046 [debug] [MainThread]: On list_: Close
[0m18:42:40.678029 [debug] [MainThread]: Connection 'seed.clickhouse_dbt_demo.stg_dim_supplier' was left open.
[0m18:42:40.680318 [debug] [MainThread]: On seed.clickhouse_dbt_demo.stg_dim_supplier: Close
[0m18:42:40.682273 [info ] [MainThread]: 
[0m18:42:40.684031 [info ] [MainThread]: Finished running 5 seeds in 0 hours 0 minutes and 0.63 seconds (0.63s).
[0m18:42:40.686798 [debug] [MainThread]: Command end result
[0m18:42:40.735251 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:42:40.738783 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:42:40.747126 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:42:40.748278 [info ] [MainThread]: 
[0m18:42:40.749687 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:42:40.750916 [info ] [MainThread]: 
[0m18:42:40.752612 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m18:42:40.754841 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 1.4280205, "process_in_blocks": "0", "process_kernel_time": 0.265775, "process_mem_max_rss": "120168", "process_out_blocks": "2304", "process_user_time": 2.427758}
[0m18:42:40.755987 [debug] [MainThread]: Command `dbt seed` succeeded at 18:42:40.755786 after 1.43 seconds
[0m18:42:40.757049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63a1f54e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63a1f54550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63a1f55590>]}
[0m18:42:40.758096 [debug] [MainThread]: Flushing usage events
[0m18:42:41.294800 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:42:45.997079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867c040410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867be67e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867c1b61d0>]}


============================== 18:42:46.001290 | 11196794-40ab-43c9-b748-cb87e69cc4b3 ==============================
[0m18:42:46.001290 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:42:46.003090 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'use_colors': 'True', 'target_path': 'None', 'log_format': 'default', 'profiles_dir': '/dbt', 'warn_error': 'None', 'use_experimental_parser': 'False', 'no_print': 'None', 'cache_selected_only': 'False', 'printer_width': '80', 'version_check': 'True', 'write_json': 'True', 'log_path': '/dbt/logs', 'fail_fast': 'False', 'log_cache_events': 'False', 'empty': 'None', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'partial_parse': 'True', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt seed'}
[0m18:42:46.197823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '11196794-40ab-43c9-b748-cb87e69cc4b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867c02ea50>]}
[0m18:42:46.266977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '11196794-40ab-43c9-b748-cb87e69cc4b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867c598850>]}
[0m18:42:46.268328 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:42:46.349507 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:42:46.468457 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:42:46.469623 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:42:46.508244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '11196794-40ab-43c9-b748-cb87e69cc4b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867bb1ee90>]}
[0m18:42:46.600179 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:42:46.603570 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:42:46.619608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '11196794-40ab-43c9-b748-cb87e69cc4b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867ba9b210>]}
[0m18:42:46.620639 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:42:46.621519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '11196794-40ab-43c9-b748-cb87e69cc4b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867bbe4d10>]}
[0m18:42:46.624931 [info ] [MainThread]: 
[0m18:42:46.628274 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:42:46.630157 [info ] [MainThread]: 
[0m18:42:46.631951 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:42:46.641646 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:42:46.661053 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:42:46.745874 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:42:46.750214 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:46.827142 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m18:42:46.834113 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:42:46.878732 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:42:46.885325 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:46.888840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '11196794-40ab-43c9-b748-cb87e69cc4b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867ea1f450>]}
[0m18:42:46.892561 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:42:46.893584 [info ] [Thread-1 (]: 1 of 5 START seed file `default`.`stg_dim_date` ................................ [RUN]
[0m18:42:46.894797 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now seed.clickhouse_dbt_demo.stg_dim_date)
[0m18:42:46.895839 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:42:46.896904 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:42:46.937259 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */
truncate table `default`.`stg_dim_date` 
  ...
[0m18:42:46.943052 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:46.952266 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */
insert into `default`.`stg_dim_date` ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")
      
      format CSV
      1,2025-09-18,2025,9,18,Thursday
2,2025-09-19,2025,9,19,Friday
3,2025-09-20,2025,9,20,Saturday
...
[0m18:42:46.960121 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:46.966382 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_date"
[0m18:42:46.989939 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11196794-40ab-43c9-b748-cb87e69cc4b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867c5bda10>]}
[0m18:42:46.991348 [info ] [Thread-1 (]: 1 of 5 OK loaded seed file default.stg_dim_date ................................ [[32mINSERT 3[0m in 0.09s]
[0m18:42:46.992862 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:42:46.994115 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:42:46.995919 [info ] [Thread-1 (]: 2 of 5 START seed file `default`.`stg_dim_payment` ............................. [RUN]
[0m18:42:46.999279 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_date, now seed.clickhouse_dbt_demo.stg_dim_payment)
[0m18:42:47.000775 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:42:47.001919 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:42:47.014045 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */
truncate table `default`.`stg_dim_payment` 
  ...
[0m18:42:47.018963 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:47.020877 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */
insert into `default`.`stg_dim_payment` ("PaymentKey", "PaymentType")
      
      format CSV
      1,Cash
2,Card
3,Voucher
...
[0m18:42:47.028294 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:47.029528 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_payment"
[0m18:42:47.033695 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11196794-40ab-43c9-b748-cb87e69cc4b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867ab6e150>]}
[0m18:42:47.034710 [info ] [Thread-1 (]: 2 of 5 OK loaded seed file default.stg_dim_payment ............................. [[32mINSERT 3[0m in 0.03s]
[0m18:42:47.035799 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:42:47.037013 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:42:47.038141 [info ] [Thread-1 (]: 3 of 5 START seed file `default`.`stg_dim_product` ............................. [RUN]
[0m18:42:47.039383 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_payment, now seed.clickhouse_dbt_demo.stg_dim_product)
[0m18:42:47.040820 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:42:47.042717 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:42:47.051724 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */
truncate table `default`.`stg_dim_product` 
  ...
[0m18:42:47.056969 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:47.061753 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */
insert into `default`.`stg_dim_product` ("ProductKey", "ProductName", "Category", "Brand")
      
      format CSV
      1,Apple,Fruit,FreshFarm
2,Banana,Fruit,Tropicana
3,Milk,Dairy,DairyBest
4,Bread,Bakery,BakeHouse
...
[0m18:42:47.067507 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:47.068805 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_product"
[0m18:42:47.072378 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11196794-40ab-43c9-b748-cb87e69cc4b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867ab6ce10>]}
[0m18:42:47.073978 [info ] [Thread-1 (]: 3 of 5 OK loaded seed file default.stg_dim_product ............................. [[32mINSERT 4[0m in 0.03s]
[0m18:42:47.077102 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:42:47.078332 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:42:47.079314 [info ] [Thread-1 (]: 4 of 5 START seed file `default`.`stg_dim_store` ............................... [RUN]
[0m18:42:47.080296 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_product, now seed.clickhouse_dbt_demo.stg_dim_store)
[0m18:42:47.081821 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:42:47.082812 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:42:47.089728 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */
truncate table `default`.`stg_dim_store` 
  ...
[0m18:42:47.097226 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:47.099656 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */
insert into `default`.`stg_dim_store` ("StoreKey", "StoreName", "City", "Region")
      
      format CSV
      1,SuperMart Downtown,Tallinn,North
2,SuperMart Suburb,Tartu,South
...
[0m18:42:47.105263 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:47.107169 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_store"
[0m18:42:47.112260 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11196794-40ab-43c9-b748-cb87e69cc4b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867abb0750>]}
[0m18:42:47.113185 [info ] [Thread-1 (]: 4 of 5 OK loaded seed file default.stg_dim_store ............................... [[32mINSERT 2[0m in 0.03s]
[0m18:42:47.114137 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:42:47.115180 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:42:47.116344 [info ] [Thread-1 (]: 5 of 5 START seed file `default`.`stg_dim_supplier` ............................ [RUN]
[0m18:42:47.117657 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_store, now seed.clickhouse_dbt_demo.stg_dim_supplier)
[0m18:42:47.118557 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:42:47.119334 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:42:47.131087 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */
truncate table `default`.`stg_dim_supplier` 
  ...
[0m18:42:47.140385 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:47.145158 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */
insert into `default`.`stg_dim_supplier` ("SupplierKey", "SupplierName", "ContactInfo")
      
      format CSV
      1,FreshFarm Supplier,fresh@farm.com
2,Tropicana Supplier,contact@tropicana.com
3,DairyBest Supplier,sales@dairybest.com
4,BakeHouse Supplier,info@bakehouse.com
...
[0m18:42:47.152011 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:47.153224 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_supplier"
[0m18:42:47.158905 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11196794-40ab-43c9-b748-cb87e69cc4b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867ace7210>]}
[0m18:42:47.160919 [info ] [Thread-1 (]: 5 of 5 OK loaded seed file default.stg_dim_supplier ............................ [[32mINSERT 4[0m in 0.04s]
[0m18:42:47.162255 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:42:47.165307 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:42:47.166601 [debug] [MainThread]: Connection 'list_' was left open.
[0m18:42:47.167310 [debug] [MainThread]: On list_: Close
[0m18:42:47.168073 [debug] [MainThread]: Connection 'seed.clickhouse_dbt_demo.stg_dim_supplier' was left open.
[0m18:42:47.168809 [debug] [MainThread]: On seed.clickhouse_dbt_demo.stg_dim_supplier: Close
[0m18:42:47.169665 [info ] [MainThread]: 
[0m18:42:47.170335 [info ] [MainThread]: Finished running 5 seeds in 0 hours 0 minutes and 0.54 seconds (0.54s).
[0m18:42:47.172364 [debug] [MainThread]: Command end result
[0m18:42:47.226272 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:42:47.229936 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:42:47.239192 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:42:47.240674 [info ] [MainThread]: 
[0m18:42:47.242018 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:42:47.243661 [info ] [MainThread]: 
[0m18:42:47.245255 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m18:42:47.249240 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 1.3167416, "process_in_blocks": "0", "process_kernel_time": 0.239911, "process_mem_max_rss": "119612", "process_out_blocks": "2181", "process_user_time": 2.448328}
[0m18:42:47.250684 [debug] [MainThread]: Command `dbt seed` succeeded at 18:42:47.250512 after 1.32 seconds
[0m18:42:47.251637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867be82450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8680b0b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f867c2d48d0>]}
[0m18:42:47.252537 [debug] [MainThread]: Flushing usage events
[0m18:42:47.784929 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:42:51.479813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873d523490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873d444c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873d409150>]}


============================== 18:42:51.483805 | 48a03b73-57a7-40c7-9d6a-50c3e5131cf2 ==============================
[0m18:42:51.483805 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:42:51.485000 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'use_colors': 'True', 'target_path': 'None', 'log_cache_events': 'False', 'static_parser': 'True', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'invocation_command': 'dbt run', 'use_experimental_parser': 'False', 'log_path': '/dbt/logs', 'fail_fast': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'no_print': 'None', 'partial_parse': 'True', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'profiles_dir': '/dbt', 'debug': 'False', 'empty': 'False', 'printer_width': '80', 'write_json': 'True'}
[0m18:42:51.681655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873d21d3d0>]}
[0m18:42:51.748640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873d998950>]}
[0m18:42:51.750776 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:42:51.834141 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:42:51.955678 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:42:51.956524 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:42:51.994405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873d0cf450>]}
[0m18:42:52.085089 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:42:52.088507 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:42:52.103819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873d1e7790>]}
[0m18:42:52.105137 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:42:52.106054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873cfd73d0>]}
[0m18:42:52.109137 [info ] [MainThread]: 
[0m18:42:52.111797 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:42:52.113620 [info ] [MainThread]: 
[0m18:42:52.115124 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:42:52.127118 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:42:52.141969 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:42:52.228695 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:42:52.232930 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:52.313220 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m18:42:52.321173 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:42:52.328529 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.332483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873cfebd90>]}
[0m18:42:52.336737 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m18:42:52.337895 [info ] [Thread-1 (]: 1 of 7 START sql table model `default`.`dim_date` .............................. [RUN]
[0m18:42:52.339084 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m18:42:52.340649 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m18:42:52.350519 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m18:42:52.355163 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m18:42:52.379746 [debug] [Thread-1 (]: Creating new relation dim_date
[0m18:42:52.422300 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m18:42:52.435770 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.456322 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:42:52.462618 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:52.467673 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m18:42:52.471346 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m18:42:52.479110 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.500307 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873d1b3810>]}
[0m18:42:52.501861 [info ] [Thread-1 (]: 1 of 7 OK created sql table model `default`.`dim_date` ......................... [[32mOK[0m in 0.16s]
[0m18:42:52.503267 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m18:42:52.504811 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m18:42:52.506274 [info ] [Thread-1 (]: 2 of 7 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m18:42:52.509466 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m18:42:52.511387 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m18:42:52.515181 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:42:52.517962 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m18:42:52.522522 [debug] [Thread-1 (]: Creating new relation dim_payment
[0m18:42:52.525930 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:42:52.537269 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.545429 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:42:52.550969 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:52.555182 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:42:52.558685 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:42:52.567144 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.572620 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8737f60e50>]}
[0m18:42:52.573800 [info ] [Thread-1 (]: 2 of 7 OK created sql table model `default`.`dim_payment` ...................... [[32mOK[0m in 0.06s]
[0m18:42:52.574866 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m18:42:52.575559 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m18:42:52.576926 [info ] [Thread-1 (]: 3 of 7 START sql table model `default`.`dim_product` ........................... [RUN]
[0m18:42:52.578226 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m18:42:52.579213 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m18:42:52.582896 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m18:42:52.585263 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m18:42:52.590216 [debug] [Thread-1 (]: Creating new relation dim_product
[0m18:42:52.592442 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:42:52.603454 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.609087 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:42:52.614571 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:52.617008 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m18:42:52.619624 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:42:52.630229 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.632793 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8737f6ec90>]}
[0m18:42:52.633953 [info ] [Thread-1 (]: 3 of 7 OK created sql table model `default`.`dim_product` ...................... [[32mOK[0m in 0.05s]
[0m18:42:52.635940 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m18:42:52.638355 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m18:42:52.639772 [info ] [Thread-1 (]: 4 of 7 START sql table model `default`.`dim_store` ............................. [RUN]
[0m18:42:52.641058 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m18:42:52.642117 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m18:42:52.645674 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m18:42:52.647980 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m18:42:52.651111 [debug] [Thread-1 (]: Creating new relation dim_store
[0m18:42:52.653248 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m18:42:52.666713 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.672194 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:42:52.678398 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:42:52.681014 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m18:42:52.683231 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m18:42:52.693877 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.696904 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8737f84c10>]}
[0m18:42:52.698009 [info ] [Thread-1 (]: 4 of 7 OK created sql table model `default`.`dim_store` ........................ [[32mOK[0m in 0.06s]
[0m18:42:52.699229 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m18:42:52.700319 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m18:42:52.701532 [info ] [Thread-1 (]: 5 of 7 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m18:42:52.703297 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m18:42:52.704387 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m18:42:52.710285 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:42:52.712539 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m18:42:52.715786 [debug] [Thread-1 (]: Creating new relation dim_supplier
[0m18:42:52.717493 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m18:42:52.731236 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.742927 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:42:52.749089 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.751895 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:42:52.756804 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m18:42:52.765732 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.768999 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8737fc31d0>]}
[0m18:42:52.771730 [info ] [Thread-1 (]: 5 of 7 OK created sql table model `default`.`dim_supplier` ..................... [[32mOK[0m in 0.07s]
[0m18:42:52.773717 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m18:42:52.775274 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:42:52.776834 [info ] [Thread-1 (]: 6 of 7 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m18:42:52.778378 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m18:42:52.779714 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:42:52.783016 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:42:52.786248 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:42:52.791870 [debug] [Thread-1 (]: Creating new relation stg_dim_customer
[0m18:42:52.793962 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m18:42:52.810940 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:42:52.814788 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:42:52.821894 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.825856 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:42:52.828242 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m18:42:52.839804 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.842587 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8737fb9d10>]}
[0m18:42:52.843967 [info ] [Thread-1 (]: 6 of 7 OK created sql table model `default`.`stg_dim_customer` ................. [[32mOK[0m in 0.06s]
[0m18:42:52.845157 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:42:52.847102 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m18:42:52.848001 [info ] [Thread-1 (]: 7 of 7 START sql table model `default`.`dim_customer` .......................... [RUN]
[0m18:42:52.849147 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.stg_dim_customer, now model.clickhouse_dbt_demo.dim_customer)
[0m18:42:52.850364 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_customer
[0m18:42:52.856270 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_customer"
[0m18:42:52.858827 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_customer
[0m18:42:52.861865 [debug] [Thread-1 (]: Creating new relation dim_customer
[0m18:42:52.863643 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

            

    
        create table `default`.`dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
          )
        
        ...
[0m18:42:52.887775 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:42:52.892880 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:42:52.899170 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.902421 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_customer"
[0m18:42:52.906179 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`dim_customer`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
  ...
[0m18:42:52.914354 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:42:52.917247 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48a03b73-57a7-40c7-9d6a-50c3e5131cf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f873c072990>]}
[0m18:42:52.918870 [info ] [Thread-1 (]: 7 of 7 OK created sql table model `default`.`dim_customer` ..................... [[32mOK[0m in 0.07s]
[0m18:42:52.920048 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m18:42:52.924430 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:42:52.925736 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.dim_customer' was left open.
[0m18:42:52.926719 [debug] [MainThread]: On model.clickhouse_dbt_demo.dim_customer: Close
[0m18:42:52.927606 [info ] [MainThread]: 
[0m18:42:52.928362 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 0.81 seconds (0.81s).
[0m18:42:52.930942 [debug] [MainThread]: Command end result
[0m18:42:52.983764 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:42:52.989186 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:42:52.998291 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:42:52.999337 [info ] [MainThread]: 
[0m18:42:53.000752 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:42:53.002839 [info ] [MainThread]: 
[0m18:42:53.004286 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m18:42:53.008683 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.5889012, "process_in_blocks": "0", "process_kernel_time": 0.285671, "process_mem_max_rss": "119492", "process_out_blocks": "2214", "process_user_time": 2.511231}
[0m18:42:53.010200 [debug] [MainThread]: Command `dbt run` succeeded at 18:42:53.010018 after 1.59 seconds
[0m18:42:53.011243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8741e09090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8741e084d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8741e09490>]}
[0m18:42:53.012328 [debug] [MainThread]: Flushing usage events
[0m18:42:53.675965 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:43:01.134509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c77dd5710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c77c2e250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c77b90790>]}


============================== 18:43:01.138574 | 67aa630b-80dd-4541-bfb5-c40fd309cefd ==============================
[0m18:43:01.138574 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:43:01.139982 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'log_format': 'default', 'profiles_dir': '/dbt', 'debug': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'empty': 'False', 'log_path': '/dbt/logs', 'static_parser': 'True', 'version_check': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'target_path': 'None', 'quiet': 'False', 'use_colors': 'True', 'write_json': 'True', 'printer_width': '80', 'no_print': 'None', 'send_anonymous_usage_stats': 'True'}
[0m18:43:01.336882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c77b34bd0>]}
[0m18:43:01.403740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c78098850>]}
[0m18:43:01.405462 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:43:01.488047 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:43:01.607219 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:43:01.608159 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:43:01.647116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c776363d0>]}
[0m18:43:01.737707 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:43:01.740956 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:43:01.756606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c778f9c90>]}
[0m18:43:01.757570 [info ] [MainThread]: Found 7 models, 5 seeds, 485 macros
[0m18:43:01.758464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c778b7e10>]}
[0m18:43:01.761506 [info ] [MainThread]: 
[0m18:43:01.764071 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:43:01.765726 [info ] [MainThread]: 
[0m18:43:01.767659 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:43:01.776360 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:43:01.791266 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:43:01.879224 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:43:01.883171 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:01.958680 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m18:43:01.966432 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:43:02.019311 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:43:02.025311 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.030487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c7a866910>]}
[0m18:43:02.034226 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m18:43:02.035292 [info ] [Thread-1 (]: 1 of 7 START sql table model `default`.`dim_date` .............................. [RUN]
[0m18:43:02.036387 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m18:43:02.037635 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m18:43:02.049416 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m18:43:02.052526 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m18:43:02.121703 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m18:43:02.136642 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.158405 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:43:02.164596 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.169335 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m18:43:02.172349 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date__dbt_backup`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m18:43:02.179509 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.184973 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
EXCHANGE TABLES `default`.`dim_date__dbt_backup` AND `default`.`dim_date` 
  
  ...
[0m18:43:02.189290 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.214630 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  ...
[0m18:43:02.218758 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.223195 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c778e9090>]}
[0m18:43:02.224825 [info ] [Thread-1 (]: 1 of 7 OK created sql table model `default`.`dim_date` ......................... [[32mOK[0m in 0.19s]
[0m18:43:02.225873 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m18:43:02.227154 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m18:43:02.228387 [info ] [Thread-1 (]: 2 of 7 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m18:43:02.231748 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m18:43:02.234044 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m18:43:02.240368 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:43:02.243740 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m18:43:02.251669 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:43:02.262064 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.268761 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:43:02.274557 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.277132 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:43:02.279851 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:43:02.289572 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.291847 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
EXCHANGE TABLES `default`.`dim_payment__dbt_backup` AND `default`.`dim_payment` 
  
  ...
[0m18:43:02.297417 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.302285 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  ...
[0m18:43:02.306721 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.309224 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c779f91d0>]}
[0m18:43:02.310681 [info ] [Thread-1 (]: 2 of 7 OK created sql table model `default`.`dim_payment` ...................... [[32mOK[0m in 0.08s]
[0m18:43:02.311641 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m18:43:02.313050 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m18:43:02.314919 [info ] [Thread-1 (]: 3 of 7 START sql table model `default`.`dim_product` ........................... [RUN]
[0m18:43:02.316598 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m18:43:02.317515 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m18:43:02.320919 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m18:43:02.322989 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m18:43:02.326971 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:43:02.339816 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.343668 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:43:02.350732 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.353670 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m18:43:02.355871 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:43:02.365899 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.368640 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
EXCHANGE TABLES `default`.`dim_product__dbt_backup` AND `default`.`dim_product` 
  
  ...
[0m18:43:02.372957 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.378860 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  ...
[0m18:43:02.384572 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.386779 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c765005d0>]}
[0m18:43:02.388101 [info ] [Thread-1 (]: 3 of 7 OK created sql table model `default`.`dim_product` ...................... [[32mOK[0m in 0.07s]
[0m18:43:02.389247 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m18:43:02.390460 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m18:43:02.391681 [info ] [Thread-1 (]: 4 of 7 START sql table model `default`.`dim_store` ............................. [RUN]
[0m18:43:02.392697 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m18:43:02.393828 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m18:43:02.398608 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m18:43:02.401027 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m18:43:02.497954 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m18:43:02.513161 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.516845 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:43:02.523292 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.526247 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m18:43:02.529862 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store__dbt_backup`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m18:43:02.540156 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.542193 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
EXCHANGE TABLES `default`.`dim_store__dbt_backup` AND `default`.`dim_store` 
  
  ...
[0m18:43:02.547710 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.552788 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  ...
[0m18:43:02.556242 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.558513 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c766e3750>]}
[0m18:43:02.560299 [info ] [Thread-1 (]: 4 of 7 OK created sql table model `default`.`dim_store` ........................ [[32mOK[0m in 0.17s]
[0m18:43:02.562016 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m18:43:02.563954 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m18:43:02.566951 [info ] [Thread-1 (]: 5 of 7 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m18:43:02.568965 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m18:43:02.570621 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m18:43:02.575393 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:43:02.579195 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m18:43:02.589597 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m18:43:02.606108 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:43:02.611385 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:43:02.620724 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.623825 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:43:02.627105 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier__dbt_backup`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m18:43:02.640174 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.642605 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
EXCHANGE TABLES `default`.`dim_supplier__dbt_backup` AND `default`.`dim_supplier` 
  
  ...
[0m18:43:02.647821 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.652827 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  ...
[0m18:43:02.657177 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.659466 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c766c82d0>]}
[0m18:43:02.661047 [info ] [Thread-1 (]: 5 of 7 OK created sql table model `default`.`dim_supplier` ..................... [[32mOK[0m in 0.09s]
[0m18:43:02.662976 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m18:43:02.666188 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:43:02.670570 [info ] [Thread-1 (]: 6 of 7 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m18:43:02.672607 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m18:43:02.675120 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:43:02.678491 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:43:02.684632 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:43:02.693668 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m18:43:02.709988 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.717240 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:43:02.724903 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.728016 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:43:02.733758 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m18:43:02.744914 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.748865 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
EXCHANGE TABLES `default`.`stg_dim_customer__dbt_backup` AND `default`.`stg_dim_customer` 
  
  ...
[0m18:43:02.754658 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.759687 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  ...
[0m18:43:02.764686 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.767462 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c767d0810>]}
[0m18:43:02.768878 [info ] [Thread-1 (]: 6 of 7 OK created sql table model `default`.`stg_dim_customer` ................. [[32mOK[0m in 0.10s]
[0m18:43:02.770316 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:43:02.773343 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m18:43:02.776711 [info ] [Thread-1 (]: 7 of 7 START sql table model `default`.`dim_customer` .......................... [RUN]
[0m18:43:02.778339 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.stg_dim_customer, now model.clickhouse_dbt_demo.dim_customer)
[0m18:43:02.781982 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_customer
[0m18:43:02.788119 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_customer"
[0m18:43:02.791044 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_customer
[0m18:43:02.795552 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

            

    
        create table `default`.`dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
          )
        
        ...
[0m18:43:02.812543 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:43:02.823780 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:43:02.836924 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.844678 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_customer"
[0m18:43:02.850012 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
  ...
[0m18:43:02.863364 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:43:02.865873 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */
EXCHANGE TABLES `default`.`dim_customer__dbt_backup` AND `default`.`dim_customer` 
  
  ...
[0m18:43:02.871260 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.876636 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */
drop table if exists `default`.`dim_customer__dbt_backup` 
  ...
[0m18:43:02.880635 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:43:02.883176 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67aa630b-80dd-4541-bfb5-c40fd309cefd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c766a6b50>]}
[0m18:43:02.884860 [info ] [Thread-1 (]: 7 of 7 OK created sql table model `default`.`dim_customer` ..................... [[32mOK[0m in 0.11s]
[0m18:43:02.886273 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m18:43:02.889479 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:43:02.890488 [debug] [MainThread]: Connection 'list_' was left open.
[0m18:43:02.891318 [debug] [MainThread]: On list_: Close
[0m18:43:02.892118 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.dim_customer' was left open.
[0m18:43:02.892933 [debug] [MainThread]: On model.clickhouse_dbt_demo.dim_customer: Close
[0m18:43:02.894291 [info ] [MainThread]: 
[0m18:43:02.895389 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 1.13 seconds (1.13s).
[0m18:43:02.900666 [debug] [MainThread]: Command end result
[0m18:43:02.971429 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:43:02.975469 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:43:02.988145 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:43:02.989256 [info ] [MainThread]: 
[0m18:43:02.990876 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:43:02.992531 [info ] [MainThread]: 
[0m18:43:02.993938 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m18:43:02.996906 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.9253953, "process_in_blocks": "0", "process_kernel_time": 0.327684, "process_mem_max_rss": "119896", "process_out_blocks": "2226", "process_user_time": 2.802932}
[0m18:43:02.999903 [debug] [MainThread]: Command `dbt run` succeeded at 18:43:02.999513 after 1.93 seconds
[0m18:43:03.001522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c77984b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c77987c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c7c5fb9d0>]}
[0m18:43:03.003086 [debug] [MainThread]: Flushing usage events
[0m18:43:03.660397 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:45:14.628310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c926c2190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c92871e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c927e84d0>]}


============================== 18:45:14.633402 | 82261902-3b07-434e-aaec-0ccf65a4a7c2 ==============================
[0m18:45:14.633402 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:45:14.634823 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'debug': 'False', 'partial_parse': 'True', 'profiles_dir': '/dbt', 'no_print': 'None', 'version_check': 'True', 'introspect': 'True', 'indirect_selection': 'eager', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'fail_fast': 'False', 'empty': 'None', 'static_parser': 'True', 'log_path': '/dbt/logs', 'warn_error': 'None', 'invocation_command': 'dbt seed', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'printer_width': '80', 'use_colors': 'True', 'use_experimental_parser': 'False', 'target_path': 'None'}
[0m18:45:14.833009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c936b53d0>]}
[0m18:45:14.898084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c92372fd0>]}
[0m18:45:14.899670 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:45:14.983450 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:45:15.119146 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m18:45:15.120317 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://seeds/stg_fact_sales.csv
[0m18:45:15.120993 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://models/marts/fact_sales.sql
[0m18:45:15.577784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c924b2010>]}
[0m18:45:15.956600 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:45:15.961149 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:45:15.981412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c921c4290>]}
[0m18:45:15.982479 [info ] [MainThread]: Found 8 models, 6 seeds, 485 macros
[0m18:45:15.983576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c91b57a90>]}
[0m18:45:15.986732 [info ] [MainThread]: 
[0m18:45:15.988354 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:45:15.989687 [info ] [MainThread]: 
[0m18:45:15.992765 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:45:16.000893 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:45:16.013411 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:45:16.137822 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:45:16.144291 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:16.181747 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m18:45:16.195705 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:45:16.206273 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:16.212567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c921c4210>]}
[0m18:45:16.217544 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:45:16.219081 [info ] [Thread-1 (]: 1 of 6 START seed file `default`.`stg_dim_date` ................................ [RUN]
[0m18:45:16.220313 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now seed.clickhouse_dbt_demo.stg_dim_date)
[0m18:45:16.221303 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:45:16.222310 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:45:16.263069 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */
truncate table `default`.`stg_dim_date` 
  ...
[0m18:45:16.268769 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:16.278563 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_date"} */
insert into `default`.`stg_dim_date` ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")
      
      format CSV
      1,2025-09-18,2025,9,18,Thursday
2,2025-09-19,2025,9,19,Friday
3,2025-09-20,2025,9,20,Saturday
...
[0m18:45:16.284747 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:16.292226 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_date"
[0m18:45:16.320561 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c90f8d550>]}
[0m18:45:16.321945 [info ] [Thread-1 (]: 1 of 6 OK loaded seed file default.stg_dim_date ................................ [[32mINSERT 3[0m in 0.10s]
[0m18:45:16.323457 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_date
[0m18:45:16.324996 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:45:16.326418 [info ] [Thread-1 (]: 2 of 6 START seed file `default`.`stg_dim_payment` ............................. [RUN]
[0m18:45:16.327672 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_date, now seed.clickhouse_dbt_demo.stg_dim_payment)
[0m18:45:16.328841 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:45:16.329661 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:45:16.336865 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */
truncate table `default`.`stg_dim_payment` 
  ...
[0m18:45:16.342752 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:16.345050 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_payment"} */
insert into `default`.`stg_dim_payment` ("PaymentKey", "PaymentType")
      
      format CSV
      1,Cash
2,Card
3,Voucher
...
[0m18:45:16.350708 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:16.352148 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_payment"
[0m18:45:16.356860 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c90f57550>]}
[0m18:45:16.358000 [info ] [Thread-1 (]: 2 of 6 OK loaded seed file default.stg_dim_payment ............................. [[32mINSERT 3[0m in 0.03s]
[0m18:45:16.359586 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_payment
[0m18:45:16.360629 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:45:16.361751 [info ] [Thread-1 (]: 3 of 6 START seed file `default`.`stg_dim_product` ............................. [RUN]
[0m18:45:16.362704 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_payment, now seed.clickhouse_dbt_demo.stg_dim_product)
[0m18:45:16.363805 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:45:16.364688 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:45:16.372478 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */
truncate table `default`.`stg_dim_product` 
  ...
[0m18:45:16.378095 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:16.380248 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_product"} */
insert into `default`.`stg_dim_product` ("ProductKey", "ProductName", "Category", "Brand")
      
      format CSV
      1,Apple,Fruit,FreshFarm
2,Banana,Fruit,Tropicana
3,Milk,Dairy,DairyBest
4,Bread,Bakery,BakeHouse
...
[0m18:45:16.386352 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:16.387626 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_product"
[0m18:45:16.392350 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c90f41ed0>]}
[0m18:45:16.393351 [info ] [Thread-1 (]: 3 of 6 OK loaded seed file default.stg_dim_product ............................. [[32mINSERT 4[0m in 0.03s]
[0m18:45:16.397147 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_product
[0m18:45:16.398405 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:45:16.399421 [info ] [Thread-1 (]: 4 of 6 START seed file `default`.`stg_dim_store` ............................... [RUN]
[0m18:45:16.400784 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_product, now seed.clickhouse_dbt_demo.stg_dim_store)
[0m18:45:16.402355 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:45:16.403205 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:45:16.410111 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */
truncate table `default`.`stg_dim_store` 
  ...
[0m18:45:16.415802 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:16.417959 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_store"} */
insert into `default`.`stg_dim_store` ("StoreKey", "StoreName", "City", "Region")
      
      format CSV
      1,SuperMart Downtown,Tallinn,North
2,SuperMart Suburb,Tartu,South
...
[0m18:45:16.423901 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:16.425156 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_store"
[0m18:45:16.429734 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c90bd6b90>]}
[0m18:45:16.430833 [info ] [Thread-1 (]: 4 of 6 OK loaded seed file default.stg_dim_store ............................... [[32mINSERT 2[0m in 0.03s]
[0m18:45:16.432352 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_store
[0m18:45:16.433463 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:45:16.434592 [info ] [Thread-1 (]: 5 of 6 START seed file `default`.`stg_dim_supplier` ............................ [RUN]
[0m18:45:16.435646 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_store, now seed.clickhouse_dbt_demo.stg_dim_supplier)
[0m18:45:16.436621 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:45:16.437773 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:45:16.445273 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */
truncate table `default`.`stg_dim_supplier` 
  ...
[0m18:45:16.451617 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:16.453624 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_dim_supplier"} */
insert into `default`.`stg_dim_supplier` ("SupplierKey", "SupplierName", "ContactInfo")
      
      format CSV
      1,FreshFarm Supplier,fresh@farm.com
2,Tropicana Supplier,contact@tropicana.com
3,DairyBest Supplier,sales@dairybest.com
4,BakeHouse Supplier,info@bakehouse.com
...
[0m18:45:16.459696 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:16.460962 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_dim_supplier"
[0m18:45:16.465773 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c90fb4e50>]}
[0m18:45:16.466882 [info ] [Thread-1 (]: 5 of 6 OK loaded seed file default.stg_dim_supplier ............................ [[32mINSERT 4[0m in 0.03s]
[0m18:45:16.468331 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_dim_supplier
[0m18:45:16.469395 [debug] [Thread-1 (]: Began running node seed.clickhouse_dbt_demo.stg_fact_sales
[0m18:45:16.470404 [info ] [Thread-1 (]: 6 of 6 START seed file `default`.`stg_fact_sales` .............................. [RUN]
[0m18:45:16.471365 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.clickhouse_dbt_demo.stg_dim_supplier, now seed.clickhouse_dbt_demo.stg_fact_sales)
[0m18:45:16.472259 [debug] [Thread-1 (]: Began compiling node seed.clickhouse_dbt_demo.stg_fact_sales
[0m18:45:16.473292 [debug] [Thread-1 (]: Began executing node seed.clickhouse_dbt_demo.stg_fact_sales
[0m18:45:16.496221 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_fact_sales"} */

    create table `default`.`stg_fact_sales` 
   ("SaleID" Int32,"DateKey" Int32,"StoreKey" Int32,"ProductKey" Int32,"SupplierKey" Int32,"CustomerKey" Int32,"PaymentKey" Int32,"Quantity" Int32,"SalesAmount" Float32,"FullDate" Date)
    
  engine = MergeTree()
    
      order by (tuple())
    
  ...
[0m18:45:16.507098 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:16.509671 [debug] [Thread-1 (]: dbt_clickhouse adapter: On seed.clickhouse_dbt_demo.stg_fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "seed.clickhouse_dbt_demo.stg_fact_sales"} */
insert into `default`.`stg_fact_sales` ("SaleID", "DateKey", "StoreKey", "ProductKey", "SupplierKey", "CustomerKey", "PaymentKey", "Quantity", "SalesAmount", "FullDate")
      
      format CSV
      1,1,1,1,1,1,2,5,6.00,2025-09-18
2,1,1,2,2,1,1,3,2.40,2025-09-18
3,2,2,3,3,2,2,2,5.00,2025-09-19
4,2,2,4,4,2,2,1,1.50,2025-09-19
5,3,1,1,1,2,1,10,12.00,2025-09-20
6,3,1,3,3,1,2,1,2.50,2025-09-20
...
[0m18:45:16.515944 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:16.517447 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.clickhouse_dbt_demo.stg_fact_sales"
[0m18:45:16.526066 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82261902-3b07-434e-aaec-0ccf65a4a7c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c90ba3250>]}
[0m18:45:16.526964 [info ] [Thread-1 (]: 6 of 6 OK loaded seed file default.stg_fact_sales .............................. [[32mINSERT 6[0m in 0.05s]
[0m18:45:16.528338 [debug] [Thread-1 (]: Finished running node seed.clickhouse_dbt_demo.stg_fact_sales
[0m18:45:16.531374 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:45:16.532394 [debug] [MainThread]: Connection 'seed.clickhouse_dbt_demo.stg_fact_sales' was left open.
[0m18:45:16.533825 [debug] [MainThread]: On seed.clickhouse_dbt_demo.stg_fact_sales: Close
[0m18:45:16.535172 [info ] [MainThread]: 
[0m18:45:16.536539 [info ] [MainThread]: Finished running 6 seeds in 0 hours 0 minutes and 0.54 seconds (0.54s).
[0m18:45:16.539683 [debug] [MainThread]: Command end result
[0m18:45:16.594271 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:45:16.597709 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:45:16.606445 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:45:16.608023 [info ] [MainThread]: 
[0m18:45:16.609611 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:45:16.611393 [info ] [MainThread]: 
[0m18:45:16.613208 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m18:45:16.615474 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 2.0567021, "process_in_blocks": "0", "process_kernel_time": 0.336591, "process_mem_max_rss": "123420", "process_out_blocks": "3264", "process_user_time": 3.124895}
[0m18:45:16.616973 [debug] [MainThread]: Command `dbt seed` succeeded at 18:45:16.616702 after 2.06 seconds
[0m18:45:16.618300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c926c0d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c926c1110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c926c1fd0>]}
[0m18:45:16.619199 [debug] [MainThread]: Flushing usage events
[0m18:45:17.327763 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:45:36.423393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fc9e7b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fccb1750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fc9d94d0>]}


============================== 18:45:36.427761 | 467d7bbf-a6e3-4cd1-9c01-c4f835e1984b ==============================
[0m18:45:36.427761 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:45:36.429322 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'invocation_command': 'dbt run', 'log_path': '/dbt/logs', 'no_print': 'None', 'log_format': 'default', 'version_check': 'True', 'target_path': 'None', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'debug': 'False', 'log_cache_events': 'False', 'write_json': 'True', 'cache_selected_only': 'False', 'use_colors': 'True', 'static_parser': 'True', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'profiles_dir': '/dbt', 'introspect': 'True', 'warn_error': 'None'}
[0m18:45:36.631724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fc7f9650>]}
[0m18:45:36.699571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fcf70850>]}
[0m18:45:36.701218 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:45:36.784496 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:45:36.903313 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:45:36.904377 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/fact_sales.sql
[0m18:45:37.163059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fc280210>]}
[0m18:45:37.256934 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:45:37.260254 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:45:37.275808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fc50f1d0>]}
[0m18:45:37.276697 [info ] [MainThread]: Found 8 models, 6 seeds, 485 macros
[0m18:45:37.277543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fc5b1d50>]}
[0m18:45:37.281432 [info ] [MainThread]: 
[0m18:45:37.283761 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:45:37.285504 [info ] [MainThread]: 
[0m18:45:37.287380 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:45:37.295994 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:45:37.309474 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:45:37.464704 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:45:37.470011 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:37.491131 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m18:45:37.498573 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:45:37.552272 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m18:45:37.559833 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:37.564832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fc5c7c50>]}
[0m18:45:37.569344 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m18:45:37.570502 [info ] [Thread-1 (]: 1 of 8 START sql table model `default`.`dim_date` .............................. [RUN]
[0m18:45:37.571749 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m18:45:37.572976 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m18:45:37.587728 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m18:45:37.591173 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m18:45:37.669605 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m18:45:37.680976 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:37.703289 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:45:37.709518 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:37.714748 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m18:45:37.717734 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date__dbt_backup`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m18:45:37.728535 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:37.735360 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
EXCHANGE TABLES `default`.`dim_date__dbt_backup` AND `default`.`dim_date` 
  
  ...
[0m18:45:37.740637 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:37.773977 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  ...
[0m18:45:37.778463 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:37.782826 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fab0d190>]}
[0m18:45:37.784407 [info ] [Thread-1 (]: 1 of 8 OK created sql table model `default`.`dim_date` ......................... [[32mOK[0m in 0.21s]
[0m18:45:37.785922 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m18:45:37.787470 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m18:45:37.788639 [info ] [Thread-1 (]: 2 of 8 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m18:45:37.789517 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m18:45:37.790383 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m18:45:37.795041 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:45:37.798551 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m18:45:37.803074 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:45:37.813580 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:37.818540 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:45:37.824146 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:37.826734 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m18:45:37.831071 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:45:37.841056 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:37.842793 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
EXCHANGE TABLES `default`.`dim_payment__dbt_backup` AND `default`.`dim_payment` 
  
  ...
[0m18:45:37.848847 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:37.853322 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  ...
[0m18:45:37.856980 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:37.859627 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fab12dd0>]}
[0m18:45:37.860831 [info ] [Thread-1 (]: 2 of 8 OK created sql table model `default`.`dim_payment` ...................... [[32mOK[0m in 0.07s]
[0m18:45:37.862389 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m18:45:37.863457 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m18:45:37.864801 [info ] [Thread-1 (]: 3 of 8 START sql table model `default`.`dim_product` ........................... [RUN]
[0m18:45:37.867551 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m18:45:37.868977 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m18:45:37.872836 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m18:45:37.876000 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m18:45:37.882135 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m18:45:37.892941 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:37.898689 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:45:37.904826 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:37.907368 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m18:45:37.909673 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m18:45:37.919584 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:37.921622 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
EXCHANGE TABLES `default`.`dim_product__dbt_backup` AND `default`.`dim_product` 
  
  ...
[0m18:45:37.926126 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:37.931776 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  ...
[0m18:45:37.935056 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:37.937680 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fb3ac150>]}
[0m18:45:37.938707 [info ] [Thread-1 (]: 3 of 8 OK created sql table model `default`.`dim_product` ...................... [[32mOK[0m in 0.07s]
[0m18:45:37.939706 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m18:45:37.940694 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m18:45:37.941954 [info ] [Thread-1 (]: 4 of 8 START sql table model `default`.`dim_store` ............................. [RUN]
[0m18:45:37.943089 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m18:45:37.943978 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m18:45:37.949287 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m18:45:37.951739 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m18:45:37.957212 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m18:45:37.969597 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:37.973162 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:45:37.978722 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:37.983418 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m18:45:37.985704 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store__dbt_backup`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m18:45:37.994489 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:37.998174 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
EXCHANGE TABLES `default`.`dim_store__dbt_backup` AND `default`.`dim_store` 
  
  ...
[0m18:45:38.003043 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:38.007482 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  ...
[0m18:45:38.010921 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:38.013128 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fabb6810>]}
[0m18:45:38.014295 [info ] [Thread-1 (]: 4 of 8 OK created sql table model `default`.`dim_store` ........................ [[32mOK[0m in 0.07s]
[0m18:45:38.015632 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m18:45:38.016849 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m18:45:38.018843 [info ] [Thread-1 (]: 5 of 8 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m18:45:38.021294 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m18:45:38.022442 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m18:45:38.025718 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:45:38.027902 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m18:45:38.035059 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m18:45:38.046301 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:38.052314 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:45:38.057826 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:38.060299 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m18:45:38.063709 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier__dbt_backup`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m18:45:38.072604 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:38.074578 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
EXCHANGE TABLES `default`.`dim_supplier__dbt_backup` AND `default`.`dim_supplier` 
  
  ...
[0m18:45:38.080823 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:38.085422 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  ...
[0m18:45:38.088586 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:38.090841 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fab96f90>]}
[0m18:45:38.091755 [info ] [Thread-1 (]: 5 of 8 OK created sql table model `default`.`dim_supplier` ..................... [[32mOK[0m in 0.07s]
[0m18:45:38.092782 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m18:45:38.093787 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.fact_sales
[0m18:45:38.095119 [info ] [Thread-1 (]: 6 of 8 START sql table model `default`.`fact_sales` ............................ [RUN]
[0m18:45:38.096841 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.fact_sales)
[0m18:45:38.099416 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.fact_sales
[0m18:45:38.103289 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.fact_sales"
[0m18:45:38.105623 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.fact_sales
[0m18:45:38.108502 [debug] [Thread-1 (]: Creating new relation fact_sales
[0m18:45:38.110258 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

            

    
        create table `default`.`fact_sales`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_fact_sales`
          )
        
        ...
[0m18:45:38.123961 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:38.127454 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

    select name, type from system.columns where table = 'fact_sales'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:45:38.135391 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:38.138762 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.fact_sales"
[0m18:45:38.140939 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

  
    
    
    
        
         


        insert into `default`.`fact_sales`
        ("SaleID", "DateKey", "StoreKey", "ProductKey", "SupplierKey", "CustomerKey", "PaymentKey", "Quantity", "SalesAmount", "FullDate")SELECT
    *
FROM `default`.`stg_fact_sales`
  ...
[0m18:45:38.153895 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:38.156927 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fabcae50>]}
[0m18:45:38.158007 [info ] [Thread-1 (]: 6 of 8 OK created sql table model `default`.`fact_sales` ....................... [[32mOK[0m in 0.06s]
[0m18:45:38.159893 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.fact_sales
[0m18:45:38.161024 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:45:38.163004 [info ] [Thread-1 (]: 7 of 8 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m18:45:38.165731 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.fact_sales, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m18:45:38.168011 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:45:38.172938 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:45:38.176731 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:45:38.184040 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m18:45:38.202437 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:45:38.206341 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:45:38.213338 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:38.217160 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m18:45:38.219610 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m18:45:38.231811 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:38.234244 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
EXCHANGE TABLES `default`.`stg_dim_customer__dbt_backup` AND `default`.`stg_dim_customer` 
  
  ...
[0m18:45:38.239047 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:38.243042 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  ...
[0m18:45:38.246682 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:38.248995 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fab79050>]}
[0m18:45:38.249963 [info ] [Thread-1 (]: 7 of 8 OK created sql table model `default`.`stg_dim_customer` ................. [[32mOK[0m in 0.08s]
[0m18:45:38.251257 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m18:45:38.253165 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m18:45:38.254297 [info ] [Thread-1 (]: 8 of 8 START sql table model `default`.`dim_customer` .......................... [RUN]
[0m18:45:38.255313 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.stg_dim_customer, now model.clickhouse_dbt_demo.dim_customer)
[0m18:45:38.256285 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_customer
[0m18:45:38.259676 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_customer"
[0m18:45:38.262415 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_customer
[0m18:45:38.268462 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

            

    
        create table `default`.`dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
          )
        
        ...
[0m18:45:38.280756 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:38.285787 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m18:45:38.292322 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:38.295109 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_customer"
[0m18:45:38.299639 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
  ...
[0m18:45:38.308714 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:45:38.313218 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */
EXCHANGE TABLES `default`.`dim_customer__dbt_backup` AND `default`.`dim_customer` 
  
  ...
[0m18:45:38.317865 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:38.322230 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */
drop table if exists `default`.`dim_customer__dbt_backup` 
  ...
[0m18:45:38.325542 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:45:38.327620 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '467d7bbf-a6e3-4cd1-9c01-c4f835e1984b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fab05510>]}
[0m18:45:38.328603 [info ] [Thread-1 (]: 8 of 8 OK created sql table model `default`.`dim_customer` ..................... [[32mOK[0m in 0.07s]
[0m18:45:38.329683 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m18:45:38.334730 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:45:38.336010 [debug] [MainThread]: Connection 'list_' was left open.
[0m18:45:38.337134 [debug] [MainThread]: On list_: Close
[0m18:45:38.337980 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.dim_customer' was left open.
[0m18:45:38.338660 [debug] [MainThread]: On model.clickhouse_dbt_demo.dim_customer: Close
[0m18:45:38.339601 [info ] [MainThread]: 
[0m18:45:38.340444 [info ] [MainThread]: Finished running 8 table models in 0 hours 0 minutes and 1.05 seconds (1.05s).
[0m18:45:38.343266 [debug] [MainThread]: Command end result
[0m18:45:38.401926 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:45:38.405184 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:45:38.414289 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m18:45:38.415238 [info ] [MainThread]: 
[0m18:45:38.416349 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:45:38.417610 [info ] [MainThread]: 
[0m18:45:38.418753 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=8
[0m18:45:38.422953 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.0625162, "process_in_blocks": "0", "process_kernel_time": 0.288173, "process_mem_max_rss": "122804", "process_out_blocks": "3311", "process_user_time": 2.918656}
[0m18:45:38.424428 [debug] [MainThread]: Command `dbt run` succeeded at 18:45:38.424235 after 2.06 seconds
[0m18:45:38.425250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fc868490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7fc86a9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb801374690>]}
[0m18:45:38.425978 [debug] [MainThread]: Flushing usage events
[0m18:45:39.090943 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:47:15.834723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9557d66290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9558e30e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9557f383d0>]}


============================== 18:47:15.838614 | d982842d-2da3-4d3c-84f3-3ce53cc410a2 ==============================
[0m18:47:15.838614 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:47:15.840059 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'write_json': 'True', 'log_cache_events': 'False', 'use_colors': 'True', 'invocation_command': 'dbt ls', 'static_parser': 'True', 'fail_fast': 'False', 'warn_error': 'None', 'printer_width': '80', 'debug': 'False', 'cache_selected_only': 'False', 'profiles_dir': '/dbt', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'empty': 'None', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'no_print': 'None', 'log_format': 'default', 'log_path': '/dbt/logs'}
[0m18:47:16.026796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd982842d-2da3-4d3c-84f3-3ce53cc410a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9557cb2a50>]}
[0m18:47:16.102957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd982842d-2da3-4d3c-84f3-3ce53cc410a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9558490890>]}
[0m18:47:16.104832 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:47:16.181018 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:47:16.321510 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:47:16.322341 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:47:16.360690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd982842d-2da3-4d3c-84f3-3ce53cc410a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95579ec290>]}
[0m18:47:16.452306 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m18:47:16.455894 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m18:47:16.470826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd982842d-2da3-4d3c-84f3-3ce53cc410a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9557a55990>]}
[0m18:47:16.471668 [info ] [MainThread]: Found 8 models, 6 seeds, 485 macros
[0m18:47:16.472413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd982842d-2da3-4d3c-84f3-3ce53cc410a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955799d610>]}
[0m18:47:16.473956 [info ] [MainThread]: clickhouse_dbt_demo.marts.dim_customer
[0m18:47:16.474841 [info ] [MainThread]: clickhouse_dbt_demo.marts.dim_date
[0m18:47:16.475660 [info ] [MainThread]: clickhouse_dbt_demo.marts.dim_payment
[0m18:47:16.476523 [info ] [MainThread]: clickhouse_dbt_demo.marts.dim_product
[0m18:47:16.477397 [info ] [MainThread]: clickhouse_dbt_demo.marts.dim_store
[0m18:47:16.478349 [info ] [MainThread]: clickhouse_dbt_demo.marts.dim_supplier
[0m18:47:16.479627 [info ] [MainThread]: clickhouse_dbt_demo.marts.fact_sales
[0m18:47:16.480951 [info ] [MainThread]: clickhouse_dbt_demo.staging.stg_dim_customer
[0m18:47:16.481882 [info ] [MainThread]: clickhouse_dbt_demo.stg_dim_date
[0m18:47:16.482782 [info ] [MainThread]: clickhouse_dbt_demo.stg_dim_payment
[0m18:47:16.483627 [info ] [MainThread]: clickhouse_dbt_demo.stg_dim_product
[0m18:47:16.484654 [info ] [MainThread]: clickhouse_dbt_demo.stg_dim_store
[0m18:47:16.485610 [info ] [MainThread]: clickhouse_dbt_demo.stg_dim_supplier
[0m18:47:16.486591 [info ] [MainThread]: clickhouse_dbt_demo.stg_fact_sales
[0m18:47:16.488264 [debug] [MainThread]: Resource report: {"command_name": "list", "command_success": true, "command_wall_clock_time": 0.7168505, "process_in_blocks": "0", "process_kernel_time": 0.377527, "process_mem_max_rss": "110988", "process_out_blocks": "1096", "process_user_time": 2.049}
[0m18:47:16.489156 [debug] [MainThread]: Command `dbt ls` succeeded at 18:47:16.489032 after 0.72 seconds
[0m18:47:16.489849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955c9fb9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f955c8c8590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9557ef8f90>]}
[0m18:47:16.490589 [debug] [MainThread]: Flushing usage events
[0m18:47:17.074004 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:12:55.167592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d34871d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d346cd510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d346c18d0>]}


============================== 19:12:55.174809 | 3e4bde69-780c-45de-9772-f29736d70a7c ==============================
[0m19:12:55.174809 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:12:55.176882 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'quiet': 'False', 'introspect': 'True', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'write_json': 'True', 'static_parser': 'True', 'partial_parse': 'True', 'log_path': '/dbt/logs', 'use_colors': 'True', 'no_print': 'None', 'indirect_selection': 'eager', 'target_path': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'empty': 'False', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'profiles_dir': '/dbt', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m19:12:55.396063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3e4bde69-780c-45de-9772-f29736d70a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d344f4790>]}
[0m19:12:55.464138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3e4bde69-780c-45de-9772-f29736d70a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d34c44910>]}
[0m19:12:55.465685 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:12:55.552794 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:12:55.695364 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m19:12:55.696369 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://models/marts/cust_sales_detailed_summary.sql
[0m19:12:55.984742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e4bde69-780c-45de-9772-f29736d70a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d33f7d210>]}
[0m19:12:56.079219 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:12:56.083882 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:12:56.103458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e4bde69-780c-45de-9772-f29736d70a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d34118c10>]}
[0m19:12:56.104353 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:12:56.105213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e4bde69-780c-45de-9772-f29736d70a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d342c0810>]}
[0m19:12:56.108026 [info ] [MainThread]: 
[0m19:12:56.108970 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:12:56.111273 [info ] [MainThread]: 
[0m19:12:56.112803 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:12:56.116502 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:12:56.128589 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:12:56.336453 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:12:56.340872 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:12:56.373499 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m19:12:56.380391 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:12:56.395607 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:12:56.400550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e4bde69-780c-45de-9772-f29736d70a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d344a7bd0>]}
[0m19:12:56.405938 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:12:56.407545 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m19:12:56.408980 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m19:12:56.410363 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:12:56.426257 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:12:56.432304 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:12:56.526630 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    pay.PaymentKey,
    pay.PaymentMethod,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey
LEFT JOIN `default`.`dim_payment` AS pay
    ON f.PaymentKey = pay.PaymentKey



GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    pay.PaymentKey,
    pay.PaymentMethod
          )
        
        ...
[0m19:12:56.542846 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    pay.PaymentKey,
    pay.PaymentMethod,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey
LEFT JOIN `default`.`dim_payment` AS pay
    ON f.PaymentKey = pay.PaymentKey



GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    pay.PaymentKey,
    pay.PaymentMethod
          )
        
        
[0m19:12:56.550897 [debug] [Thread-1 (]: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'pay.PaymentKey' cannot be resolved from table with name pay. In scope SELECT c.CustomerKey, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, pay.PaymentKey, pay.PaymentMethod, count(f.SaleID) AS TotalOrders, sum(f.SalesAmount) AS TotalSales, max(f.FullDate) AS LastOrderDate FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey LEFT JOIN default.dim_payment AS pay ON f.PaymentKey = pay.PaymentKey GROUP BY c.CustomerKey, c.FirstName, c.LastName, c.City, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, pay.PaymentKey, pay.PaymentMethod. Maybe you meant: ['pay.ProductKey']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m19:12:56.553326 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e4bde69-780c-45de-9772-f29736d70a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d33e9add0>]}
[0m19:12:56.554576 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model `default`.`cust_sales_detailed_summary`  [[31mERROR[0m in 0.14s]
[0m19:12:56.556910 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:12:56.559634 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' to be skipped because of status 'error'.  Reason: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'pay.PaymentKey' cannot be resolved from table with name pay. In scope SELECT c.CustomerKey, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, pay.PaymentKey, pay.PaymentMethod, count(f.SaleID) AS TotalOrders, sum(f.SalesAmount) AS TotalSales, max(f.FullDate) AS LastOrderDate FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey LEFT JOIN default.dim_payment AS pay ON f.PaymentKey = pay.PaymentKey GROUP BY c.CustomerKey, c.FirstName, c.LastName, c.City, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, pay.PaymentKey, pay.PaymentMethod. Maybe you meant: ['pay.ProductKey']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m19:12:56.564433 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:12:56.566292 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m19:12:56.569292 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m19:12:56.570822 [info ] [MainThread]: 
[0m19:12:56.572635 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m19:12:56.576586 [debug] [MainThread]: Command end result
[0m19:12:56.639447 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:12:56.642823 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:12:56.654812 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:12:56.655663 [info ] [MainThread]: 
[0m19:12:56.656599 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:12:56.657497 [info ] [MainThread]: 
[0m19:12:56.659490 [error] [MainThread]: [31mFailure in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)[0m
[0m19:12:56.660826 [error] [MainThread]:   Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'pay.PaymentKey' cannot be resolved from table with name pay. In scope SELECT c.CustomerKey, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, pay.PaymentKey, pay.PaymentMethod, count(f.SaleID) AS TotalOrders, sum(f.SalesAmount) AS TotalSales, max(f.FullDate) AS LastOrderDate FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey LEFT JOIN default.dim_payment AS pay ON f.PaymentKey = pay.PaymentKey GROUP BY c.CustomerKey, c.FirstName, c.LastName, c.City, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, pay.PaymentKey, pay.PaymentMethod. Maybe you meant: ['pay.ProductKey']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m19:12:56.663032 [info ] [MainThread]: 
[0m19:12:56.667720 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:12:56.670782 [info ] [MainThread]: 
[0m19:12:56.673145 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m19:12:56.677859 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5787041, "process_in_blocks": "0", "process_kernel_time": 0.473096, "process_mem_max_rss": "123240", "process_out_blocks": "3280", "process_user_time": 2.729717}
[0m19:12:56.680603 [debug] [MainThread]: Command `dbt run` failed at 19:12:56.679894 after 1.58 seconds
[0m19:12:56.682068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d346c16d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d356b0fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d39028f50>]}
[0m19:12:56.684246 [debug] [MainThread]: Flushing usage events
[0m19:12:57.298962 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:13:58.893179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa85c5750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa85c5510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa8626ad0>]}


============================== 19:13:58.897599 | 7b233280-1d30-49d9-8acb-b75c66e2cff1 ==============================
[0m19:13:58.897599 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:13:58.899128 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'printer_width': '80', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'quiet': 'False', 'debug': 'False', 'log_path': '/dbt/logs', 'use_colors': 'True', 'warn_error': 'None', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'use_experimental_parser': 'False', 'empty': 'False', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'target_path': 'None', 'log_format': 'default', 'introspect': 'True', 'write_json': 'True', 'profiles_dir': '/dbt', 'static_parser': 'True'}
[0m19:13:59.125620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7b233280-1d30-49d9-8acb-b75c66e2cff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa83eee10>]}
[0m19:13:59.198294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7b233280-1d30-49d9-8acb-b75c66e2cff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa95abcd0>]}
[0m19:13:59.199983 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:13:59.288551 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:13:59.432182 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:13:59.434175 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/cust_sales_detailed_summary.sql
[0m19:13:59.767676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7b233280-1d30-49d9-8acb-b75c66e2cff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa7eda8d0>]}
[0m19:13:59.874682 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:13:59.879203 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:13:59.898243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7b233280-1d30-49d9-8acb-b75c66e2cff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa7ed8850>]}
[0m19:13:59.899183 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:13:59.899939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b233280-1d30-49d9-8acb-b75c66e2cff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa8239e90>]}
[0m19:13:59.902277 [info ] [MainThread]: 
[0m19:13:59.903438 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:13:59.905235 [info ] [MainThread]: 
[0m19:13:59.909595 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:13:59.912235 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:13:59.928660 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:14:00.087487 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:14:00.091541 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:14:00.113694 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m19:14:00.120913 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:14:00.128886 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:14:00.133044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b233280-1d30-49d9-8acb-b75c66e2cff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa7258c90>]}
[0m19:14:00.136957 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:14:00.138333 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m19:14:00.139398 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m19:14:00.140390 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:14:00.151972 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:14:00.155267 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:14:00.250590 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey



GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    pay.PaymentKey,
    pay.PaymentMethod
          )
        
        ...
[0m19:14:00.260286 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey



GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    pay.PaymentKey,
    pay.PaymentMethod
          )
        
        
[0m19:14:00.266707 [debug] [Thread-1 (]: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `pay.PaymentKey` in scope SELECT c.CustomerKey, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, count(f.SaleID) AS TotalOrders, sum(f.SalesAmount) AS TotalSales, max(f.FullDate) AS LastOrderDate FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey GROUP BY c.CustomerKey, c.FirstName, c.LastName, c.City, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, pay.PaymentKey, pay.PaymentMethod. Maybe you meant: ['f.PaymentKey']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m19:14:00.269693 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b233280-1d30-49d9-8acb-b75c66e2cff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa7ef9690>]}
[0m19:14:00.271377 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model `default`.`cust_sales_detailed_summary`  [[31mERROR[0m in 0.13s]
[0m19:14:00.272778 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:14:00.274352 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' to be skipped because of status 'error'.  Reason: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `pay.PaymentKey` in scope SELECT c.CustomerKey, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, count(f.SaleID) AS TotalOrders, sum(f.SalesAmount) AS TotalSales, max(f.FullDate) AS LastOrderDate FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey GROUP BY c.CustomerKey, c.FirstName, c.LastName, c.City, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, pay.PaymentKey, pay.PaymentMethod. Maybe you meant: ['f.PaymentKey']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m19:14:00.278943 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:14:00.280169 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m19:14:00.280927 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m19:14:00.281783 [info ] [MainThread]: 
[0m19:14:00.282690 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.37 seconds (0.37s).
[0m19:14:00.284507 [debug] [MainThread]: Command end result
[0m19:14:00.337320 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:14:00.342086 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:14:00.350223 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:14:00.350916 [info ] [MainThread]: 
[0m19:14:00.352131 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:14:00.353397 [info ] [MainThread]: 
[0m19:14:00.354574 [error] [MainThread]: [31mFailure in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)[0m
[0m19:14:00.356309 [error] [MainThread]:   Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `pay.PaymentKey` in scope SELECT c.CustomerKey, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, count(f.SaleID) AS TotalOrders, sum(f.SalesAmount) AS TotalSales, max(f.FullDate) AS LastOrderDate FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey GROUP BY c.CustomerKey, c.FirstName, c.LastName, c.City, p.ProductKey, p.ProductName, s.StoreKey, s.StoreName, pay.PaymentKey, pay.PaymentMethod. Maybe you meant: ['f.PaymentKey']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m19:14:00.359374 [info ] [MainThread]: 
[0m19:14:00.361549 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:14:00.362566 [info ] [MainThread]: 
[0m19:14:00.363652 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m19:14:00.365884 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5410682, "process_in_blocks": "0", "process_kernel_time": 0.330159, "process_mem_max_rss": "123436", "process_out_blocks": "3276", "process_user_time": 3.024257}
[0m19:14:00.366939 [debug] [MainThread]: Command `dbt run` failed at 19:14:00.366801 after 1.54 seconds
[0m19:14:00.367666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa8769dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aacf19490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7aa85c4410>]}
[0m19:14:00.368404 [debug] [MainThread]: Flushing usage events
[0m19:14:00.906273 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:14:55.338735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e645f810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e66c9790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e63fd4d0>]}


============================== 19:14:55.342859 | 9b6d59aa-7350-4304-80c3-c1abe9c8a3ef ==============================
[0m19:14:55.342859 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:14:55.344486 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'version_check': 'True', 'invocation_command': 'dbt run --select cust_sales_detailed_summar', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'use_colors': 'True', 'no_print': 'None', 'target_path': 'None', 'fail_fast': 'False', 'write_json': 'True', 'profiles_dir': '/dbt', 'log_path': '/dbt/logs', 'empty': 'False', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'log_format': 'default'}
[0m19:14:55.541021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9b6d59aa-7350-4304-80c3-c1abe9c8a3ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e645dfd0>]}
[0m19:14:55.609468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9b6d59aa-7350-4304-80c3-c1abe9c8a3ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e6988d90>]}
[0m19:14:55.611277 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:14:55.695879 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:14:55.824773 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:14:55.825961 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/cust_sales_detailed_summary.sql
[0m19:14:56.125128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b6d59aa-7350-4304-80c3-c1abe9c8a3ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e61d4910>]}
[0m19:14:56.225248 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:14:56.228706 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:14:56.250169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b6d59aa-7350-4304-80c3-c1abe9c8a3ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e5e33dd0>]}
[0m19:14:56.251266 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:14:56.252354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b6d59aa-7350-4304-80c3-c1abe9c8a3ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51e6248810>]}
[0m19:14:56.254425 [warn ] [MainThread]: The selection criterion 'cust_sales_detailed_summar' does not match any enabled nodes
[0m19:14:56.259770 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m19:14:56.262080 [debug] [MainThread]: Command end result
[0m19:14:56.378789 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:14:56.382137 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:14:56.386746 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:14:56.388194 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.1118844, "process_in_blocks": "0", "process_kernel_time": 0.237316, "process_mem_max_rss": "114232", "process_out_blocks": "3250", "process_user_time": 2.384319}
[0m19:14:56.389149 [debug] [MainThread]: Command `dbt run` succeeded at 19:14:56.388977 after 1.11 seconds
[0m19:14:56.390115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51ead58f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51ead58650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51ead58690>]}
[0m19:14:56.391093 [debug] [MainThread]: Flushing usage events
[0m19:14:56.974817 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:15:24.029303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc6b6cfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc6b6d150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc6b6d110>]}


============================== 19:15:24.033345 | 9881bc18-656e-4386-8710-74d1c12a0a0d ==============================
[0m19:15:24.033345 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:15:24.034691 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'target_path': 'None', 'empty': 'False', 'no_print': 'None', 'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'log_path': '/dbt/logs', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'profiles_dir': '/dbt', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'introspect': 'True', 'printer_width': '80', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'quiet': 'False'}
[0m19:15:24.236526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9881bc18-656e-4386-8710-74d1c12a0a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc6b6c490>]}
[0m19:15:24.306888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9881bc18-656e-4386-8710-74d1c12a0a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc729c9d0>]}
[0m19:15:24.308591 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:15:24.393568 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:15:24.519429 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:15:24.520259 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:15:24.560293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9881bc18-656e-4386-8710-74d1c12a0a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc682d190>]}
[0m19:15:24.657479 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:15:24.661065 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:15:24.678349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9881bc18-656e-4386-8710-74d1c12a0a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc68ed190>]}
[0m19:15:24.679297 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:15:24.680234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9881bc18-656e-4386-8710-74d1c12a0a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc6af1250>]}
[0m19:15:24.682974 [info ] [MainThread]: 
[0m19:15:24.684646 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:15:24.685810 [info ] [MainThread]: 
[0m19:15:24.688267 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:15:24.690056 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:15:24.705752 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:15:24.798439 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:15:24.802475 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:15:24.882136 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m19:15:24.889500 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:15:24.897224 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:15:24.901872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9881bc18-656e-4386-8710-74d1c12a0a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc5ab9790>]}
[0m19:15:24.906245 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:15:24.907657 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m19:15:24.908604 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m19:15:24.909801 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:15:24.926861 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:15:24.929350 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:15:25.023448 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey



GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
          )
        
        ...
[0m19:15:25.040730 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m19:15:25.063408 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:15:25.069585 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:15:25.075397 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:15:25.084299 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        
  
    
    
    
        
         


        insert into `default`.`cust_sales_detailed_summary`
        ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey



GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
  
    ...
[0m19:15:25.114952 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m19:15:25.139328 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9881bc18-656e-4386-8710-74d1c12a0a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc6bf1090>]}
[0m19:15:25.140790 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model `default`.`cust_sales_detailed_summary`  [[32mOK[0m in 0.23s]
[0m19:15:25.142119 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:15:25.145614 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:15:25.147922 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m19:15:25.149410 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m19:15:25.150707 [info ] [MainThread]: 
[0m19:15:25.152423 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m19:15:25.155004 [debug] [MainThread]: Command end result
[0m19:15:25.207507 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:15:25.211102 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:15:25.220595 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:15:25.221505 [info ] [MainThread]: 
[0m19:15:25.222476 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:15:25.223884 [info ] [MainThread]: 
[0m19:15:25.225391 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m19:15:25.227469 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.2613314, "process_in_blocks": "0", "process_kernel_time": 0.287087, "process_mem_max_rss": "120428", "process_out_blocks": "2205", "process_user_time": 2.442781}
[0m19:15:25.228475 [debug] [MainThread]: Command `dbt run` succeeded at 19:15:25.228332 after 1.26 seconds
[0m19:15:25.229205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc6eaa950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc6eb9f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc6eb9bd0>]}
[0m19:15:25.230127 [debug] [MainThread]: Flushing usage events
[0m19:15:25.772295 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:25:34.825936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71c60f1290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71c62a9790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71c6109e50>]}


============================== 19:25:34.830170 | d00a9b71-4a91-4c09-bf50-84437741d4e3 ==============================
[0m19:25:34.830170 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:25:34.831531 [debug] [MainThread]: running dbt with arguments {'log_path': '/dbt/logs', 'profiles_dir': '/dbt', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'debug': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'invocation_command': 'dbt snapshot --select fact_sales_snapshot', 'version_check': 'True', 'static_parser': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'write_json': 'True', 'quiet': 'False', 'introspect': 'True', 'use_colors': 'True', 'fail_fast': 'False'}
[0m19:25:35.023999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd00a9b71-4a91-4c09-bf50-84437741d4e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71c5ea2190>]}
[0m19:25:35.091872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd00a9b71-4a91-4c09-bf50-84437741d4e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71c668c9d0>]}
[0m19:25:35.093401 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:25:35.169417 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:25:35.303107 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m19:25:35.304251 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://models/marts/fact_sales_snapshot.sql
[0m19:25:35.567155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd00a9b71-4a91-4c09-bf50-84437741d4e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71c5f14450>]}
[0m19:25:35.657274 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:25:35.660891 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:25:35.678144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd00a9b71-4a91-4c09-bf50-84437741d4e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71c5b2dc90>]}
[0m19:25:35.679082 [info ] [MainThread]: Found 10 models, 6 seeds, 485 macros
[0m19:25:35.679909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd00a9b71-4a91-4c09-bf50-84437741d4e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71c5edee90>]}
[0m19:25:35.681990 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m19:25:35.683080 [debug] [MainThread]: Command end result
[0m19:25:35.795082 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:25:35.798474 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:25:35.803120 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:25:35.804460 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 1.0413194, "process_in_blocks": "0", "process_kernel_time": 0.293856, "process_mem_max_rss": "114760", "process_out_blocks": "3267", "process_user_time": 2.335598}
[0m19:25:35.805344 [debug] [MainThread]: Command `dbt snapshot` succeeded at 19:25:35.805182 after 1.04 seconds
[0m19:25:35.806064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71caa490d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71caa48650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71c73f8b10>]}
[0m19:25:35.806779 [debug] [MainThread]: Flushing usage events
[0m19:25:36.380336 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:26:15.688194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13b8a0b8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13bb88df90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13b8873e10>]}


============================== 19:26:15.692366 | b6a71af0-154b-4db5-a373-af1827a703f1 ==============================
[0m19:26:15.692366 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:26:15.694054 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'partial_parse': 'True', 'write_json': 'True', 'introspect': 'True', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'log_path': '/dbt/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'version_check': 'True', 'empty': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt snapshot --select fact_sales_snapshot', 'printer_width': '80', 'indirect_selection': 'eager', 'profiles_dir': '/dbt', 'no_print': 'None', 'log_format': 'default', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'static_parser': 'True', 'quiet': 'False', 'send_anonymous_usage_stats': 'True'}
[0m19:26:15.886731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b6a71af0-154b-4db5-a373-af1827a703f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13b8a1c490>]}
[0m19:26:15.957443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b6a71af0-154b-4db5-a373-af1827a703f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13b8fa0a10>]}
[0m19:26:15.959190 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:26:16.042289 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:26:16.167892 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:26:16.168776 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:26:16.205063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b6a71af0-154b-4db5-a373-af1827a703f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13b85402d0>]}
[0m19:26:16.299516 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:26:16.303203 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:26:16.319879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b6a71af0-154b-4db5-a373-af1827a703f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13b8814e50>]}
[0m19:26:16.320941 [info ] [MainThread]: Found 10 models, 6 seeds, 485 macros
[0m19:26:16.321807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b6a71af0-154b-4db5-a373-af1827a703f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13b86dae90>]}
[0m19:26:16.324257 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m19:26:16.329601 [debug] [MainThread]: Command end result
[0m19:26:16.379386 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:26:16.384953 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:26:16.391382 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:26:16.393328 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 0.7670949, "process_in_blocks": "0", "process_kernel_time": 0.231548, "process_mem_max_rss": "111688", "process_out_blocks": "2198", "process_user_time": 2.062702}
[0m19:26:16.394601 [debug] [MainThread]: Command `dbt snapshot` succeeded at 19:26:16.394413 after 0.77 seconds
[0m19:26:16.395434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13bd3d91d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13bd3d8750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13bd3d9710>]}
[0m19:26:16.396232 [debug] [MainThread]: Flushing usage events
[0m19:26:16.933953 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:27:00.757815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe97ca30350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe97cb16250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe97ca3fc90>]}


============================== 19:27:00.761943 | 1fead3cc-234a-4d10-8872-289f56eac927 ==============================
[0m19:27:00.761943 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:27:00.763171 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt snapshot --select fact_sales_snapshot', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'debug': 'False', 'profiles_dir': '/dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'target_path': 'None', 'fail_fast': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'log_path': '/dbt/logs', 'use_colors': 'True', 'indirect_selection': 'eager', 'introspect': 'True', 'quiet': 'False', 'static_parser': 'True', 'warn_error': 'None', 'log_cache_events': 'False', 'log_format': 'default', 'partial_parse': 'True', 'cache_selected_only': 'False', 'no_print': 'None'}
[0m19:27:00.956948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1fead3cc-234a-4d10-8872-289f56eac927', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe97c84c490>]}
[0m19:27:01.027284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1fead3cc-234a-4d10-8872-289f56eac927', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe97d9d7ad0>]}
[0m19:27:01.028738 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:27:01.104674 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:27:01.271822 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:27:01.273018 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/fact_sales_snapshot.sql
[0m19:27:01.495904 [error] [MainThread]: Encountered an error:
Compilation Error in model fact_sales_snapshot (models/marts/fact_sales_snapshot.sql)
  Encountered unknown tag 'snapshot'.
    line 1
      {% snapshot fact_sales_snapshot %}
[0m19:27:01.497975 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": false, "command_wall_clock_time": 0.80182916, "process_in_blocks": "0", "process_kernel_time": 0.305996, "process_mem_max_rss": "112704", "process_out_blocks": "5", "process_user_time": 2.38839}
[0m19:27:01.499066 [debug] [MainThread]: Command `dbt snapshot` failed at 19:27:01.498871 after 0.80 seconds
[0m19:27:01.499854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe97c9f2b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9814e5610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe97c442110>]}
[0m19:27:01.500853 [debug] [MainThread]: Flushing usage events
[0m19:27:02.047059 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:30:34.059048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f237fd0c8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f237fb6d010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f237fe324d0>]}


============================== 19:30:34.063286 | be06adc7-2cac-4b01-874a-3fbeae796fe9 ==============================
[0m19:30:34.063286 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:30:34.064999 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'no_print': 'None', 'introspect': 'True', 'quiet': 'False', 'static_parser': 'True', 'printer_width': '80', 'log_format': 'default', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'log_path': '/dbt/logs', 'target_path': 'None', 'profiles_dir': '/dbt', 'fail_fast': 'False', 'log_cache_events': 'False', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'debug': 'False', 'empty': 'False', 'invocation_command': 'dbt snapshot', 'cache_selected_only': 'False'}
[0m19:30:34.277235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be06adc7-2cac-4b01-874a-3fbeae796fe9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f237fd48e90>]}
[0m19:30:34.350072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be06adc7-2cac-4b01-874a-3fbeae796fe9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f238029c890>]}
[0m19:30:34.351899 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:30:34.441728 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:30:34.580311 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:30:34.581941 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/fact_sales_snapshot.sql
[0m19:30:34.800908 [error] [MainThread]: Encountered an error:
Compilation Error in model fact_sales_snapshot (models/marts/fact_sales_snapshot.sql)
  Encountered unknown tag 'snapshot'.
    line 1
      {% snapshot fact_sales_snapshot %}
[0m19:30:34.803381 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": false, "command_wall_clock_time": 0.8138791, "process_in_blocks": "0", "process_kernel_time": 0.271493, "process_mem_max_rss": "112696", "process_out_blocks": "4", "process_user_time": 2.176974}
[0m19:30:34.805056 [debug] [MainThread]: Command `dbt snapshot` failed at 19:30:34.804764 after 0.82 seconds
[0m19:30:34.807113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f237fd48290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f237fd48c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f237f5c7290>]}
[0m19:30:34.808918 [debug] [MainThread]: Flushing usage events
[0m19:30:35.420679 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:33:47.399648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff67cf1350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff67cf18d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff67cf1610>]}


============================== 19:33:47.403977 | 4640b9dd-d86e-4088-9e14-e23b266ec29b ==============================
[0m19:33:47.403977 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:33:47.405111 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'target_path': 'None', 'no_print': 'None', 'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'static_parser': 'True', 'warn_error': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'write_json': 'True', 'introspect': 'True', 'use_experimental_parser': 'False', 'use_colors': 'True', 'fail_fast': 'False', 'indirect_selection': 'eager', 'version_check': 'True', 'debug': 'False', 'profiles_dir': '/dbt', 'log_path': '/dbt/logs', 'partial_parse': 'True', 'quiet': 'False'}
[0m19:33:47.596464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4640b9dd-d86e-4088-9e14-e23b266ec29b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff67cf04d0>]}
[0m19:33:47.664112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4640b9dd-d86e-4088-9e14-e23b266ec29b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff68280cd0>]}
[0m19:33:47.665936 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:33:47.749624 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:33:47.882869 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m19:33:47.883992 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/cust_sales_detailed_summary.sql
[0m19:33:47.884746 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/fact_sales_snapshot.sql
[0m19:33:48.105741 [error] [MainThread]: Encountered an error:
Compilation Error in model fact_sales_snapshot (models/marts/fact_sales_snapshot.sql)
  Encountered unknown tag 'snapshot'.
    line 1
      {% snapshot fact_sales_snapshot %}
[0m19:33:48.108139 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.7746179, "process_in_blocks": "0", "process_kernel_time": 0.244343, "process_mem_max_rss": "113004", "process_out_blocks": "5", "process_user_time": 2.145797}
[0m19:33:48.109804 [debug] [MainThread]: Command `dbt run` failed at 19:33:48.109370 after 0.78 seconds
[0m19:33:48.111295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff6c7d5610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff67b3a510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff67924d50>]}
[0m19:33:48.112473 [debug] [MainThread]: Flushing usage events
[0m19:33:48.731872 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:34:13.092777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57ac3c8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57adad550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57ac3cc50>]}


============================== 19:34:13.097577 | ad0762e3-8c4b-43d3-bf6d-0943de28c32c ==============================
[0m19:34:13.097577 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:34:13.099376 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'introspect': 'True', 'empty': 'False', 'version_check': 'True', 'printer_width': '80', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'no_print': 'None', 'log_cache_events': 'False', 'log_path': '/dbt/logs', 'indirect_selection': 'eager', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'log_format': 'default', 'profiles_dir': '/dbt', 'use_experimental_parser': 'False', 'static_parser': 'True', 'target_path': 'None', 'cache_selected_only': 'False', 'use_colors': 'True', 'debug': 'False'}
[0m19:34:13.314051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ad0762e3-8c4b-43d3-bf6d-0943de28c32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57aaa3910>]}
[0m19:34:13.383623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ad0762e3-8c4b-43d3-bf6d-0943de28c32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57bbe3b10>]}
[0m19:34:13.385196 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:34:13.473549 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:34:13.619666 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 1 files changed.
[0m19:34:13.620660 [debug] [MainThread]: Partial parsing: deleted file: clickhouse_dbt_demo://models/marts/fact_sales_snapshot.sql
[0m19:34:13.621493 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/cust_sales_detailed_summary.sql
[0m19:34:13.935892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ad0762e3-8c4b-43d3-bf6d-0943de28c32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57c9d0a90>]}
[0m19:34:14.029873 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:34:14.033357 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:34:14.050644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ad0762e3-8c4b-43d3-bf6d-0943de28c32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57a8c5d90>]}
[0m19:34:14.051690 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:34:14.052743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad0762e3-8c4b-43d3-bf6d-0943de28c32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57b2062d0>]}
[0m19:34:14.055112 [info ] [MainThread]: 
[0m19:34:14.056080 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:34:14.057276 [info ] [MainThread]: 
[0m19:34:14.059377 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:34:14.062262 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:34:14.074543 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:34:14.301169 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:34:14.305548 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:34:14.334515 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m19:34:14.341679 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:34:14.352851 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:34:14.358182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad0762e3-8c4b-43d3-bf6d-0943de28c32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57a148f10>]}
[0m19:34:14.362429 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:34:14.363658 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m19:34:14.365028 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m19:34:14.366315 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:34:14.378253 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:34:14.383232 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:34:14.459754 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_new_data` 
  ...
[0m19:34:14.463464 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:34:14.505316 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey

GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
          )
        
        ...
[0m19:34:14.519273 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:34:14.541266 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary__dbt_new_data'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:34:14.547706 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:34:14.552414 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        
  
    
    
    
        
         


        insert into `default`.`cust_sales_detailed_summary__dbt_new_data`
        ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey

GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
  
      ...
[0m19:34:14.572134 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m19:34:14.573816 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:34:14.577031 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

          create table `default`.`cust_sales_detailed_summary__dbt_tmp` 
   as `default`.`cust_sales_detailed_summary__dbt_new_data`
      ...
[0m19:34:14.586807 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:34:14.590420 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:34:14.595548 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:34:14.597903 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    ...
[0m19:34:14.603242 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    
[0m19:34:14.608793 [debug] [Thread-1 (]: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:34:14.611215 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad0762e3-8c4b-43d3-bf6d-0943de28c32c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57ac3e890>]}
[0m19:34:14.612491 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model `default`.`cust_sales_detailed_summary`  [[31mERROR[0m in 0.25s]
[0m19:34:14.613682 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:34:14.614754 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' to be skipped because of status 'error'.  Reason: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql.
[0m19:34:14.619434 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:34:14.620507 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m19:34:14.621535 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m19:34:14.622527 [info ] [MainThread]: 
[0m19:34:14.623390 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m19:34:14.625294 [debug] [MainThread]: Command end result
[0m19:34:14.677274 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:34:14.681637 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:34:14.690036 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:34:14.690781 [info ] [MainThread]: 
[0m19:34:14.691845 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:34:14.693187 [info ] [MainThread]: 
[0m19:34:14.695338 [error] [MainThread]: [31mFailure in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)[0m
[0m19:34:14.698414 [error] [MainThread]:   Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:34:14.699880 [info ] [MainThread]: 
[0m19:34:14.701803 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:34:14.703090 [info ] [MainThread]: 
[0m19:34:14.705029 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m19:34:14.707014 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6772008, "process_in_blocks": "0", "process_kernel_time": 0.31969, "process_mem_max_rss": "123632", "process_out_blocks": "3281", "process_user_time": 2.7046}
[0m19:34:14.708247 [debug] [MainThread]: Command `dbt run` failed at 19:34:14.708074 after 1.68 seconds
[0m19:34:14.709025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57aa86910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57911bad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff57f539490>]}
[0m19:34:14.709792 [debug] [MainThread]: Flushing usage events
[0m19:34:15.256626 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:34:38.361397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29795e0b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29795d9090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f297a452610>]}


============================== 19:34:38.366503 | 17605f39-e6e3-4061-852a-f8f0adaefda1 ==============================
[0m19:34:38.366503 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:34:38.367845 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'static_parser': 'True', 'use_colors': 'True', 'warn_error': 'None', 'quiet': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'introspect': 'True', 'indirect_selection': 'eager', 'fail_fast': 'False', 'profiles_dir': '/dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'cache_selected_only': 'False', 'write_json': 'True', 'no_print': 'None', 'version_check': 'True', 'empty': 'False', 'printer_width': '80', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'log_path': '/dbt/logs', 'target_path': 'None', 'debug': 'False'}
[0m19:34:38.604666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '17605f39-e6e3-4061-852a-f8f0adaefda1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2979bc9e10>]}
[0m19:34:38.701085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '17605f39-e6e3-4061-852a-f8f0adaefda1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2979b74a10>]}
[0m19:34:38.702482 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:34:38.799783 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:34:38.951773 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:34:38.952954 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/cust_sales_detailed_summary.sql
[0m19:34:39.254939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '17605f39-e6e3-4061-852a-f8f0adaefda1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2978ee3690>]}
[0m19:34:39.350841 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:34:39.356044 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:34:39.376011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '17605f39-e6e3-4061-852a-f8f0adaefda1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2978f22ad0>]}
[0m19:34:39.377185 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:34:39.378238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17605f39-e6e3-4061-852a-f8f0adaefda1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2978fbbf50>]}
[0m19:34:39.381247 [info ] [MainThread]: 
[0m19:34:39.382324 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:34:39.383868 [info ] [MainThread]: 
[0m19:34:39.386278 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:34:39.388377 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:34:39.404355 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:34:39.582216 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:34:39.587525 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:34:39.615210 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m19:34:39.621802 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:34:39.629564 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:34:39.635851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17605f39-e6e3-4061-852a-f8f0adaefda1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2979251250>]}
[0m19:34:39.640566 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:34:39.641677 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m19:34:39.643149 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m19:34:39.644509 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:34:39.664800 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:34:39.667907 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:34:39.736435 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_tmp` 
  ...
[0m19:34:39.740568 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:34:39.762829 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_new_data` 
  ...
[0m19:34:39.767474 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:34:39.812309 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey


  -- Only include new sales since the last run
  WHERE f.FullDate > (SELECT MAX(LastOrderDate) FROM `default`.`cust_sales_detailed_summary`)


GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
          )
        
        ...
[0m19:34:39.828984 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m19:34:39.855410 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary__dbt_new_data'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:34:39.861736 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:34:39.866347 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        
  
    
    
    
        
         


        insert into `default`.`cust_sales_detailed_summary__dbt_new_data`
        ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey


  -- Only include new sales since the last run
  WHERE f.FullDate > (SELECT MAX(LastOrderDate) FROM `default`.`cust_sales_detailed_summary`)


GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
  
      ...
[0m19:34:39.884630 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m19:34:39.888754 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:34:39.895325 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

          create table `default`.`cust_sales_detailed_summary__dbt_tmp` 
   as `default`.`cust_sales_detailed_summary__dbt_new_data`
      ...
[0m19:34:39.911867 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m19:34:39.916678 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:34:39.923249 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:34:39.926246 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    ...
[0m19:34:39.933673 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    
[0m19:34:39.939503 [debug] [Thread-1 (]: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:34:39.941944 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17605f39-e6e3-4061-852a-f8f0adaefda1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2978d93450>]}
[0m19:34:39.943763 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model `default`.`cust_sales_detailed_summary`  [[31mERROR[0m in 0.30s]
[0m19:34:39.945629 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:34:39.947510 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' to be skipped because of status 'error'.  Reason: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql.
[0m19:34:39.953884 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:34:39.955159 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m19:34:39.956235 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m19:34:39.957787 [info ] [MainThread]: 
[0m19:34:39.959528 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.57 seconds (0.57s).
[0m19:34:39.964529 [debug] [MainThread]: Command end result
[0m19:34:40.042435 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:34:40.047075 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:34:40.056451 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:34:40.057709 [info ] [MainThread]: 
[0m19:34:40.059265 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:34:40.061077 [info ] [MainThread]: 
[0m19:34:40.062219 [error] [MainThread]: [31mFailure in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)[0m
[0m19:34:40.063610 [error] [MainThread]:   Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:34:40.064923 [info ] [MainThread]: 
[0m19:34:40.066567 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:34:40.067740 [info ] [MainThread]: 
[0m19:34:40.068824 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m19:34:40.071001 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.7765778, "process_in_blocks": "0", "process_kernel_time": 0.294642, "process_mem_max_rss": "123532", "process_out_blocks": "3285", "process_user_time": 2.818411}
[0m19:34:40.072029 [debug] [MainThread]: Command `dbt run` failed at 19:34:40.071798 after 1.78 seconds
[0m19:34:40.072768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f297df75510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f297df74710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29795e2ad0>]}
[0m19:34:40.073429 [debug] [MainThread]: Flushing usage events
[0m19:34:40.594671 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:35:50.025250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e0348750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e02e9610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e0320f90>]}


============================== 19:35:50.029608 | de2539a7-e106-4c3f-bb30-192a9677d349 ==============================
[0m19:35:50.029608 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:35:50.031159 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'no_print': 'None', 'debug': 'False', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'empty': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'log_format': 'default', 'log_path': '/dbt/logs', 'log_cache_events': 'False', 'warn_error': 'None', 'printer_width': '80', 'quiet': 'False', 'target_path': 'None', 'profiles_dir': '/dbt', 'introspect': 'True', 'version_check': 'True', 'static_parser': 'True'}
[0m19:35:50.234266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de2539a7-e106-4c3f-bb30-192a9677d349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e0092f50>]}
[0m19:35:50.301635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'de2539a7-e106-4c3f-bb30-192a9677d349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e08789d0>]}
[0m19:35:50.303582 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:35:50.384201 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:35:50.515413 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:35:50.516316 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:35:50.555141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'de2539a7-e106-4c3f-bb30-192a9677d349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58dfe16990>]}
[0m19:35:50.647853 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:35:50.651298 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:35:50.667109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'de2539a7-e106-4c3f-bb30-192a9677d349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e00c9cd0>]}
[0m19:35:50.668094 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:35:50.668839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de2539a7-e106-4c3f-bb30-192a9677d349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58dfcf3d90>]}
[0m19:35:50.671661 [info ] [MainThread]: 
[0m19:35:50.673304 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:35:50.676076 [info ] [MainThread]: 
[0m19:35:50.678214 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:35:50.680242 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:35:50.697290 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:35:50.788446 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:35:50.792830 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:35:50.876333 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m19:35:50.883463 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:35:50.891866 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:35:50.897704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de2539a7-e106-4c3f-bb30-192a9677d349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e0136410>]}
[0m19:35:50.902263 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:35:50.903378 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m19:35:50.904597 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m19:35:50.905704 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:35:50.927249 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:35:50.930932 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:35:50.984944 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_tmp` 
  ...
[0m19:35:50.989184 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:35:51.009392 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_new_data` 
  ...
[0m19:35:51.013443 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:35:51.055468 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey


  -- Only include new sales since the last run
  WHERE f.FullDate > (SELECT MAX(LastOrderDate) FROM `default`.`cust_sales_detailed_summary`)


GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
          )
        
        ...
[0m19:35:51.071441 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:35:51.096359 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary__dbt_new_data'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:35:51.102667 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:35:51.107697 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        
  
    
    
    
        
         


        insert into `default`.`cust_sales_detailed_summary__dbt_new_data`
        ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey


  -- Only include new sales since the last run
  WHERE f.FullDate > (SELECT MAX(LastOrderDate) FROM `default`.`cust_sales_detailed_summary`)


GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
  
      ...
[0m19:35:51.192253 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m19:35:51.194554 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:35:51.198348 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

          create table `default`.`cust_sales_detailed_summary__dbt_tmp` 
   as `default`.`cust_sales_detailed_summary__dbt_new_data`
      ...
[0m19:35:51.207435 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:35:51.211300 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:35:51.216662 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:35:51.218814 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    ...
[0m19:35:51.223334 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    
[0m19:35:51.227943 [debug] [Thread-1 (]: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:35:51.229881 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de2539a7-e106-4c3f-bb30-192a9677d349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e0862f10>]}
[0m19:35:51.230958 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model `default`.`cust_sales_detailed_summary`  [[31mERROR[0m in 0.32s]
[0m19:35:51.232373 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:35:51.233706 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' to be skipped because of status 'error'.  Reason: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql.
[0m19:35:51.238759 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:35:51.239849 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m19:35:51.240561 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m19:35:51.241376 [info ] [MainThread]: 
[0m19:35:51.242386 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m19:35:51.244067 [debug] [MainThread]: Command end result
[0m19:35:51.296291 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:35:51.302977 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:35:51.312174 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:35:51.313044 [info ] [MainThread]: 
[0m19:35:51.314264 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:35:51.315576 [info ] [MainThread]: 
[0m19:35:51.317237 [error] [MainThread]: [31mFailure in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)[0m
[0m19:35:51.319988 [error] [MainThread]:   Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:35:51.321333 [info ] [MainThread]: 
[0m19:35:51.323368 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:35:51.324486 [info ] [MainThread]: 
[0m19:35:51.325625 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m19:35:51.327805 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.3651423, "process_in_blocks": "0", "process_kernel_time": 0.293186, "process_mem_max_rss": "121020", "process_out_blocks": "2220", "process_user_time": 2.431002}
[0m19:35:51.328793 [debug] [MainThread]: Command `dbt run` failed at 19:35:51.328664 after 1.37 seconds
[0m19:35:51.329514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e4ca91d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e02eab10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e02ead50>]}
[0m19:35:51.330482 [debug] [MainThread]: Flushing usage events
[0m19:35:51.924923 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:39:04.703467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f586a1361d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f586a04cb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f586a010350>]}


============================== 19:39:04.709149 | 971d8b53-b425-4662-bc80-a0e28b3eb99c ==============================
[0m19:39:04.709149 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:39:04.711120 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'log_format': 'default', 'introspect': 'True', 'log_path': '/dbt/logs', 'log_cache_events': 'False', 'fail_fast': 'False', 'printer_width': '80', 'static_parser': 'True', 'partial_parse': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'warn_error': 'None', 'no_print': 'None', 'target_path': 'None', 'debug': 'False', 'write_json': 'True', 'quiet': 'False', 'profiles_dir': '/dbt', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'version_check': 'True'}
[0m19:39:04.910324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '971d8b53-b425-4662-bc80-a0e28b3eb99c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f586a012b50>]}
[0m19:39:04.978592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '971d8b53-b425-4662-bc80-a0e28b3eb99c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f586a5a09d0>]}
[0m19:39:04.980182 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:39:05.071894 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:39:05.221449 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:39:05.222860 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/cust_sales_detailed_summary.sql
[0m19:39:05.502013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '971d8b53-b425-4662-bc80-a0e28b3eb99c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5869c6e010>]}
[0m19:39:05.592701 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:39:05.596928 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:39:05.618031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '971d8b53-b425-4662-bc80-a0e28b3eb99c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5869a40350>]}
[0m19:39:05.619017 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:39:05.619979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '971d8b53-b425-4662-bc80-a0e28b3eb99c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f586bc6bf50>]}
[0m19:39:05.623285 [info ] [MainThread]: 
[0m19:39:05.624614 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:39:05.625902 [info ] [MainThread]: 
[0m19:39:05.627345 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:39:05.630833 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:39:05.642363 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:39:05.798880 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:39:05.803008 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:39:05.825735 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m19:39:05.833271 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:39:05.841121 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:39:05.847024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '971d8b53-b425-4662-bc80-a0e28b3eb99c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5869c45a50>]}
[0m19:39:05.852258 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:39:05.853843 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m19:39:05.855171 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m19:39:05.856643 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:39:05.873378 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:39:05.876869 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:39:05.944807 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_tmp` 
  ...
[0m19:39:05.949092 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:39:05.970648 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_new_data` 
  ...
[0m19:39:05.974398 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:39:06.018724 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

-- Pre-aggregate only new sales
WITH new_sales AS (
    SELECT *
    FROM `default`.`fact_sales`
    
      WHERE FullDate > (SELECT COALESCE(MAX(LastOrderDate), '1970-01-01') FROM `default`.`cust_sales_detailed_summary`)
    
)

SELECT
    c.CustomerKey AS CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey AS ProductKey,
    p.ProductName,
    s.StoreKey AS StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM new_sales AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey
GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
          )
        
        ...
[0m19:39:06.040464 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m19:39:06.065656 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary__dbt_new_data'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:39:06.072599 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:39:06.077078 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        
  
    
    
    
        
         


        insert into `default`.`cust_sales_detailed_summary__dbt_new_data`
        ("CustomerKey", "FirstName", "LastName", "CustomerCity", "ProductKey", "ProductName", "StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")

-- Pre-aggregate only new sales
WITH new_sales AS (
    SELECT *
    FROM `default`.`fact_sales`
    
      WHERE FullDate > (SELECT COALESCE(MAX(LastOrderDate), '1970-01-01') FROM `default`.`cust_sales_detailed_summary`)
    
)

SELECT
    c.CustomerKey AS CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey AS ProductKey,
    p.ProductName,
    s.StoreKey AS StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM new_sales AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey
GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
  
      ...
[0m19:39:06.096550 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m19:39:06.098394 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:39:06.101815 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

          create table `default`.`cust_sales_detailed_summary__dbt_tmp` 
   as `default`.`cust_sales_detailed_summary__dbt_new_data`
      ...
[0m19:39:06.113153 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:39:06.116258 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:39:06.121711 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:39:06.124077 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    ...
[0m19:39:06.130855 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    
[0m19:39:06.136316 [debug] [Thread-1 (]: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 16, server response: Code: 16. DB::Exception: No such column c.CustomerKey in table default.cust_sales_detailed_summary__dbt_tmp (c07bcbd8-cbd3-4029-8739-641b8dd58360). (NO_SUCH_COLUMN_IN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:39:06.138674 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971d8b53-b425-4662-bc80-a0e28b3eb99c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5869db9910>]}
[0m19:39:06.140052 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model `default`.`cust_sales_detailed_summary`  [[31mERROR[0m in 0.28s]
[0m19:39:06.141907 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:39:06.143656 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' to be skipped because of status 'error'.  Reason: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 16, server response: Code: 16. DB::Exception: No such column c.CustomerKey in table default.cust_sales_detailed_summary__dbt_tmp (c07bcbd8-cbd3-4029-8739-641b8dd58360). (NO_SUCH_COLUMN_IN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql.
[0m19:39:06.149086 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:39:06.150297 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m19:39:06.151221 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m19:39:06.152286 [info ] [MainThread]: 
[0m19:39:06.153247 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.53 seconds (0.53s).
[0m19:39:06.154865 [debug] [MainThread]: Command end result
[0m19:39:06.211215 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:39:06.214866 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:39:06.222863 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:39:06.223514 [info ] [MainThread]: 
[0m19:39:06.224338 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:39:06.225836 [info ] [MainThread]: 
[0m19:39:06.226836 [error] [MainThread]: [31mFailure in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)[0m
[0m19:39:06.228100 [error] [MainThread]:   Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 16, server response: Code: 16. DB::Exception: No such column c.CustomerKey in table default.cust_sales_detailed_summary__dbt_tmp (c07bcbd8-cbd3-4029-8739-641b8dd58360). (NO_SUCH_COLUMN_IN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:39:06.229150 [info ] [MainThread]: 
[0m19:39:06.230730 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:39:06.232287 [info ] [MainThread]: 
[0m19:39:06.234337 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m19:39:06.236837 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.600391, "process_in_blocks": "0", "process_kernel_time": 0.294929, "process_mem_max_rss": "123512", "process_out_blocks": "3285", "process_user_time": 2.708451}
[0m19:39:06.238072 [debug] [MainThread]: Command `dbt run` failed at 19:39:06.237905 after 1.60 seconds
[0m19:39:06.238882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f586a012850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f586a04c2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f586e998790>]}
[0m19:39:06.239664 [debug] [MainThread]: Flushing usage events
[0m19:39:06.836170 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:40:33.117444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa22736d090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa22823cb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa227544dd0>]}


============================== 19:40:33.121628 | 6543171e-9d30-47ef-b8e3-0736b78d8d1a ==============================
[0m19:40:33.121628 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:40:33.123145 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'log_cache_events': 'False', 'version_check': 'True', 'use_colors': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'empty': 'False', 'debug': 'False', 'write_json': 'True', 'cache_selected_only': 'False', 'log_path': '/dbt/logs', 'log_format': 'default', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'profiles_dir': '/dbt', 'quiet': 'False', 'partial_parse': 'True', 'introspect': 'True'}
[0m19:40:33.325002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6543171e-9d30-47ef-b8e3-0736b78d8d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa22838eb90>]}
[0m19:40:33.392937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6543171e-9d30-47ef-b8e3-0736b78d8d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa227a989d0>]}
[0m19:40:33.394490 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:40:33.479324 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:40:33.608233 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:40:33.609376 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/cust_sales_detailed_summary.sql
[0m19:40:33.892544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6543171e-9d30-47ef-b8e3-0736b78d8d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa226f3d8d0>]}
[0m19:40:33.986504 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:40:33.989979 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:40:34.007832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6543171e-9d30-47ef-b8e3-0736b78d8d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa226c8f490>]}
[0m19:40:34.008855 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:40:34.009681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6543171e-9d30-47ef-b8e3-0736b78d8d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa22715c0d0>]}
[0m19:40:34.012468 [info ] [MainThread]: 
[0m19:40:34.014135 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:40:34.016704 [info ] [MainThread]: 
[0m19:40:34.018727 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:40:34.021006 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:40:34.034315 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:40:34.185083 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:40:34.189276 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:40:34.210679 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m19:40:34.219014 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:40:34.227448 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:40:34.232250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6543171e-9d30-47ef-b8e3-0736b78d8d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa226158310>]}
[0m19:40:34.239100 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:40:34.240590 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m19:40:34.241864 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m19:40:34.243013 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:40:34.259278 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:40:34.262177 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:40:34.321701 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_tmp` 
  ...
[0m19:40:34.325530 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:40:34.345693 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_new_data` 
  ...
[0m19:40:34.349632 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:40:34.392720 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

WITH new_sales AS (
    SELECT *
    FROM `default`.`fact_sales`
    
      WHERE FullDate > (SELECT COALESCE(MAX(LastOrderDate), '1970-01-01') FROM `default`.`cust_sales_detailed_summary`)
    
)

SELECT
    CustomerKey,
    FirstName,
    LastName,
    City AS CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName,
    COUNT(SaleID) AS TotalOrders,
    SUM(SalesAmount) AS TotalSales,
    MAX(FullDate) AS LastOrderDate
FROM new_sales
GROUP BY
    CustomerKey,
    FirstName,
    LastName,
    CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName
          )
        
        ...
[0m19:40:34.402632 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

WITH new_sales AS (
    SELECT *
    FROM `default`.`fact_sales`
    
      WHERE FullDate > (SELECT COALESCE(MAX(LastOrderDate), '1970-01-01') FROM `default`.`cust_sales_detailed_summary`)
    
)

SELECT
    CustomerKey,
    FirstName,
    LastName,
    City AS CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName,
    COUNT(SaleID) AS TotalOrders,
    SUM(SalesAmount) AS TotalSales,
    MAX(FullDate) AS LastOrderDate
FROM new_sales
GROUP BY
    CustomerKey,
    FirstName,
    LastName,
    CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName
          )
        
        
[0m19:40:34.410219 [debug] [Thread-1 (]: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `FirstName` in scope WITH new_sales AS (SELECT * FROM default.fact_sales WHERE FullDate > (SELECT coalesce(max(LastOrderDate), '1970-01-01') FROM default.cust_sales_detailed_summary)) SELECT CustomerKey, FirstName, LastName, City AS CustomerCity, ProductKey, ProductName, StoreKey, StoreName, count(SaleID) AS TotalOrders, sum(SalesAmount) AS TotalSales, max(FullDate) AS LastOrderDate FROM new_sales GROUP BY CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m19:40:34.412697 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6543171e-9d30-47ef-b8e3-0736b78d8d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2272b9a10>]}
[0m19:40:34.414263 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model `default`.`cust_sales_detailed_summary`  [[31mERROR[0m in 0.17s]
[0m19:40:34.415492 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:40:34.417313 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' to be skipped because of status 'error'.  Reason: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `FirstName` in scope WITH new_sales AS (SELECT * FROM default.fact_sales WHERE FullDate > (SELECT coalesce(max(LastOrderDate), '1970-01-01') FROM default.cust_sales_detailed_summary)) SELECT CustomerKey, FirstName, LastName, City AS CustomerCity, ProductKey, ProductName, StoreKey, StoreName, count(SaleID) AS TotalOrders, sum(SalesAmount) AS TotalSales, max(FullDate) AS LastOrderDate FROM new_sales GROUP BY CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m19:40:34.425614 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:40:34.426521 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m19:40:34.427319 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m19:40:34.428241 [info ] [MainThread]: 
[0m19:40:34.429207 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.41 seconds (0.41s).
[0m19:40:34.430786 [debug] [MainThread]: Command end result
[0m19:40:34.483369 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:40:34.486641 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:40:34.496916 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:40:34.497640 [info ] [MainThread]: 
[0m19:40:34.498553 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:40:34.500170 [info ] [MainThread]: 
[0m19:40:34.501435 [error] [MainThread]: [31mFailure in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)[0m
[0m19:40:34.503049 [error] [MainThread]:   Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `FirstName` in scope WITH new_sales AS (SELECT * FROM default.fact_sales WHERE FullDate > (SELECT coalesce(max(LastOrderDate), '1970-01-01') FROM default.cust_sales_detailed_summary)) SELECT CustomerKey, FirstName, LastName, City AS CustomerCity, ProductKey, ProductName, StoreKey, StoreName, count(SaleID) AS TotalOrders, sum(SalesAmount) AS TotalSales, max(FullDate) AS LastOrderDate FROM new_sales GROUP BY CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m19:40:34.505119 [info ] [MainThread]: 
[0m19:40:34.507075 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:40:34.508611 [info ] [MainThread]: 
[0m19:40:34.510001 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m19:40:34.512995 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.4631913, "process_in_blocks": "0", "process_kernel_time": 0.302319, "process_mem_max_rss": "123312", "process_out_blocks": "3270", "process_user_time": 2.643017}
[0m19:40:34.513993 [debug] [MainThread]: Command `dbt run` failed at 19:40:34.513841 after 1.46 seconds
[0m19:40:34.514796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa22bec91d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa22bec87d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa22a263650>]}
[0m19:40:34.515580 [debug] [MainThread]: Flushing usage events
[0m19:40:35.091437 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:41:53.741412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5e727cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5e7bdc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5e6052d0>]}


============================== 19:41:53.745974 | 4d41eb60-d2ad-45ed-919c-14e9e623e154 ==============================
[0m19:41:53.745974 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:41:53.747497 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'static_parser': 'True', 'quiet': 'False', 'write_json': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'partial_parse': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'use_colors': 'True', 'printer_width': '80', 'empty': 'False', 'use_experimental_parser': 'False', 'profiles_dir': '/dbt', 'warn_error': 'None', 'introspect': 'True', 'log_format': 'default', 'no_print': 'None', 'target_path': 'None', 'debug': 'False', 'log_path': '/dbt/logs'}
[0m19:41:53.939091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4d41eb60-d2ad-45ed-919c-14e9e623e154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5e430a90>]}
[0m19:41:54.013186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4d41eb60-d2ad-45ed-919c-14e9e623e154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5eba0990>]}
[0m19:41:54.015492 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:41:54.109158 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:41:54.244311 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:41:54.245467 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/cust_sales_detailed_summary.sql
[0m19:41:54.524827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4d41eb60-d2ad-45ed-919c-14e9e623e154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5e4dfb90>]}
[0m19:41:54.616855 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:41:54.620355 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:41:54.637482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4d41eb60-d2ad-45ed-919c-14e9e623e154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5e22a490>]}
[0m19:41:54.638378 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:41:54.639151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4d41eb60-d2ad-45ed-919c-14e9e623e154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5e0eb890>]}
[0m19:41:54.641414 [info ] [MainThread]: 
[0m19:41:54.642390 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:41:54.643951 [info ] [MainThread]: 
[0m19:41:54.645592 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:41:54.647719 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:41:54.662500 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:41:54.819892 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:41:54.823947 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:41:54.846069 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m19:41:54.853254 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:41:54.861109 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:41:54.866090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4d41eb60-d2ad-45ed-919c-14e9e623e154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5d247150>]}
[0m19:41:54.870312 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:41:54.871529 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m19:41:54.872791 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m19:41:54.873907 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:41:54.889184 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:41:54.892063 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:41:54.964657 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_new_data` 
  ...
[0m19:41:54.968699 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:41:55.010297 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

WITH new_sales AS (
    SELECT
        f.SaleID,
        f.FullDate,
        f.CustomerKey,
        f.ProductKey,
        f.StoreKey,
        f.SalesAmount,
        f.Quantity,
        c.FirstName,
        c.LastName,
        c.City AS CustomerCity,
        p.ProductName,
        s.StoreName
    FROM `default`.`fact_sales` AS f
    LEFT JOIN `default`.`dim_customer` AS c
        ON f.CustomerKey = c.CustomerKey
    LEFT JOIN `default`.`dim_product` AS p
        ON f.ProductKey = p.ProductKey
    LEFT JOIN `default`.`dim_store` AS s
        ON f.StoreKey = s.StoreKey
    
      WHERE f.FullDate > (SELECT COALESCE(MAX(LastOrderDate), '1970-01-01') FROM `default`.`cust_sales_detailed_summary`)
    
)

SELECT
    CustomerKey,
    FirstName,
    LastName,
    CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName,
    COUNT(SaleID) AS TotalOrders,
    SUM(SalesAmount) AS TotalSales,
    MAX(FullDate) AS LastOrderDate
FROM new_sales
GROUP BY
    CustomerKey,
    FirstName,
    LastName,
    CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName
          )
        
        ...
[0m19:41:55.019443 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

WITH new_sales AS (
    SELECT
        f.SaleID,
        f.FullDate,
        f.CustomerKey,
        f.ProductKey,
        f.StoreKey,
        f.SalesAmount,
        f.Quantity,
        c.FirstName,
        c.LastName,
        c.City AS CustomerCity,
        p.ProductName,
        s.StoreName
    FROM `default`.`fact_sales` AS f
    LEFT JOIN `default`.`dim_customer` AS c
        ON f.CustomerKey = c.CustomerKey
    LEFT JOIN `default`.`dim_product` AS p
        ON f.ProductKey = p.ProductKey
    LEFT JOIN `default`.`dim_store` AS s
        ON f.StoreKey = s.StoreKey
    
      WHERE f.FullDate > (SELECT COALESCE(MAX(LastOrderDate), '1970-01-01') FROM `default`.`cust_sales_detailed_summary`)
    
)

SELECT
    CustomerKey,
    FirstName,
    LastName,
    CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName,
    COUNT(SaleID) AS TotalOrders,
    SUM(SalesAmount) AS TotalSales,
    MAX(FullDate) AS LastOrderDate
FROM new_sales
GROUP BY
    CustomerKey,
    FirstName,
    LastName,
    CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName
          )
        
        
[0m19:41:55.026967 [debug] [Thread-1 (]: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `CustomerKey` in scope WITH new_sales AS (SELECT f.SaleID, f.FullDate, f.CustomerKey, f.ProductKey, f.StoreKey, f.SalesAmount, f.Quantity, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductName, s.StoreName FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey WHERE f.FullDate > (SELECT coalesce(max(LastOrderDate), '1970-01-01') FROM default.cust_sales_detailed_summary)) SELECT CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName, count(SaleID) AS TotalOrders, sum(SalesAmount) AS TotalSales, max(FullDate) AS LastOrderDate FROM new_sales GROUP BY CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName. Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m19:41:55.029309 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d41eb60-d2ad-45ed-919c-14e9e623e154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5e036090>]}
[0m19:41:55.031332 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model `default`.`cust_sales_detailed_summary`  [[31mERROR[0m in 0.16s]
[0m19:41:55.032855 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:41:55.034379 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' to be skipped because of status 'error'.  Reason: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `CustomerKey` in scope WITH new_sales AS (SELECT f.SaleID, f.FullDate, f.CustomerKey, f.ProductKey, f.StoreKey, f.SalesAmount, f.Quantity, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductName, s.StoreName FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey WHERE f.FullDate > (SELECT coalesce(max(LastOrderDate), '1970-01-01') FROM default.cust_sales_detailed_summary)) SELECT CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName, count(SaleID) AS TotalOrders, sum(SalesAmount) AS TotalSales, max(FullDate) AS LastOrderDate FROM new_sales GROUP BY CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName. Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m19:41:55.041368 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:41:55.042276 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m19:41:55.043072 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m19:41:55.043940 [info ] [MainThread]: 
[0m19:41:55.044771 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.40 seconds (0.40s).
[0m19:41:55.046426 [debug] [MainThread]: Command end result
[0m19:41:55.097666 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:41:55.101363 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:41:55.111904 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:41:55.112698 [info ] [MainThread]: 
[0m19:41:55.113564 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:41:55.114570 [info ] [MainThread]: 
[0m19:41:55.115905 [error] [MainThread]: [31mFailure in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)[0m
[0m19:41:55.117643 [error] [MainThread]:   Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `CustomerKey` in scope WITH new_sales AS (SELECT f.SaleID, f.FullDate, f.CustomerKey, f.ProductKey, f.StoreKey, f.SalesAmount, f.Quantity, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductName, s.StoreName FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey WHERE f.FullDate > (SELECT coalesce(max(LastOrderDate), '1970-01-01') FROM default.cust_sales_detailed_summary)) SELECT CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName, count(SaleID) AS TotalOrders, sum(SalesAmount) AS TotalSales, max(FullDate) AS LastOrderDate FROM new_sales GROUP BY CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName. Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m19:41:55.120043 [info ] [MainThread]: 
[0m19:41:55.122231 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:41:55.123833 [info ] [MainThread]: 
[0m19:41:55.124931 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m19:41:55.127171 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.4512321, "process_in_blocks": "0", "process_kernel_time": 0.283353, "process_mem_max_rss": "123328", "process_out_blocks": "3285", "process_user_time": 2.605025}
[0m19:41:55.128088 [debug] [MainThread]: Command `dbt run` failed at 19:41:55.127952 after 1.45 seconds
[0m19:41:55.128812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5d1195d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5e60d510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e5e60c250>]}
[0m19:41:55.129552 [debug] [MainThread]: Flushing usage events
[0m19:41:55.733043 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:42:09.015300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff91689010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff90409ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9040bdd0>]}


============================== 19:42:09.019392 | 7252413f-2b07-40ea-ac6c-304efd825758 ==============================
[0m19:42:09.019392 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:42:09.020769 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'static_parser': 'True', 'version_check': 'True', 'quiet': 'False', 'target_path': 'None', 'empty': 'False', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'log_path': '/dbt/logs', 'indirect_selection': 'eager', 'fail_fast': 'False', 'introspect': 'True', 'profiles_dir': '/dbt', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'write_json': 'True', 'printer_width': '80', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:42:09.223289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff901b9850>]}
[0m19:42:09.292460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9099c950>]}
[0m19:42:09.294172 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:42:09.377614 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:42:09.498974 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:42:09.499955 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:42:09.539598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8ff3b390>]}
[0m19:42:09.638976 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:42:09.642462 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:42:09.660046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9026c9d0>]}
[0m19:42:09.661300 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:42:09.662329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff902db990>]}
[0m19:42:09.665866 [info ] [MainThread]: 
[0m19:42:09.667416 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:42:09.669413 [info ] [MainThread]: 
[0m19:42:09.671362 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:42:09.685267 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:42:09.702880 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:42:09.814260 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:42:09.818534 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:09.894068 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m19:42:09.900979 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:42:10.068490 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:42:10.076971 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.081973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8f0cee90>]}
[0m19:42:10.085932 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m19:42:10.086954 [info ] [Thread-1 (]: 1 of 9 START sql table model `default`.`dim_date` .............................. [RUN]
[0m19:42:10.087933 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m19:42:10.089134 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m19:42:10.099237 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m19:42:10.105581 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m19:42:10.178586 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m19:42:10.190968 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.214119 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:42:10.220513 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.226819 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m19:42:10.230300 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date__dbt_backup`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m19:42:10.240960 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.246222 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
EXCHANGE TABLES `default`.`dim_date__dbt_backup` AND `default`.`dim_date` 
  
  ...
[0m19:42:10.250768 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.277286 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  ...
[0m19:42:10.281150 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.285569 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff901c0090>]}
[0m19:42:10.287218 [info ] [Thread-1 (]: 1 of 9 OK created sql table model `default`.`dim_date` ......................... [[32mOK[0m in 0.20s]
[0m19:42:10.288479 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m19:42:10.289812 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m19:42:10.291460 [info ] [Thread-1 (]: 2 of 9 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m19:42:10.295364 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m19:42:10.297132 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m19:42:10.300742 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m19:42:10.305855 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m19:42:10.311822 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m19:42:10.322542 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.327177 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:42:10.333655 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.336720 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m19:42:10.339132 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m19:42:10.350637 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.353020 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
EXCHANGE TABLES `default`.`dim_payment__dbt_backup` AND `default`.`dim_payment` 
  
  ...
[0m19:42:10.357554 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.363702 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  ...
[0m19:42:10.367089 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.369361 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff902f9ad0>]}
[0m19:42:10.370301 [info ] [Thread-1 (]: 2 of 9 OK created sql table model `default`.`dim_payment` ...................... [[32mOK[0m in 0.07s]
[0m19:42:10.371495 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m19:42:10.372989 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m19:42:10.373962 [info ] [Thread-1 (]: 3 of 9 START sql table model `default`.`dim_product` ........................... [RUN]
[0m19:42:10.375616 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m19:42:10.377525 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m19:42:10.381602 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m19:42:10.384577 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m19:42:10.388838 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m19:42:10.404608 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.408694 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:42:10.418072 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.420702 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m19:42:10.423062 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m19:42:10.433319 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.435573 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
EXCHANGE TABLES `default`.`dim_product__dbt_backup` AND `default`.`dim_product` 
  
  ...
[0m19:42:10.439994 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.448467 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  ...
[0m19:42:10.452298 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.456191 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8e512450>]}
[0m19:42:10.457471 [info ] [Thread-1 (]: 3 of 9 OK created sql table model `default`.`dim_product` ...................... [[32mOK[0m in 0.08s]
[0m19:42:10.459866 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m19:42:10.461483 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m19:42:10.462870 [info ] [Thread-1 (]: 4 of 9 START sql table model `default`.`dim_store` ............................. [RUN]
[0m19:42:10.464057 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m19:42:10.465215 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m19:42:10.469091 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m19:42:10.472889 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m19:42:10.480144 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m19:42:10.491768 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.498334 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:42:10.505796 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.508819 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m19:42:10.514502 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store__dbt_backup`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m19:42:10.523987 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.527597 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
EXCHANGE TABLES `default`.`dim_store__dbt_backup` AND `default`.`dim_store` 
  
  ...
[0m19:42:10.532508 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.536751 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  ...
[0m19:42:10.540248 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.542391 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8e5142d0>]}
[0m19:42:10.543505 [info ] [Thread-1 (]: 4 of 9 OK created sql table model `default`.`dim_store` ........................ [[32mOK[0m in 0.08s]
[0m19:42:10.544653 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m19:42:10.545580 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m19:42:10.546649 [info ] [Thread-1 (]: 5 of 9 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m19:42:10.548200 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m19:42:10.549692 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m19:42:10.554516 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m19:42:10.557174 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m19:42:10.564431 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m19:42:10.574526 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.581470 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:42:10.587773 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.590375 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m19:42:10.595147 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier__dbt_backup`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m19:42:10.603974 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.606192 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
EXCHANGE TABLES `default`.`dim_supplier__dbt_backup` AND `default`.`dim_supplier` 
  
  ...
[0m19:42:10.612839 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.617564 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  ...
[0m19:42:10.620903 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.623036 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8eff6510>]}
[0m19:42:10.624054 [info ] [Thread-1 (]: 5 of 9 OK created sql table model `default`.`dim_supplier` ..................... [[32mOK[0m in 0.08s]
[0m19:42:10.625600 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m19:42:10.626798 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.fact_sales
[0m19:42:10.627932 [info ] [Thread-1 (]: 6 of 9 START sql table model `default`.`fact_sales` ............................ [RUN]
[0m19:42:10.629000 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.fact_sales)
[0m19:42:10.630057 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.fact_sales
[0m19:42:10.633602 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.fact_sales"
[0m19:42:10.636834 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.fact_sales
[0m19:42:10.642441 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

            

    
        create table `default`.`fact_sales__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_fact_sales`
          )
        
        ...
[0m19:42:10.655008 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.658596 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

    select name, type from system.columns where table = 'fact_sales__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:42:10.666403 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.669677 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.fact_sales"
[0m19:42:10.672052 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

  
    
    
    
        
         


        insert into `default`.`fact_sales__dbt_backup`
        ("SaleID", "DateKey", "StoreKey", "ProductKey", "SupplierKey", "CustomerKey", "PaymentKey", "Quantity", "SalesAmount", "FullDate")SELECT
    *
FROM `default`.`stg_fact_sales`
  ...
[0m19:42:10.683194 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.685164 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */
EXCHANGE TABLES `default`.`fact_sales__dbt_backup` AND `default`.`fact_sales` 
  
  ...
[0m19:42:10.690111 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.696923 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */
drop table if exists `default`.`fact_sales__dbt_backup` 
  ...
[0m19:42:10.700392 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.702535 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff902f9310>]}
[0m19:42:10.703512 [info ] [Thread-1 (]: 6 of 9 OK created sql table model `default`.`fact_sales` ....................... [[32mOK[0m in 0.07s]
[0m19:42:10.705059 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.fact_sales
[0m19:42:10.706014 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m19:42:10.707043 [info ] [Thread-1 (]: 7 of 9 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m19:42:10.708228 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.fact_sales, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m19:42:10.709194 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m19:42:10.714372 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m19:42:10.719898 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m19:42:10.724453 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m19:42:10.748991 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m19:42:10.752484 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:42:10.757957 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.763000 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m19:42:10.765868 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m19:42:10.788156 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m19:42:10.790107 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
EXCHANGE TABLES `default`.`stg_dim_customer__dbt_backup` AND `default`.`stg_dim_customer` 
  
  ...
[0m19:42:10.794620 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.798752 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  ...
[0m19:42:10.802039 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.804046 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8ef708d0>]}
[0m19:42:10.805116 [info ] [Thread-1 (]: 7 of 9 OK created sql table model `default`.`stg_dim_customer` ................. [[32mOK[0m in 0.10s]
[0m19:42:10.806252 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m19:42:10.807918 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m19:42:10.811051 [info ] [Thread-1 (]: 8 of 9 START sql table model `default`.`dim_customer` .......................... [RUN]
[0m19:42:10.815199 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.stg_dim_customer, now model.clickhouse_dbt_demo.dim_customer)
[0m19:42:10.816261 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_customer
[0m19:42:10.819895 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_customer"
[0m19:42:10.822380 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_customer
[0m19:42:10.827708 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

            

    
        create table `default`.`dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
          )
        
        ...
[0m19:42:10.841236 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.849337 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:42:10.855013 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.858240 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_customer"
[0m19:42:10.863479 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
  ...
[0m19:42:10.873976 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:42:10.877769 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */
EXCHANGE TABLES `default`.`dim_customer__dbt_backup` AND `default`.`dim_customer` 
  
  ...
[0m19:42:10.883197 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.887648 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */
drop table if exists `default`.`dim_customer__dbt_backup` 
  ...
[0m19:42:10.891770 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.894818 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8efeac50>]}
[0m19:42:10.895941 [info ] [Thread-1 (]: 8 of 9 OK created sql table model `default`.`dim_customer` ..................... [[32mOK[0m in 0.08s]
[0m19:42:10.897079 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m19:42:10.899434 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:42:10.900383 [info ] [Thread-1 (]: 9 of 9 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m19:42:10.901261 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_customer, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m19:42:10.902142 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:42:10.913590 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:42:10.917449 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:42:10.983849 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_new_data` 
  ...
[0m19:42:10.987332 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:42:10.990197 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

WITH new_sales AS (
    SELECT
        f.SaleID,
        f.FullDate,
        f.CustomerKey,
        f.ProductKey,
        f.StoreKey,
        f.SalesAmount,
        f.Quantity,
        c.FirstName,
        c.LastName,
        c.City AS CustomerCity,
        p.ProductName,
        s.StoreName
    FROM `default`.`fact_sales` AS f
    LEFT JOIN `default`.`dim_customer` AS c
        ON f.CustomerKey = c.CustomerKey
    LEFT JOIN `default`.`dim_product` AS p
        ON f.ProductKey = p.ProductKey
    LEFT JOIN `default`.`dim_store` AS s
        ON f.StoreKey = s.StoreKey
    
      WHERE f.FullDate > (SELECT COALESCE(MAX(LastOrderDate), '1970-01-01') FROM `default`.`cust_sales_detailed_summary`)
    
)

SELECT
    CustomerKey,
    FirstName,
    LastName,
    CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName,
    COUNT(SaleID) AS TotalOrders,
    SUM(SalesAmount) AS TotalSales,
    MAX(FullDate) AS LastOrderDate
FROM new_sales
GROUP BY
    CustomerKey,
    FirstName,
    LastName,
    CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName
          )
        
        ...
[0m19:42:10.998896 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

WITH new_sales AS (
    SELECT
        f.SaleID,
        f.FullDate,
        f.CustomerKey,
        f.ProductKey,
        f.StoreKey,
        f.SalesAmount,
        f.Quantity,
        c.FirstName,
        c.LastName,
        c.City AS CustomerCity,
        p.ProductName,
        s.StoreName
    FROM `default`.`fact_sales` AS f
    LEFT JOIN `default`.`dim_customer` AS c
        ON f.CustomerKey = c.CustomerKey
    LEFT JOIN `default`.`dim_product` AS p
        ON f.ProductKey = p.ProductKey
    LEFT JOIN `default`.`dim_store` AS s
        ON f.StoreKey = s.StoreKey
    
      WHERE f.FullDate > (SELECT COALESCE(MAX(LastOrderDate), '1970-01-01') FROM `default`.`cust_sales_detailed_summary`)
    
)

SELECT
    CustomerKey,
    FirstName,
    LastName,
    CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName,
    COUNT(SaleID) AS TotalOrders,
    SUM(SalesAmount) AS TotalSales,
    MAX(FullDate) AS LastOrderDate
FROM new_sales
GROUP BY
    CustomerKey,
    FirstName,
    LastName,
    CustomerCity,
    ProductKey,
    ProductName,
    StoreKey,
    StoreName
          )
        
        
[0m19:42:11.006173 [debug] [Thread-1 (]: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `CustomerKey` in scope WITH new_sales AS (SELECT f.SaleID, f.FullDate, f.CustomerKey, f.ProductKey, f.StoreKey, f.SalesAmount, f.Quantity, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductName, s.StoreName FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey WHERE f.FullDate > (SELECT coalesce(max(LastOrderDate), '1970-01-01') FROM default.cust_sales_detailed_summary)) SELECT CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName, count(SaleID) AS TotalOrders, sum(SalesAmount) AS TotalSales, max(FullDate) AS LastOrderDate FROM new_sales GROUP BY CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName. Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m19:42:11.008165 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7252413f-2b07-40ea-ac6c-304efd825758', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8f1bd0d0>]}
[0m19:42:11.009410 [error] [Thread-1 (]: 9 of 9 ERROR creating sql incremental model `default`.`cust_sales_detailed_summary`  [[31mERROR[0m in 0.11s]
[0m19:42:11.010944 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:42:11.012575 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' to be skipped because of status 'error'.  Reason: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `CustomerKey` in scope WITH new_sales AS (SELECT f.SaleID, f.FullDate, f.CustomerKey, f.ProductKey, f.StoreKey, f.SalesAmount, f.Quantity, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductName, s.StoreName FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey WHERE f.FullDate > (SELECT coalesce(max(LastOrderDate), '1970-01-01') FROM default.cust_sales_detailed_summary)) SELECT CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName, count(SaleID) AS TotalOrders, sum(SalesAmount) AS TotalSales, max(FullDate) AS LastOrderDate FROM new_sales GROUP BY CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName. Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123).
[0m19:42:11.017423 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:42:11.018789 [debug] [MainThread]: Connection 'list_' was left open.
[0m19:42:11.021044 [debug] [MainThread]: On list_: Close
[0m19:42:11.022253 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m19:42:11.023162 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m19:42:11.024148 [info ] [MainThread]: 
[0m19:42:11.025268 [info ] [MainThread]: Finished running 1 incremental model, 8 table models in 0 hours 0 minutes and 1.35 seconds (1.35s).
[0m19:42:11.031243 [debug] [MainThread]: Command end result
[0m19:42:11.094086 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:42:11.098604 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:42:11.109879 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:42:11.110936 [info ] [MainThread]: 
[0m19:42:11.112182 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:42:11.113588 [info ] [MainThread]: 
[0m19:42:11.115329 [error] [MainThread]: [31mFailure in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)[0m
[0m19:42:11.118516 [error] [MainThread]:   Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `CustomerKey` in scope WITH new_sales AS (SELECT f.SaleID, f.FullDate, f.CustomerKey, f.ProductKey, f.StoreKey, f.SalesAmount, f.Quantity, c.FirstName, c.LastName, c.City AS CustomerCity, p.ProductName, s.StoreName FROM default.fact_sales AS f LEFT JOIN default.dim_customer AS c ON f.CustomerKey = c.CustomerKey LEFT JOIN default.dim_product AS p ON f.ProductKey = p.ProductKey LEFT JOIN default.dim_store AS s ON f.StoreKey = s.StoreKey WHERE f.FullDate > (SELECT coalesce(max(LastOrderDate), '1970-01-01') FROM default.cust_sales_detailed_summary)) SELECT CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName, count(SaleID) AS TotalOrders, sum(SalesAmount) AS TotalSales, max(FullDate) AS LastOrderDate FROM new_sales GROUP BY CustomerKey, FirstName, LastName, CustomerCity, ProductKey, ProductName, StoreKey, StoreName. Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
[0m19:42:11.120973 [info ] [MainThread]: 
[0m19:42:11.122218 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:42:11.123299 [info ] [MainThread]: 
[0m19:42:11.124940 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=9
[0m19:42:11.127220 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.1744606, "process_in_blocks": "0", "process_kernel_time": 0.322638, "process_mem_max_rss": "122568", "process_out_blocks": "2304", "process_user_time": 2.895477}
[0m19:42:11.129875 [debug] [MainThread]: Command `dbt run` failed at 19:42:11.129369 after 2.18 seconds
[0m19:42:11.131643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8e5fbfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8e5f8c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff8e5fb210>]}
[0m19:42:11.133123 [debug] [MainThread]: Flushing usage events
[0m19:42:11.785567 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:50:58.052260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2867453d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb286701c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb286744c50>]}


============================== 19:50:58.056203 | b4576692-0a77-461b-8df7-8f769943eed6 ==============================
[0m19:50:58.056203 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:50:58.057688 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'profiles_dir': '/dbt', 'warn_error': 'None', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'partial_parse': 'True', 'printer_width': '80', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/dbt/logs', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'write_json': 'True', 'no_print': 'None', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'fail_fast': 'False'}
[0m19:50:58.270653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b4576692-0a77-461b-8df7-8f769943eed6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2868ba290>]}
[0m19:50:58.342233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b4576692-0a77-461b-8df7-8f769943eed6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb28743c850>]}
[0m19:50:58.344230 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:50:58.447172 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:50:58.570262 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading clickhouse_dbt_demo: marts/schema.yml - Runtime Error
    Syntax error near line 8
    ------------------------------
    5  | 
    6  | ### Step 9.1: Create a schema.yml file
    7  | 
    8  | Inside your dbt project, create a file named `schema.yml` (or add to an existing one) in the same folder as your models, e.g., `dbt_project/models/marts/schema.yml`.
    9  | 
    10 | Example `schema.yml` content:
    11 | 
    
    Raw Error:
    ------------------------------
    did not find expected <document start>
      in "<unicode string>", line 8, column 1
[0m19:50:58.572018 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.58625394, "process_in_blocks": "0", "process_kernel_time": 0.248836, "process_mem_max_rss": "110296", "process_out_blocks": "5", "process_user_time": 1.903048}
[0m19:50:58.573005 [debug] [MainThread]: Command `dbt run` failed at 19:50:58.572735 after 0.59 seconds
[0m19:50:58.573936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb28670aad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb286708410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb28670be10>]}
[0m19:50:58.575129 [debug] [MainThread]: Flushing usage events
[0m19:50:59.207864 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:51:11.340783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2d411810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2d9e0890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2d411b10>]}


============================== 19:51:11.345304 | c5d92d44-020d-404c-bf96-d3c6a934bc1e ==============================
[0m19:51:11.345304 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:51:11.346577 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'profiles_dir': '/dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'fail_fast': 'False', 'log_path': '/dbt/logs', 'log_format': 'default', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'target_path': 'None', 'static_parser': 'True', 'version_check': 'True', 'empty': 'False', 'invocation_command': 'dbt run --select cust_sales_detailed_summary', 'write_json': 'True', 'use_colors': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False', 'partial_parse': 'True'}
[0m19:51:11.555234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c5d92d44-020d-404c-bf96-d3c6a934bc1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2d43a190>]}
[0m19:51:11.622853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c5d92d44-020d-404c-bf96-d3c6a934bc1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2d9a0d50>]}
[0m19:51:11.624444 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:51:11.711989 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:51:11.836376 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:51:11.837717 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/cust_sales_detailed_summary.sql
[0m19:51:12.144866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c5d92d44-020d-404c-bf96-d3c6a934bc1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2d1c4090>]}
[0m19:51:12.238840 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:51:12.242552 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:51:12.258764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c5d92d44-020d-404c-bf96-d3c6a934bc1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2cd5c690>]}
[0m19:51:12.259718 [info ] [MainThread]: Found 9 models, 6 seeds, 485 macros
[0m19:51:12.260565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c5d92d44-020d-404c-bf96-d3c6a934bc1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2cd15a50>]}
[0m19:51:12.262932 [info ] [MainThread]: 
[0m19:51:12.263865 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:51:12.265047 [info ] [MainThread]: 
[0m19:51:12.266318 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:51:12.268742 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:51:12.282806 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:51:12.438263 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:51:12.442438 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:51:12.463716 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m19:51:12.471282 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:51:12.478787 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:51:12.484075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c5d92d44-020d-404c-bf96-d3c6a934bc1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2ce95350>]}
[0m19:51:12.488119 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:51:12.489339 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m19:51:12.490754 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m19:51:12.491967 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:51:12.504850 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:51:12.514298 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:51:12.586949 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_new_data` 
  ...
[0m19:51:12.590703 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:51:12.630786 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

WITH aggregated AS (
    SELECT
        c.CustomerKey,
        c.FirstName,
        c.LastName,
        c.City AS CustomerCity,
        COUNT(f.SaleID) AS TotalOrders,
        SUM(f.SalesAmount) AS TotalSales,
        MAX(f.FullDate) AS LastOrderDate
    FROM `default`.`fact_sales` AS f
    LEFT JOIN `default`.`dim_customer` AS c
        ON f.CustomerKey = c.CustomerKey
    
      WHERE f.FullDate > (SELECT COALESCE(MAX(LastOrderDate), '1970-01-01') FROM `default`.`cust_sales_detailed_summary`)
    
    GROUP BY c.CustomerKey, c.FirstName, c.LastName, c.City
)
SELECT * FROM aggregated
          )
        
        ...
[0m19:51:12.645288 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:51:12.668274 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary__dbt_new_data'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:51:12.675445 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:51:12.680403 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        
  
    
    
    
        
         


        insert into `default`.`cust_sales_detailed_summary__dbt_new_data`
        ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "TotalOrders", "TotalSales", "LastOrderDate")

WITH aggregated AS (
    SELECT
        c.CustomerKey,
        c.FirstName,
        c.LastName,
        c.City AS CustomerCity,
        COUNT(f.SaleID) AS TotalOrders,
        SUM(f.SalesAmount) AS TotalSales,
        MAX(f.FullDate) AS LastOrderDate
    FROM `default`.`fact_sales` AS f
    LEFT JOIN `default`.`dim_customer` AS c
        ON f.CustomerKey = c.CustomerKey
    
      WHERE f.FullDate > (SELECT COALESCE(MAX(LastOrderDate), '1970-01-01') FROM `default`.`cust_sales_detailed_summary`)
    
    GROUP BY c.CustomerKey, c.FirstName, c.LastName, c.City
)
SELECT * FROM aggregated
  
      ...
[0m19:51:12.722301 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m19:51:12.724246 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m19:51:12.729165 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

          create table `default`.`cust_sales_detailed_summary__dbt_tmp` 
   as `default`.`cust_sales_detailed_summary__dbt_new_data`
      ...
[0m19:51:12.737875 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:51:12.741625 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:51:12.746807 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:51:12.748996 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    ...
[0m19:51:12.752877 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    
[0m19:51:12.757640 [debug] [Thread-1 (]: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 16, server response: Code: 16. DB::Exception: No such column p.ProductKey in table default.cust_sales_detailed_summary__dbt_tmp (5abf1978-ac08-416e-829f-6d5ee6476d56). (NO_SUCH_COLUMN_IN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:51:12.759727 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5d92d44-020d-404c-bf96-d3c6a934bc1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2cbcc9d0>]}
[0m19:51:12.760987 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model `default`.`cust_sales_detailed_summary`  [[31mERROR[0m in 0.27s]
[0m19:51:12.767509 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m19:51:12.769857 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' to be skipped because of status 'error'.  Reason: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 16, server response: Code: 16. DB::Exception: No such column p.ProductKey in table default.cust_sales_detailed_summary__dbt_tmp (5abf1978-ac08-416e-829f-6d5ee6476d56). (NO_SUCH_COLUMN_IN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql.
[0m19:51:12.773079 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:51:12.774294 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m19:51:12.775945 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m19:51:12.777445 [info ] [MainThread]: 
[0m19:51:12.779928 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.51 seconds (0.51s).
[0m19:51:12.781973 [debug] [MainThread]: Command end result
[0m19:51:12.835885 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:51:12.839114 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:51:12.850237 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:51:12.851006 [info ] [MainThread]: 
[0m19:51:12.851847 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:51:12.853150 [info ] [MainThread]: 
[0m19:51:12.854711 [error] [MainThread]: [31mFailure in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)[0m
[0m19:51:12.855965 [error] [MainThread]:   Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 16, server response: Code: 16. DB::Exception: No such column p.ProductKey in table default.cust_sales_detailed_summary__dbt_tmp (5abf1978-ac08-416e-829f-6d5ee6476d56). (NO_SUCH_COLUMN_IN_TABLE) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:51:12.857213 [info ] [MainThread]: 
[0m19:51:12.859741 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m19:51:12.862004 [info ] [MainThread]: 
[0m19:51:12.863762 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m19:51:12.865836 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5950919, "process_in_blocks": "0", "process_kernel_time": 0.245714, "process_mem_max_rss": "123464", "process_out_blocks": "3276", "process_user_time": 2.739563}
[0m19:51:12.866870 [debug] [MainThread]: Command `dbt run` failed at 19:51:12.866708 after 1.60 seconds
[0m19:51:12.867615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2d28ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2d299210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac2d4104d0>]}
[0m19:51:12.868492 [debug] [MainThread]: Flushing usage events
[0m19:51:13.394124 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:54:43.966079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c784c810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c7936210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c784cc50>]}


============================== 19:54:43.971332 | a29f35b6-1e95-473f-877a-494a42c5004a ==============================
[0m19:54:43.971332 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:54:43.973086 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'empty': 'False', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'quiet': 'False', 'log_cache_events': 'False', 'target_path': 'None', 'indirect_selection': 'eager', 'log_path': '/dbt/logs', 'introspect': 'True', 'write_json': 'True', 'invocation_command': 'dbt run --select fact_sales', 'static_parser': 'True', 'log_format': 'default', 'warn_error': 'None', 'profiles_dir': '/dbt', 'cache_selected_only': 'False', 'version_check': 'True', 'no_print': 'None', 'debug': 'False', 'partial_parse': 'True'}
[0m19:54:44.174925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a29f35b6-1e95-473f-877a-494a42c5004a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c7672ed0>]}
[0m19:54:44.244411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a29f35b6-1e95-473f-877a-494a42c5004a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c7d6ab10>]}
[0m19:54:44.245980 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:54:44.326473 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:54:44.478709 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m19:54:44.480116 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://models/marts/schema.yml
[0m19:54:44.760002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a29f35b6-1e95-473f-877a-494a42c5004a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c715c650>]}
[0m19:54:44.932712 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:54:44.936070 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:54:44.955550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a29f35b6-1e95-473f-877a-494a42c5004a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c7248210>]}
[0m19:54:44.956487 [info ] [MainThread]: Found 9 models, 6 seeds, 6 data tests, 485 macros
[0m19:54:44.957365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a29f35b6-1e95-473f-877a-494a42c5004a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c715d710>]}
[0m19:54:44.959913 [info ] [MainThread]: 
[0m19:54:44.961664 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:54:44.964345 [info ] [MainThread]: 
[0m19:54:44.967107 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:54:44.969266 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:54:44.982390 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:54:45.075884 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:54:45.080101 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:54:45.101776 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default)
[0m19:54:45.109185 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:54:45.116806 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:54:45.122593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a29f35b6-1e95-473f-877a-494a42c5004a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c7004cd0>]}
[0m19:54:45.126975 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.fact_sales
[0m19:54:45.128078 [info ] [Thread-1 (]: 1 of 1 START sql table model `default`.`fact_sales` ............................ [RUN]
[0m19:54:45.129374 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.fact_sales)
[0m19:54:45.130935 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.fact_sales
[0m19:54:45.143283 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.fact_sales"
[0m19:54:45.149736 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.fact_sales
[0m19:54:45.220568 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

            

    
        create table `default`.`fact_sales__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_fact_sales`
          )
        
        ...
[0m19:54:45.233085 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:54:45.252599 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

    select name, type from system.columns where table = 'fact_sales__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m19:54:45.259097 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:54:45.264648 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.fact_sales"
[0m19:54:45.272683 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

  
    
    
    
        
         


        insert into `default`.`fact_sales__dbt_backup`
        ("SaleID", "DateKey", "StoreKey", "ProductKey", "SupplierKey", "CustomerKey", "PaymentKey", "Quantity", "SalesAmount", "FullDate")SELECT
    *
FROM `default`.`stg_fact_sales`
  ...
[0m19:54:45.280528 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:54:45.298643 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */
EXCHANGE TABLES `default`.`fact_sales__dbt_backup` AND `default`.`fact_sales` 
  
  ...
[0m19:54:45.305590 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:54:45.335648 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */
drop table if exists `default`.`fact_sales__dbt_backup` 
  ...
[0m19:54:45.339938 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m19:54:45.344788 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a29f35b6-1e95-473f-877a-494a42c5004a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c70b3e90>]}
[0m19:54:45.346358 [info ] [Thread-1 (]: 1 of 1 OK created sql table model `default`.`fact_sales` ....................... [[32mOK[0m in 0.21s]
[0m19:54:45.347985 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.fact_sales
[0m19:54:45.353633 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:54:45.355976 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.fact_sales' was left open.
[0m19:54:45.357809 [debug] [MainThread]: On model.clickhouse_dbt_demo.fact_sales: Close
[0m19:54:45.358744 [info ] [MainThread]: 
[0m19:54:45.359897 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.39 seconds (0.39s).
[0m19:54:45.362020 [debug] [MainThread]: Command end result
[0m19:54:45.432495 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:54:45.436392 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:54:45.448622 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:54:45.449723 [info ] [MainThread]: 
[0m19:54:45.451718 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:54:45.453454 [info ] [MainThread]: 
[0m19:54:45.454902 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m19:54:45.457945 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.5547731, "process_in_blocks": "0", "process_kernel_time": 0.294738, "process_mem_max_rss": "122136", "process_out_blocks": "3345", "process_user_time": 2.75776}
[0m19:54:45.459329 [debug] [MainThread]: Command `dbt run` succeeded at 19:54:45.459061 after 1.56 seconds
[0m19:54:45.460409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c7672950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9cc1b90d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9cc1b9490>]}
[0m19:54:45.461191 [debug] [MainThread]: Flushing usage events
[0m19:54:46.046556 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:55:07.185546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd098a9e510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd097c09ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd097d36250>]}


============================== 19:55:07.189924 | 9c07e197-561f-4869-abc3-10852bbaaf57 ==============================
[0m19:55:07.189924 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:55:07.191674 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'partial_parse': 'True', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/dbt/logs', 'log_cache_events': 'False', 'write_json': 'True', 'static_parser': 'True', 'printer_width': '80', 'version_check': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'use_colors': 'True', 'target_path': 'None', 'no_print': 'None', 'profiles_dir': '/dbt', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'None'}
[0m19:55:07.428409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9c07e197-561f-4869-abc3-10852bbaaf57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0979c2050>]}
[0m19:55:07.498793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9c07e197-561f-4869-abc3-10852bbaaf57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0981a09d0>]}
[0m19:55:07.500430 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m19:55:07.592205 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:55:07.741356 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:55:07.742340 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:55:07.794814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9c07e197-561f-4869-abc3-10852bbaaf57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd097754290>]}
[0m19:55:07.902978 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:55:07.906348 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:55:07.991614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9c07e197-561f-4869-abc3-10852bbaaf57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0973a3e10>]}
[0m19:55:07.992729 [info ] [MainThread]: Found 9 models, 6 seeds, 6 data tests, 485 macros
[0m19:55:07.993635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9c07e197-561f-4869-abc3-10852bbaaf57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0977dd9d0>]}
[0m19:55:07.997324 [info ] [MainThread]: 
[0m19:55:07.999620 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:55:08.001550 [info ] [MainThread]: 
[0m19:55:08.003024 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:55:08.015594 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m19:55:08.031746 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:55:08.117626 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m19:55:08.124063 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:55:08.202192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9c07e197-561f-4869-abc3-10852bbaaf57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0977dd9d0>]}
[0m19:55:08.206902 [debug] [Thread-1 (]: Began running node test.clickhouse_dbt_demo.not_null_fact_sales_CustomerKey.0fbf53a987
[0m19:55:08.208002 [info ] [Thread-1 (]: 1 of 6 START test not_null_fact_sales_CustomerKey .............................. [RUN]
[0m19:55:08.209512 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now test.clickhouse_dbt_demo.not_null_fact_sales_CustomerKey.0fbf53a987)
[0m19:55:08.210996 [debug] [Thread-1 (]: Began compiling node test.clickhouse_dbt_demo.not_null_fact_sales_CustomerKey.0fbf53a987
[0m19:55:08.234207 [debug] [Thread-1 (]: Writing injected SQL for node "test.clickhouse_dbt_demo.not_null_fact_sales_CustomerKey.0fbf53a987"
[0m19:55:08.241699 [debug] [Thread-1 (]: Began executing node test.clickhouse_dbt_demo.not_null_fact_sales_CustomerKey.0fbf53a987
[0m19:55:08.263652 [debug] [Thread-1 (]: Writing runtime sql for node "test.clickhouse_dbt_demo.not_null_fact_sales_CustomerKey.0fbf53a987"
[0m19:55:08.268829 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.clickhouse_dbt_demo.not_null_fact_sales_CustomerKey.0fbf53a987: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "test.clickhouse_dbt_demo.not_null_fact_sales_CustomerKey.0fbf53a987"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select CustomerKey
from `default`.`fact_sales`
where CustomerKey is null



  
  
    ) dbt_internal_test...
[0m19:55:08.279030 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:55:08.284721 [info ] [Thread-1 (]: 1 of 6 PASS not_null_fact_sales_CustomerKey .................................... [[32mPASS[0m in 0.08s]
[0m19:55:08.286177 [debug] [Thread-1 (]: Finished running node test.clickhouse_dbt_demo.not_null_fact_sales_CustomerKey.0fbf53a987
[0m19:55:08.287638 [debug] [Thread-1 (]: Began running node test.clickhouse_dbt_demo.not_null_fact_sales_FullDate.00caa99c6f
[0m19:55:08.288644 [info ] [Thread-1 (]: 2 of 6 START test not_null_fact_sales_FullDate ................................. [RUN]
[0m19:55:08.289896 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.clickhouse_dbt_demo.not_null_fact_sales_CustomerKey.0fbf53a987, now test.clickhouse_dbt_demo.not_null_fact_sales_FullDate.00caa99c6f)
[0m19:55:08.290817 [debug] [Thread-1 (]: Began compiling node test.clickhouse_dbt_demo.not_null_fact_sales_FullDate.00caa99c6f
[0m19:55:08.297213 [debug] [Thread-1 (]: Writing injected SQL for node "test.clickhouse_dbt_demo.not_null_fact_sales_FullDate.00caa99c6f"
[0m19:55:08.300478 [debug] [Thread-1 (]: Began executing node test.clickhouse_dbt_demo.not_null_fact_sales_FullDate.00caa99c6f
[0m19:55:08.308047 [debug] [Thread-1 (]: Writing runtime sql for node "test.clickhouse_dbt_demo.not_null_fact_sales_FullDate.00caa99c6f"
[0m19:55:08.313927 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.clickhouse_dbt_demo.not_null_fact_sales_FullDate.00caa99c6f: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "test.clickhouse_dbt_demo.not_null_fact_sales_FullDate.00caa99c6f"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select FullDate
from `default`.`fact_sales`
where FullDate is null



  
  
    ) dbt_internal_test...
[0m19:55:08.325726 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:55:08.328305 [info ] [Thread-1 (]: 2 of 6 PASS not_null_fact_sales_FullDate ....................................... [[32mPASS[0m in 0.04s]
[0m19:55:08.329521 [debug] [Thread-1 (]: Finished running node test.clickhouse_dbt_demo.not_null_fact_sales_FullDate.00caa99c6f
[0m19:55:08.330673 [debug] [Thread-1 (]: Began running node test.clickhouse_dbt_demo.not_null_fact_sales_ProductKey.60b5513800
[0m19:55:08.331586 [info ] [Thread-1 (]: 3 of 6 START test not_null_fact_sales_ProductKey ............................... [RUN]
[0m19:55:08.332779 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.clickhouse_dbt_demo.not_null_fact_sales_FullDate.00caa99c6f, now test.clickhouse_dbt_demo.not_null_fact_sales_ProductKey.60b5513800)
[0m19:55:08.333609 [debug] [Thread-1 (]: Began compiling node test.clickhouse_dbt_demo.not_null_fact_sales_ProductKey.60b5513800
[0m19:55:08.339624 [debug] [Thread-1 (]: Writing injected SQL for node "test.clickhouse_dbt_demo.not_null_fact_sales_ProductKey.60b5513800"
[0m19:55:08.344063 [debug] [Thread-1 (]: Began executing node test.clickhouse_dbt_demo.not_null_fact_sales_ProductKey.60b5513800
[0m19:55:08.347503 [debug] [Thread-1 (]: Writing runtime sql for node "test.clickhouse_dbt_demo.not_null_fact_sales_ProductKey.60b5513800"
[0m19:55:08.351376 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.clickhouse_dbt_demo.not_null_fact_sales_ProductKey.60b5513800: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "test.clickhouse_dbt_demo.not_null_fact_sales_ProductKey.60b5513800"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ProductKey
from `default`.`fact_sales`
where ProductKey is null



  
  
    ) dbt_internal_test...
[0m19:55:08.362202 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:55:08.364844 [info ] [Thread-1 (]: 3 of 6 PASS not_null_fact_sales_ProductKey ..................................... [[32mPASS[0m in 0.03s]
[0m19:55:08.366247 [debug] [Thread-1 (]: Finished running node test.clickhouse_dbt_demo.not_null_fact_sales_ProductKey.60b5513800
[0m19:55:08.367587 [debug] [Thread-1 (]: Began running node test.clickhouse_dbt_demo.not_null_fact_sales_SaleID.54675be502
[0m19:55:08.368393 [info ] [Thread-1 (]: 4 of 6 START test not_null_fact_sales_SaleID ................................... [RUN]
[0m19:55:08.369454 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.clickhouse_dbt_demo.not_null_fact_sales_ProductKey.60b5513800, now test.clickhouse_dbt_demo.not_null_fact_sales_SaleID.54675be502)
[0m19:55:08.370529 [debug] [Thread-1 (]: Began compiling node test.clickhouse_dbt_demo.not_null_fact_sales_SaleID.54675be502
[0m19:55:08.376884 [debug] [Thread-1 (]: Writing injected SQL for node "test.clickhouse_dbt_demo.not_null_fact_sales_SaleID.54675be502"
[0m19:55:08.380881 [debug] [Thread-1 (]: Began executing node test.clickhouse_dbt_demo.not_null_fact_sales_SaleID.54675be502
[0m19:55:08.384356 [debug] [Thread-1 (]: Writing runtime sql for node "test.clickhouse_dbt_demo.not_null_fact_sales_SaleID.54675be502"
[0m19:55:08.386554 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.clickhouse_dbt_demo.not_null_fact_sales_SaleID.54675be502: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "test.clickhouse_dbt_demo.not_null_fact_sales_SaleID.54675be502"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select SaleID
from `default`.`fact_sales`
where SaleID is null



  
  
    ) dbt_internal_test...
[0m19:55:08.398503 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:55:08.400822 [info ] [Thread-1 (]: 4 of 6 PASS not_null_fact_sales_SaleID ......................................... [[32mPASS[0m in 0.03s]
[0m19:55:08.402401 [debug] [Thread-1 (]: Finished running node test.clickhouse_dbt_demo.not_null_fact_sales_SaleID.54675be502
[0m19:55:08.403425 [debug] [Thread-1 (]: Began running node test.clickhouse_dbt_demo.not_null_fact_sales_SalesAmount.0ea043749c
[0m19:55:08.404646 [info ] [Thread-1 (]: 5 of 6 START test not_null_fact_sales_SalesAmount .............................. [RUN]
[0m19:55:08.407078 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.clickhouse_dbt_demo.not_null_fact_sales_SaleID.54675be502, now test.clickhouse_dbt_demo.not_null_fact_sales_SalesAmount.0ea043749c)
[0m19:55:08.408692 [debug] [Thread-1 (]: Began compiling node test.clickhouse_dbt_demo.not_null_fact_sales_SalesAmount.0ea043749c
[0m19:55:08.414042 [debug] [Thread-1 (]: Writing injected SQL for node "test.clickhouse_dbt_demo.not_null_fact_sales_SalesAmount.0ea043749c"
[0m19:55:08.416822 [debug] [Thread-1 (]: Began executing node test.clickhouse_dbt_demo.not_null_fact_sales_SalesAmount.0ea043749c
[0m19:55:08.422816 [debug] [Thread-1 (]: Writing runtime sql for node "test.clickhouse_dbt_demo.not_null_fact_sales_SalesAmount.0ea043749c"
[0m19:55:08.426461 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.clickhouse_dbt_demo.not_null_fact_sales_SalesAmount.0ea043749c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "test.clickhouse_dbt_demo.not_null_fact_sales_SalesAmount.0ea043749c"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select SalesAmount
from `default`.`fact_sales`
where SalesAmount is null



  
  
    ) dbt_internal_test...
[0m19:55:08.435174 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:55:08.438520 [info ] [Thread-1 (]: 5 of 6 PASS not_null_fact_sales_SalesAmount .................................... [[32mPASS[0m in 0.03s]
[0m19:55:08.442524 [debug] [Thread-1 (]: Finished running node test.clickhouse_dbt_demo.not_null_fact_sales_SalesAmount.0ea043749c
[0m19:55:08.443914 [debug] [Thread-1 (]: Began running node test.clickhouse_dbt_demo.not_null_fact_sales_StoreKey.6666ed57cf
[0m19:55:08.445005 [info ] [Thread-1 (]: 6 of 6 START test not_null_fact_sales_StoreKey ................................. [RUN]
[0m19:55:08.446519 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.clickhouse_dbt_demo.not_null_fact_sales_SalesAmount.0ea043749c, now test.clickhouse_dbt_demo.not_null_fact_sales_StoreKey.6666ed57cf)
[0m19:55:08.447543 [debug] [Thread-1 (]: Began compiling node test.clickhouse_dbt_demo.not_null_fact_sales_StoreKey.6666ed57cf
[0m19:55:08.452548 [debug] [Thread-1 (]: Writing injected SQL for node "test.clickhouse_dbt_demo.not_null_fact_sales_StoreKey.6666ed57cf"
[0m19:55:08.457028 [debug] [Thread-1 (]: Began executing node test.clickhouse_dbt_demo.not_null_fact_sales_StoreKey.6666ed57cf
[0m19:55:08.460585 [debug] [Thread-1 (]: Writing runtime sql for node "test.clickhouse_dbt_demo.not_null_fact_sales_StoreKey.6666ed57cf"
[0m19:55:08.463676 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.clickhouse_dbt_demo.not_null_fact_sales_StoreKey.6666ed57cf: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "test.clickhouse_dbt_demo.not_null_fact_sales_StoreKey.6666ed57cf"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select StoreKey
from `default`.`fact_sales`
where StoreKey is null



  
  
    ) dbt_internal_test...
[0m19:55:08.475471 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m19:55:08.478261 [info ] [Thread-1 (]: 6 of 6 PASS not_null_fact_sales_StoreKey ....................................... [[32mPASS[0m in 0.03s]
[0m19:55:08.479634 [debug] [Thread-1 (]: Finished running node test.clickhouse_dbt_demo.not_null_fact_sales_StoreKey.6666ed57cf
[0m19:55:08.483019 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:55:08.483789 [debug] [MainThread]: Connection 'test.clickhouse_dbt_demo.not_null_fact_sales_StoreKey.6666ed57cf' was left open.
[0m19:55:08.484437 [debug] [MainThread]: On test.clickhouse_dbt_demo.not_null_fact_sales_StoreKey.6666ed57cf: Close
[0m19:55:08.485114 [info ] [MainThread]: 
[0m19:55:08.485952 [info ] [MainThread]: Finished running 6 data tests in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m19:55:08.491370 [debug] [MainThread]: Command end result
[0m19:55:08.550178 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:55:08.555769 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:55:08.567540 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:55:08.568736 [info ] [MainThread]: 
[0m19:55:08.569665 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:55:08.572470 [info ] [MainThread]: 
[0m19:55:08.574437 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m19:55:08.577237 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.4631474, "process_in_blocks": "0", "process_kernel_time": 0.322775, "process_mem_max_rss": "121032", "process_out_blocks": "2293", "process_user_time": 2.607738}
[0m19:55:08.578626 [debug] [MainThread]: Command `dbt test` succeeded at 19:55:08.578446 after 1.46 seconds
[0m19:55:08.579432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd09c70b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd09c598590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd09c5995d0>]}
[0m19:55:08.580287 [debug] [MainThread]: Flushing usage events
[0m19:55:09.118162 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:00:17.238759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d9176150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d9314c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d9314f90>]}


============================== 20:00:17.244903 | 92097fe9-4e6f-4c14-aa7e-12d1aa0ac484 ==============================
[0m20:00:17.244903 [info ] [MainThread]: Running with dbt=1.10.13
[0m20:00:17.246452 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'no_print': 'None', 'profiles_dir': '/dbt', 'invocation_command': 'dbt test --select check_pos_total_sales.sql', 'empty': 'None', 'printer_width': '80', 'version_check': 'True', 'write_json': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'introspect': 'True', 'static_parser': 'True', 'fail_fast': 'False', 'quiet': 'False', 'warn_error': 'None', 'log_format': 'default', 'log_cache_events': 'False', 'log_path': '/dbt/logs'}
[0m20:00:17.451782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '92097fe9-4e6f-4c14-aa7e-12d1aa0ac484', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d9438450>]}
[0m20:00:17.525807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '92097fe9-4e6f-4c14-aa7e-12d1aa0ac484', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d98a49d0>]}
[0m20:00:17.527553 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m20:00:17.611573 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m20:00:17.778186 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m20:00:17.779566 [debug] [MainThread]: Partial parsing: added file: clickhouse_dbt_demo://tests/check_pos_total_sales.sql
[0m20:00:17.780426 [debug] [MainThread]: Partial parsing: updated file: clickhouse_dbt_demo://models/marts/cust_sales_detailed_summary.sql
[0m20:00:18.180381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '92097fe9-4e6f-4c14-aa7e-12d1aa0ac484', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d8f92a90>]}
[0m20:00:18.368961 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m20:00:18.372352 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m20:00:18.400250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '92097fe9-4e6f-4c14-aa7e-12d1aa0ac484', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d8fc9dd0>]}
[0m20:00:18.401245 [info ] [MainThread]: Found 9 models, 6 seeds, 7 data tests, 485 macros
[0m20:00:18.402140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '92097fe9-4e6f-4c14-aa7e-12d1aa0ac484', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d8a747d0>]}
[0m20:00:18.405395 [info ] [MainThread]: 
[0m20:00:18.408496 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:00:18.410236 [info ] [MainThread]: 
[0m20:00:18.411741 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m20:00:18.420704 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m20:00:18.434670 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:00:18.538745 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m20:00:18.545337 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:00:18.562502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '92097fe9-4e6f-4c14-aa7e-12d1aa0ac484', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d8aecc10>]}
[0m20:00:18.567297 [debug] [Thread-1 (]: Began running node test.clickhouse_dbt_demo.check_pos_total_sales
[0m20:00:18.568362 [info ] [Thread-1 (]: 1 of 1 START test check_pos_total_sales ........................................ [RUN]
[0m20:00:18.569405 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now test.clickhouse_dbt_demo.check_pos_total_sales)
[0m20:00:18.570742 [debug] [Thread-1 (]: Began compiling node test.clickhouse_dbt_demo.check_pos_total_sales
[0m20:00:18.581141 [debug] [Thread-1 (]: Writing injected SQL for node "test.clickhouse_dbt_demo.check_pos_total_sales"
[0m20:00:18.585787 [debug] [Thread-1 (]: Began executing node test.clickhouse_dbt_demo.check_pos_total_sales
[0m20:00:18.612429 [debug] [Thread-1 (]: Writing runtime sql for node "test.clickhouse_dbt_demo.check_pos_total_sales"
[0m20:00:18.617905 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.clickhouse_dbt_demo.check_pos_total_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "test.clickhouse_dbt_demo.check_pos_total_sales"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  SELECT *
FROM `default`.`cust_sales_detailed_summary`
WHERE TotalSales < 0
  
  
    ) dbt_internal_test...
[0m20:00:18.629711 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:00:18.634675 [info ] [Thread-1 (]: 1 of 1 PASS check_pos_total_sales .............................................. [[32mPASS[0m in 0.07s]
[0m20:00:18.636314 [debug] [Thread-1 (]: Finished running node test.clickhouse_dbt_demo.check_pos_total_sales
[0m20:00:18.640235 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:00:18.642177 [debug] [MainThread]: Connection 'test.clickhouse_dbt_demo.check_pos_total_sales' was left open.
[0m20:00:18.643216 [debug] [MainThread]: On test.clickhouse_dbt_demo.check_pos_total_sales: Close
[0m20:00:18.644161 [info ] [MainThread]: 
[0m20:00:18.645084 [info ] [MainThread]: Finished running 1 test in 0 hours 0 minutes and 0.23 seconds (0.23s).
[0m20:00:18.646720 [debug] [MainThread]: Command end result
[0m20:00:18.698391 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m20:00:18.702188 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m20:00:18.712800 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m20:00:18.713551 [info ] [MainThread]: 
[0m20:00:18.714489 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:00:18.715557 [info ] [MainThread]: 
[0m20:00:18.716579 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m20:00:18.718655 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.547687, "process_in_blocks": "0", "process_kernel_time": 0.254654, "process_mem_max_rss": "123840", "process_out_blocks": "3359", "process_user_time": 2.697117}
[0m20:00:18.719995 [debug] [MainThread]: Command `dbt test` succeeded at 20:00:18.719754 after 1.55 seconds
[0m20:00:18.721629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73dddd5610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d94b3a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73ddc891d0>]}
[0m20:00:18.723936 [debug] [MainThread]: Flushing usage events
[0m20:00:19.313183 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:16:16.375943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b3d81e250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b3d8a5b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b3d895a10>]}


============================== 20:16:16.381732 | cfd7491d-4858-4d7a-af1c-95472e6a7b14 ==============================
[0m20:16:16.381732 [info ] [MainThread]: Running with dbt=1.10.13
[0m20:16:16.383323 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'target_path': 'None', 'log_path': '/dbt/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'warn_error': 'None', 'static_parser': 'True', 'invocation_command': 'dbt run --selector all_models', 'quiet': 'False', 'fail_fast': 'False', 'indirect_selection': 'eager', 'debug': 'False', 'profiles_dir': '/dbt', 'write_json': 'True', 'introspect': 'True', 'no_print': 'None'}
[0m20:16:16.585642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cfd7491d-4858-4d7a-af1c-95472e6a7b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b3d51f390>]}
[0m20:16:16.654323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cfd7491d-4858-4d7a-af1c-95472e6a7b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b3e6dbcd0>]}
[0m20:16:16.655903 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m20:16:16.741510 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m20:16:16.913318 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:16:16.914252 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:16:16.973091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cfd7491d-4858-4d7a-af1c-95472e6a7b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b3d06c6d0>]}
[0m20:16:17.099208 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m20:16:17.102622 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m20:16:17.121661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cfd7491d-4858-4d7a-af1c-95472e6a7b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b3d2a64d0>]}
[0m20:16:17.122609 [info ] [MainThread]: Found 9 models, 6 seeds, 7 data tests, 485 macros
[0m20:16:17.123732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cfd7491d-4858-4d7a-af1c-95472e6a7b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b3d35a210>]}
[0m20:16:17.125237 [error] [MainThread]: Encountered an error:
'list' object has no attribute 'split'
[0m20:16:17.139785 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 272, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 303, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 373, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 350, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 390, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/main.py", line 587, in run
    results = task.run()
              ^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/task/runnable.py", line 583, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.11/site-packages/dbt/task/compile.py", line 133, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.11/site-packages/dbt/task/runnable.py", line 174, in _runtime_initialize
    self.job_queue = self.get_graph_queue()
                     ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/task/runnable.py", line 164, in get_graph_queue
    return selector.get_graph_queue(spec, preserve_edges)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/graph/selector.py", line 342, in get_graph_queue
    selected_nodes = self.get_selected(spec)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/graph/selector.py", line 332, in get_selected
    selected_nodes, indirect_only = self.select_nodes(spec)
                                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/graph/selector.py", line 159, in select_nodes
    direct_nodes, indirect_nodes = self.select_nodes_recursively(spec)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/graph/selector.py", line 131, in select_nodes_recursively
    bundles = [self.select_nodes_recursively(component) for component in spec]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/graph/selector.py", line 131, in <listcomp>
    bundles = [self.select_nodes_recursively(component) for component in spec]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/graph/selector.py", line 129, in select_nodes_recursively
    direct_nodes, indirect_nodes = self.get_nodes_from_criteria(spec)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/graph/selector.py", line 80, in get_nodes_from_criteria
    collected = self.select_included(nodes, spec)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/graph/selector.py", line 66, in select_included
    return set(method.search(included_nodes, spec.value))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/graph/selector_methods.py", line 269, in search
    if self.node_is_match(selector, node.fqn, node.is_versioned):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/graph/selector_methods.py", line 254, in node_is_match
    if is_selected_node(fqn, qualified_name, is_versioned):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/graph/selector_methods.py", line 84, in is_selected_node
    if len(flat_fqn) < len(node_selector.split(".")):
                           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'

[0m20:16:17.142573 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.83340764, "process_in_blocks": "0", "process_kernel_time": 0.260604, "process_mem_max_rss": "111884", "process_out_blocks": "1160", "process_user_time": 2.068672}
[0m20:16:17.146303 [debug] [MainThread]: Command `dbt run` failed at 20:16:17.145291 after 0.84 seconds
[0m20:16:17.147570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b3d6fabd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b3d6f9510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b3d6fbcd0>]}
[0m20:16:17.148640 [debug] [MainThread]: Flushing usage events
[0m20:16:17.739264 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:17:06.082820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee0a0a5590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee09f7c690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee09ef8850>]}


============================== 20:17:06.087292 | 516e95ce-a7b6-4291-b4c4-159b10cf0560 ==============================
[0m20:17:06.087292 [info ] [MainThread]: Running with dbt=1.10.13
[0m20:17:06.088685 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'write_json': 'True', 'partial_parse': 'True', 'invocation_command': 'dbt run --selector all_models', 'log_format': 'default', 'version_check': 'True', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'warn_error': 'None', 'empty': 'False', 'cache_selected_only': 'False', 'introspect': 'True', 'use_experimental_parser': 'False', 'log_path': '/dbt/logs', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'debug': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'profiles_dir': '/dbt', 'use_colors': 'True', 'log_cache_events': 'False'}
[0m20:17:06.286467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee09eef8d0>]}
[0m20:17:06.353491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee0a484990>]}
[0m20:17:06.355138 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m20:17:06.458370 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m20:17:06.676302 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:17:06.677209 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:17:06.738482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee09868490>]}
[0m20:17:06.859624 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m20:17:06.863724 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m20:17:06.879886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee09ca9910>]}
[0m20:17:06.881080 [info ] [MainThread]: Found 9 models, 6 seeds, 7 data tests, 485 macros
[0m20:17:06.881969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee09af3a50>]}
[0m20:17:06.884854 [info ] [MainThread]: 
[0m20:17:06.886404 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:17:06.889094 [info ] [MainThread]: 
[0m20:17:06.891533 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m20:17:06.902581 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m20:17:06.920535 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:17:07.015394 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m20:17:07.019774 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.099518 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m20:17:07.106259 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:17:07.161871 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m20:17:07.170175 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.178447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee08bd2cd0>]}
[0m20:17:07.183588 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_date
[0m20:17:07.185697 [info ] [Thread-1 (]: 1 of 9 START sql table model `default`.`dim_date` .............................. [RUN]
[0m20:17:07.187542 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default, now model.clickhouse_dbt_demo.dim_date)
[0m20:17:07.189066 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_date
[0m20:17:07.205843 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_date"
[0m20:17:07.215987 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_date
[0m20:17:07.309915 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

            

    
        create table `default`.`dim_date__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_date`
          )
        
        ...
[0m20:17:07.323008 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.353975 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

    select name, type from system.columns where table = 'dim_date__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m20:17:07.363056 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.369524 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_date"
[0m20:17:07.373631 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */

  
    
    
    
        
         


        insert into `default`.`dim_date__dbt_backup`
        ("DateKey", "FullDate", "Year", "Month", "Day", "DayOfWeek")SELECT
    *
FROM `default`.`stg_dim_date`
  ...
[0m20:17:07.385594 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.394237 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
EXCHANGE TABLES `default`.`dim_date__dbt_backup` AND `default`.`dim_date` 
  
  ...
[0m20:17:07.400082 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.437263 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_date: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_date"} */
drop table if exists `default`.`dim_date__dbt_backup` 
  ...
[0m20:17:07.443635 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.449676 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee08bfcf50>]}
[0m20:17:07.451050 [info ] [Thread-1 (]: 1 of 9 OK created sql table model `default`.`dim_date` ......................... [[32mOK[0m in 0.26s]
[0m20:17:07.452600 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_date
[0m20:17:07.454771 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_payment
[0m20:17:07.456139 [info ] [Thread-1 (]: 2 of 9 START sql table model `default`.`dim_payment` ........................... [RUN]
[0m20:17:07.457666 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_date, now model.clickhouse_dbt_demo.dim_payment)
[0m20:17:07.459045 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_payment
[0m20:17:07.466202 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_payment"
[0m20:17:07.469659 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_payment
[0m20:17:07.479868 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

            

    
        create table `default`.`dim_payment__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m20:17:07.495143 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.499592 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

    select name, type from system.columns where table = 'dim_payment__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m20:17:07.505467 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.510032 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_payment"
[0m20:17:07.513027 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */

  
    
    
    
        
         


        insert into `default`.`dim_payment__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m20:17:07.521020 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.523074 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
EXCHANGE TABLES `default`.`dim_payment__dbt_backup` AND `default`.`dim_payment` 
  
  ...
[0m20:17:07.527963 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.533604 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_payment: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_payment"} */
drop table if exists `default`.`dim_payment__dbt_backup` 
  ...
[0m20:17:07.536693 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.538784 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee08916e90>]}
[0m20:17:07.539822 [info ] [Thread-1 (]: 2 of 9 OK created sql table model `default`.`dim_payment` ...................... [[32mOK[0m in 0.08s]
[0m20:17:07.541034 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_payment
[0m20:17:07.542194 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_product
[0m20:17:07.543555 [info ] [Thread-1 (]: 3 of 9 START sql table model `default`.`dim_product` ........................... [RUN]
[0m20:17:07.544701 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_payment, now model.clickhouse_dbt_demo.dim_product)
[0m20:17:07.545823 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_product
[0m20:17:07.551312 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_product"
[0m20:17:07.555087 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_product
[0m20:17:07.564539 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

            

    
        create table `default`.`dim_product__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_product`
          )
        
        ...
[0m20:17:07.576185 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.581955 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

    select name, type from system.columns where table = 'dim_product__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m20:17:07.587310 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.590078 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_product"
[0m20:17:07.593804 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product__dbt_backup`
        ("ProductKey", "ProductName", "Category", "Brand")SELECT
    *
FROM `default`.`stg_dim_product`
  ...
[0m20:17:07.602486 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.604590 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
EXCHANGE TABLES `default`.`dim_product__dbt_backup` AND `default`.`dim_product` 
  
  ...
[0m20:17:07.610712 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.615427 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_product"} */
drop table if exists `default`.`dim_product__dbt_backup` 
  ...
[0m20:17:07.618683 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.620798 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee08915ed0>]}
[0m20:17:07.622061 [info ] [Thread-1 (]: 3 of 9 OK created sql table model `default`.`dim_product` ...................... [[32mOK[0m in 0.08s]
[0m20:17:07.623402 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_product
[0m20:17:07.624698 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_store
[0m20:17:07.625761 [info ] [Thread-1 (]: 4 of 9 START sql table model `default`.`dim_store` ............................. [RUN]
[0m20:17:07.628874 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_product, now model.clickhouse_dbt_demo.dim_store)
[0m20:17:07.630030 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_store
[0m20:17:07.633632 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_store"
[0m20:17:07.636788 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_store
[0m20:17:07.641352 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

            

    
        create table `default`.`dim_store__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_store`
          )
        
        ...
[0m20:17:07.655509 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.659627 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m20:17:07.667240 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.670035 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_store"
[0m20:17:07.672202 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */

  
    
    
    
        
         


        insert into `default`.`dim_store__dbt_backup`
        ("StoreKey", "StoreName", "City", "Region")SELECT
    *
FROM `default`.`stg_dim_store`
  ...
[0m20:17:07.682639 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.684806 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
EXCHANGE TABLES `default`.`dim_store__dbt_backup` AND `default`.`dim_store` 
  
  ...
[0m20:17:07.689157 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.695931 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_store"} */
drop table if exists `default`.`dim_store__dbt_backup` 
  ...
[0m20:17:07.699721 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.701850 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee08ac7510>]}
[0m20:17:07.702803 [info ] [Thread-1 (]: 4 of 9 OK created sql table model `default`.`dim_store` ........................ [[32mOK[0m in 0.07s]
[0m20:17:07.703742 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_store
[0m20:17:07.704781 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_supplier
[0m20:17:07.706030 [info ] [Thread-1 (]: 5 of 9 START sql table model `default`.`dim_supplier` .......................... [RUN]
[0m20:17:07.706956 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_store, now model.clickhouse_dbt_demo.dim_supplier)
[0m20:17:07.708115 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_supplier
[0m20:17:07.715293 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_supplier"
[0m20:17:07.718507 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_supplier
[0m20:17:07.722728 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

            

    
        create table `default`.`dim_supplier__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_dim_supplier`
          )
        
        ...
[0m20:17:07.736057 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.739983 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

    select name, type from system.columns where table = 'dim_supplier__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m20:17:07.747771 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.750315 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_supplier"
[0m20:17:07.753257 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */

  
    
    
    
        
         


        insert into `default`.`dim_supplier__dbt_backup`
        ("SupplierKey", "SupplierName", "ContactInfo")SELECT
    *
FROM `default`.`stg_dim_supplier`
  ...
[0m20:17:07.765278 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.767000 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
EXCHANGE TABLES `default`.`dim_supplier__dbt_backup` AND `default`.`dim_supplier` 
  
  ...
[0m20:17:07.771439 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.777793 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_supplier: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_supplier"} */
drop table if exists `default`.`dim_supplier__dbt_backup` 
  ...
[0m20:17:07.781232 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.783747 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee097a42d0>]}
[0m20:17:07.784840 [info ] [Thread-1 (]: 5 of 9 OK created sql table model `default`.`dim_supplier` ..................... [[32mOK[0m in 0.08s]
[0m20:17:07.785886 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_supplier
[0m20:17:07.786709 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.fact_sales
[0m20:17:07.788068 [info ] [Thread-1 (]: 6 of 9 START sql table model `default`.`fact_sales` ............................ [RUN]
[0m20:17:07.789653 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_supplier, now model.clickhouse_dbt_demo.fact_sales)
[0m20:17:07.790578 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.fact_sales
[0m20:17:07.796280 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.fact_sales"
[0m20:17:07.799740 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.fact_sales
[0m20:17:07.804009 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

            

    
        create table `default`.`fact_sales__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    *
FROM `default`.`stg_fact_sales`
          )
        
        ...
[0m20:17:07.816974 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.820849 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

    select name, type from system.columns where table = 'fact_sales__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m20:17:07.829536 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.833239 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.fact_sales"
[0m20:17:07.835965 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */

  
    
    
    
        
         


        insert into `default`.`fact_sales__dbt_backup`
        ("SaleID", "DateKey", "StoreKey", "ProductKey", "SupplierKey", "CustomerKey", "PaymentKey", "Quantity", "SalesAmount", "FullDate")SELECT
    *
FROM `default`.`stg_fact_sales`
  ...
[0m20:17:07.848218 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.850463 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */
EXCHANGE TABLES `default`.`fact_sales__dbt_backup` AND `default`.`fact_sales` 
  
  ...
[0m20:17:07.854927 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.859267 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.fact_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.fact_sales"} */
drop table if exists `default`.`fact_sales__dbt_backup` 
  ...
[0m20:17:07.862635 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.864603 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee09cc8310>]}
[0m20:17:07.865611 [info ] [Thread-1 (]: 6 of 9 OK created sql table model `default`.`fact_sales` ....................... [[32mOK[0m in 0.07s]
[0m20:17:07.866588 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.fact_sales
[0m20:17:07.867861 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.stg_dim_customer
[0m20:17:07.869828 [info ] [Thread-1 (]: 7 of 9 START sql table model `default`.`stg_dim_customer` ...................... [RUN]
[0m20:17:07.872903 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.fact_sales, now model.clickhouse_dbt_demo.stg_dim_customer)
[0m20:17:07.874469 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.stg_dim_customer
[0m20:17:07.878102 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m20:17:07.883627 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.stg_dim_customer
[0m20:17:07.889634 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

            

    
        create table `default`.`stg_dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
          )
        
        ...
[0m20:17:07.906232 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m20:17:07.912294 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

    select name, type from system.columns where table = 'stg_dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m20:17:07.918460 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.921545 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.stg_dim_customer"
[0m20:17:07.927098 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`stg_dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM file('/var/lib/clickhouse/user_files/dim_customer.csv')
  ...
[0m20:17:07.939916 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:07.942132 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
EXCHANGE TABLES `default`.`stg_dim_customer__dbt_backup` AND `default`.`stg_dim_customer` 
  
  ...
[0m20:17:07.946995 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.951879 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.stg_dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.stg_dim_customer"} */
drop table if exists `default`.`stg_dim_customer__dbt_backup` 
  ...
[0m20:17:07.955347 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:07.958218 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee0898eb90>]}
[0m20:17:07.959774 [info ] [Thread-1 (]: 7 of 9 OK created sql table model `default`.`stg_dim_customer` ................. [[32mOK[0m in 0.09s]
[0m20:17:07.961054 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.stg_dim_customer
[0m20:17:07.963458 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.dim_customer
[0m20:17:07.964515 [info ] [Thread-1 (]: 8 of 9 START sql table model `default`.`dim_customer` .......................... [RUN]
[0m20:17:07.965544 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.stg_dim_customer, now model.clickhouse_dbt_demo.dim_customer)
[0m20:17:07.966563 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.dim_customer
[0m20:17:07.970290 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.dim_customer"
[0m20:17:07.973371 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.dim_customer
[0m20:17:07.980766 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

            

    
        create table `default`.`dim_customer__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
          )
        
        ...
[0m20:17:07.999460 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m20:17:08.004232 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m20:17:08.013200 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:08.016480 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.dim_customer"
[0m20:17:08.020596 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */

  
    
    
    
        
         


        insert into `default`.`dim_customer__dbt_backup`
        ("CustomerKey", "FirstName", "LastName", "Segment", "City", "ValidFrom", "ValidTo")SELECT
    CustomerKey,
    FirstName,
    LastName,
    Segment,
    City,
    ValidFrom,
    ValidTo
FROM `default`.`stg_dim_customer`
  ...
[0m20:17:08.032216 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:08.034748 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */
EXCHANGE TABLES `default`.`dim_customer__dbt_backup` AND `default`.`dim_customer` 
  
  ...
[0m20:17:08.039947 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:08.045089 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.dim_customer: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.dim_customer"} */
drop table if exists `default`.`dim_customer__dbt_backup` 
  ...
[0m20:17:08.048813 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:08.051532 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee08925750>]}
[0m20:17:08.053053 [info ] [Thread-1 (]: 8 of 9 OK created sql table model `default`.`dim_customer` ..................... [[32mOK[0m in 0.09s]
[0m20:17:08.054198 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.dim_customer
[0m20:17:08.056587 [debug] [Thread-1 (]: Began running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m20:17:08.057908 [info ] [Thread-1 (]: 9 of 9 START sql incremental model `default`.`cust_sales_detailed_summary` ..... [RUN]
[0m20:17:08.062327 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_dbt_demo.dim_customer, now model.clickhouse_dbt_demo.cust_sales_detailed_summary)
[0m20:17:08.064742 [debug] [Thread-1 (]: Began compiling node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m20:17:08.079451 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m20:17:08.084621 [debug] [Thread-1 (]: Began executing node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m20:17:08.140351 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_tmp` 
  ...
[0m20:17:08.145935 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:08.164870 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */
drop table if exists `default`.`cust_sales_detailed_summary__dbt_new_data` 
  ...
[0m20:17:08.168894 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:08.171661 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

            

    
        create table `default`.`cust_sales_detailed_summary__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey


  -- Only include new sales since the last run
  WHERE f.FullDate > (SELECT MAX(LastOrderDate) FROM `default`.`cust_sales_detailed_summary`)


GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
          )
        
        ...
[0m20:17:08.190768 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m20:17:08.195172 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary__dbt_new_data'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m20:17:08.201445 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:08.203745 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        
  
    
    
    
        
         


        insert into `default`.`cust_sales_detailed_summary__dbt_new_data`
        ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")

SELECT
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City AS CustomerCity,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName,
    COUNT(f.SaleID) AS TotalOrders,
    SUM(f.SalesAmount) AS TotalSales,
    MAX(f.FullDate) AS LastOrderDate
FROM `default`.`fact_sales` AS f
LEFT JOIN `default`.`dim_customer` AS c
    ON f.CustomerKey = c.CustomerKey
LEFT JOIN `default`.`dim_product` AS p
    ON f.ProductKey = p.ProductKey
LEFT JOIN `default`.`dim_store` AS s
    ON f.StoreKey = s.StoreKey


  -- Only include new sales since the last run
  WHERE f.FullDate > (SELECT MAX(LastOrderDate) FROM `default`.`cust_sales_detailed_summary`)


GROUP BY
    c.CustomerKey,
    c.FirstName,
    c.LastName,
    c.City,
    p.ProductKey,
    p.ProductName,
    s.StoreKey,
    s.StoreName
  
      ...
[0m20:17:08.223437 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m20:17:08.225241 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_dbt_demo.cust_sales_detailed_summary"
[0m20:17:08.229263 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

          create table `default`.`cust_sales_detailed_summary__dbt_tmp` 
   as `default`.`cust_sales_detailed_summary__dbt_new_data`
      ...
[0m20:17:08.239237 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:17:08.243779 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

    select name, type from system.columns where table = 'cust_sales_detailed_summary'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m20:17:08.249099 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:17:08.251612 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    ...
[0m20:17:08.256901 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_dbt_demo", "target_name": "dev", "node_id": "model.clickhouse_dbt_demo.cust_sales_detailed_summary"} */

        insert into `default`.`cust_sales_detailed_summary__dbt_tmp` ("c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate")
        select "c.CustomerKey", "FirstName", "LastName", "CustomerCity", "p.ProductKey", "ProductName", "s.StoreKey", "StoreName", "TotalOrders", "TotalSales", "LastOrderDate"
        from `default`.`cust_sales_detailed_summary`
          where (CustomerKey) not in (
            select CustomerKey
            from `default`.`cust_sales_detailed_summary__dbt_new_data`
          )
       
    
[0m20:17:08.262365 [debug] [Thread-1 (]: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m20:17:08.264481 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '516e95ce-a7b6-4291-b4c4-159b10cf0560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee08b11c10>]}
[0m20:17:08.265880 [error] [Thread-1 (]: 9 of 9 ERROR creating sql incremental model `default`.`cust_sales_detailed_summary`  [[31mERROR[0m in 0.20s]
[0m20:17:08.267610 [debug] [Thread-1 (]: Finished running node model.clickhouse_dbt_demo.cust_sales_detailed_summary
[0m20:17:08.269184 [debug] [Thread-4 (]: Marking all children of 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' to be skipped because of status 'error'.  Reason: Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql.
[0m20:17:08.272753 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:17:08.273746 [debug] [MainThread]: Connection 'list_' was left open.
[0m20:17:08.274834 [debug] [MainThread]: On list_: Close
[0m20:17:08.275955 [debug] [MainThread]: Connection 'model.clickhouse_dbt_demo.cust_sales_detailed_summary' was left open.
[0m20:17:08.278643 [debug] [MainThread]: On model.clickhouse_dbt_demo.cust_sales_detailed_summary: Close
[0m20:17:08.280505 [info ] [MainThread]: 
[0m20:17:08.281825 [info ] [MainThread]: Finished running 1 incremental model, 8 table models in 0 hours 0 minutes and 1.39 seconds (1.39s).
[0m20:17:08.286014 [debug] [MainThread]: Command end result
[0m20:17:08.353791 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m20:17:08.357774 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m20:17:08.366689 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m20:17:08.367632 [info ] [MainThread]: 
[0m20:17:08.369013 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m20:17:08.370827 [info ] [MainThread]: 
[0m20:17:08.373029 [error] [MainThread]: [31mFailure in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)[0m
[0m20:17:08.378224 [error] [MainThread]:   Database Error in model cust_sales_detailed_summary (models/marts/cust_sales_detailed_summary.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or table expression identifier `CustomerKey` in scope SELECT `c.CustomerKey`, FirstName, LastName, CustomerCity, `p.ProductKey`, ProductName, `s.StoreKey`, StoreName, TotalOrders, TotalSales, LastOrderDate FROM default.cust_sales_detailed_summary WHERE CustomerKey NOT IN (SELECT CustomerKey FROM default.cust_sales_detailed_summary__dbt_new_data). Maybe you meant: ['CustomerCity']. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build)) (for url http://clickhouse-server:8123)
  compiled code at target/run/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m20:17:08.380176 [info ] [MainThread]: 
[0m20:17:08.384319 [info ] [MainThread]:   compiled code at target/compiled/clickhouse_dbt_demo/models/marts/cust_sales_detailed_summary.sql
[0m20:17:08.386248 [info ] [MainThread]: 
[0m20:17:08.388582 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=9
[0m20:17:08.392404 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.3735132, "process_in_blocks": "0", "process_kernel_time": 0.327943, "process_mem_max_rss": "122824", "process_out_blocks": "2381", "process_user_time": 3.054619}
[0m20:17:08.394378 [debug] [MainThread]: Command `dbt run` failed at 20:17:08.394095 after 2.38 seconds
[0m20:17:08.396087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee0e865510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee09eeddd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee09eece10>]}
[0m20:17:08.398588 [debug] [MainThread]: Flushing usage events
[0m20:17:09.043034 [debug] [MainThread]: An error was encountered while trying to flush usage events
